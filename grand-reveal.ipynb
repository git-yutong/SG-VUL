{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import tempfile\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_node(feats, drop_rate,training=True,seed=42):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        feats (Tensor): 节点特征 [batch_size, num_nodes, feature_dim] 或 [num_nodes, feature_dim]\n",
    "        drop_rate (float): 丢弃概率。\n",
    "\n",
    "    Returns:\n",
    "        Tensor: 丢弃后的节点特征，与输入形状一致。\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    if not training or drop_rate <= 0.0:\n",
    "        return feats\n",
    "    if feats.dim() == 2:  # [num_nodes, feature_dim]\n",
    "        num_nodes, feature_dim = feats.shape\n",
    "        drop_rates = torch.full((num_nodes,), drop_rate, device=feats.device, dtype=feats.dtype)  # [num_nodes]\n",
    "        if training:\n",
    "            masks = torch.bernoulli(1. - drop_rates).unsqueeze(1).expand(-1, feature_dim)  # [num_nodes, feature_dim]\n",
    "            feats = masks * feats\n",
    "        else :\n",
    "            feats = feats * (1. - drop_rate)\n",
    "    elif feats.dim() == 3:  # [batch_size, num_nodes, feature_dim]\n",
    "        batch_size, num_nodes, feature_dim = feats.shape\n",
    "        drop_rates = torch.full((batch_size, num_nodes), drop_rate, device=feats.device, dtype=feats.dtype)  # [batch_size, num_nodes]\n",
    "        if training:\n",
    "            masks = torch.bernoulli(1. - drop_rates).unsqueeze(2).expand(-1, -1, feature_dim)  # [batch_size, num_nodes, feature_dim]\n",
    "            feats = masks * feats\n",
    "        else :\n",
    "            feats = feats * (1. - drop_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported feats dimension: {feats.dim()}\")\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, input_dropout, hidden_dropout, batchnorm):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, hid_dim)\n",
    "        self.layer2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.input_dropout = nn.Dropout(input_dropout)\n",
    "        self.hidden_dropout = nn.Dropout(hidden_dropout)\n",
    "        self.bn1 = nn.BatchNorm1d(in_dim) if batchnorm else None\n",
    "        self.bn2 = nn.BatchNorm1d(hid_dim) if batchnorm else None\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.layer1.reset_parameters()\n",
    "        self.layer2.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.bn1:\n",
    "            x = self.bn1(x)\n",
    "        x = self.input_dropout(x)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        if self.bn2:\n",
    "            x = self.bn2(x)\n",
    "        x = self.hidden_dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GGGNN(nn.Module):\n",
    "    def __init__(self, feature_dim_size, hidden_size, num_GNN_layers, dropout, act=nn.functional.relu):\n",
    "        super(GGGNN, self).__init__()\n",
    "        self.num_GNN_layers = num_GNN_layers\n",
    "        self.emb_encode = nn.Linear(feature_dim_size, hidden_size)\n",
    "        self.dropout_encode = nn.Dropout(dropout)\n",
    "        self.z0 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.z1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.r0 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.r1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h0 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.soft_att = nn.Linear(hidden_size, 1)\n",
    "        self.ln = nn.Linear(hidden_size, hidden_size)\n",
    "        self.act = act\n",
    "\n",
    "    def gatedGNN(self, x, adj):\n",
    "        a = torch.matmul(adj, x)\n",
    "        # update gate\n",
    "        z0 = self.z0(a)\n",
    "        z1 = self.z1(x)\n",
    "        z = torch.sigmoid(z0 + z1)\n",
    "        # reset gate\n",
    "        r = torch.sigmoid(self.r0(a) + self.r1(x))\n",
    "        # update embeddings\n",
    "        h = self.act(self.h0(a) + self.h1(r * x))\n",
    "\n",
    "        return h * z + x * (1 - z)\n",
    "\n",
    "    def forward(self, inputs, adj, mask):        # mask [B, N]\n",
    "        x = self.dropout_encode(inputs)\n",
    "        x = self.emb_encode(x)          # [B, N, H]\n",
    "        mask_3d = mask.unsqueeze(-1)             # [B, N, 1]\n",
    "\n",
    "        x = x * mask_3d                          # 广播到 [B, N, H]\n",
    "        for _ in range(self.num_GNN_layers):\n",
    "            x = self.gatedGNN(x, adj) * mask_3d  # 避免重复 unsqueeze\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRAND_GatedFusion(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim,\n",
    "                 hid_dim,\n",
    "                 S=5,\n",
    "                 K=3,\n",
    "                 num_GNN_layers=2,\n",
    "                 node_dropout=0.05,\n",
    "                 input_droprate=0.1,\n",
    "                 hidden_droprate=0.1,\n",
    "                 batchnorm=False,\n",
    "                 att_op='sum',\n",
    "                 num_heads=8,\n",
    "                 temp=0.5,\n",
    "                 lam=1.0,\n",
    "                 gnn_dropout=0.1,\n",
    "                 args=None):\n",
    "        super(GRAND_GatedFusion, self).__init__()\n",
    "        self.S = S\n",
    "        self.K = K\n",
    "        self.args = args\n",
    "        self.node_dropout_rate = node_dropout\n",
    "        self.att_op = att_op\n",
    "        self.temp = temp\n",
    "        self.lam = lam\n",
    "        \n",
    "        # GRAND components\n",
    "        self.grand_mlp = MLP(in_dim, hid_dim, hid_dim, input_droprate, hidden_droprate, batchnorm)\n",
    "        \n",
    "        # Gated GNN components\n",
    "        self.gggnn = GGGNN(in_dim, hid_dim, num_GNN_layers, gnn_dropout)\n",
    "        \n",
    "        # Fusion gate parameters\n",
    "        self.fusion_gate = nn.Linear(2 * hid_dim, hid_dim)\n",
    "        self.reset_gate = nn.Linear(2 * hid_dim, hid_dim)\n",
    "        self.update_gate = nn.Linear(2 * hid_dim, hid_dim)\n",
    "        self.output_gate = nn.Linear(2 * hid_dim, hid_dim)\n",
    "        \n",
    "        # Output layer parameters\n",
    "        if self.att_op == 'atten':\n",
    "            self.att_fc = nn.Linear(hid_dim, 1)\n",
    "            self.out_dim = hid_dim\n",
    "        elif self.att_op == 'mul_head':\n",
    "            self.att_fc = nn.Linear(hid_dim, num_heads)\n",
    "            self.out_dim = hid_dim * num_heads\n",
    "        elif self.att_op == 'concat':\n",
    "            self.out_dim = 2 * hid_dim\n",
    "        else:\n",
    "            self.out_dim = hid_dim\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def normalize_adj(self, adj):\n",
    "        if adj.dim() == 3:            # batched dense\n",
    "            eye = torch.eye(adj.size(-1), device=adj.device)\n",
    "            adj = adj + eye           # 加自环\n",
    "            deg = adj.sum(-1)         # [B,N]\n",
    "            deg_inv_sqrt = (deg + 1e-9).pow(-0.5)   # 避免除零\n",
    "            # 利用广播而不是显式 diag，加速\n",
    "            return deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n",
    "\n",
    "\n",
    "        elif adj.dim() == 2:\n",
    "            N = adj.size(0)\n",
    "            eye = torch.eye(N, device=adj.device, dtype=adj.dtype)\n",
    "            adj = adj + eye\n",
    "            deg = adj.sum(dim=1)                      \n",
    "            deg_inv_sqrt = (deg + 1e-9).pow(-0.5)    \n",
    "            return deg_inv_sqrt.unsqueeze(1) * adj * deg_inv_sqrt.unsqueeze(0)\n",
    "\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported adj dimension: {adj.dim()}\")\n",
    "\n",
    "    def grand_conv(self, X, adj_norm):\n",
    "        X_agg = X.clone()\n",
    "        for _ in range(self.K):\n",
    "            X = adj_norm @ X\n",
    "            X_agg += X\n",
    "        return X_agg / (self.K + 1)\n",
    "\n",
    "    def gate_fusion(self, grand_feats, ggnn_feats):\n",
    "        \"\"\"Gated fusion mechanism combining GRAND and Gated GNN features\"\"\"\n",
    "        combined = torch.cat([grand_feats, ggnn_feats], dim=-1)\n",
    "        \n",
    "        # Gating mechanisms\n",
    "        reset = torch.sigmoid(self.reset_gate(combined))\n",
    "        update = torch.sigmoid(self.update_gate(combined))\n",
    "        \n",
    "        # Intermediate fusion state\n",
    "        intermediate = torch.tanh(self.fusion_gate(torch.cat([grand_feats, reset * ggnn_feats], dim=-1)))\n",
    "        \n",
    "        # Final fused output\n",
    "        fused_output = update * ggnn_feats + (1 - update) * intermediate\n",
    "        \n",
    "        # Output gate\n",
    "        output_gate = torch.sigmoid(self.output_gate(combined))\n",
    "        return output_gate * fused_output + (1 - output_gate) * grand_feats\n",
    "\n",
    "    def aggregate(self, x, mask=None):\n",
    "        \"\"\"Aggregate node features into graph-level embeddings\"\"\"\n",
    "        x_sum = torch.sum(x, dim=1, keepdim=True)\n",
    "        x_max = torch.amax(x, dim=1, keepdim=True)\n",
    "        x_mean = torch.mean(x, dim=1, keepdim=True)\n",
    "        \n",
    "        if self.att_op == 'sum':\n",
    "            return (x_sum + x_max).squeeze(1)\n",
    "        elif self.att_op == 'max+mean':\n",
    "            return (x_mean + x_max).squeeze(1)\n",
    "        elif self.att_op == 'concat':\n",
    "            return torch.cat((x_sum, x_max), dim=2).squeeze(1)\n",
    "        elif self.att_op == 'atten':            # 单头注意力\n",
    "            scores = self.att_fc(x).squeeze(-1)         # [B, N]\n",
    "            if mask is not None:\n",
    "                scores = scores.masked_fill(mask == 0, -1e9)\n",
    "            alpha = torch.softmax(scores, dim=1).unsqueeze(-1)\n",
    "            return (alpha * x).sum(dim=1)\n",
    "        elif self.att_op == 'mul_head':         # 多头注意力\n",
    "            scores = self.att_fc(x)                       # [B, N, H]\n",
    "            if mask is not None:\n",
    "                scores = scores.masked_fill(mask.unsqueeze(-1) == 0, -1e9)  \n",
    "            alpha = torch.softmax(scores, dim=1)\n",
    "            z_heads = (alpha.unsqueeze(-1) * x.unsqueeze(2)).sum(dim=1)\n",
    "            return z_heads.reshape(x.size(0), -1)\n",
    "        else:\n",
    "            # multiply\n",
    "            return (x_sum * x_max).squeeze(1)\n",
    "\n",
    "    def forward(self, inputs, adj, mask=None, seed=None):\n",
    "        inputs = inputs\n",
    "        adj = adj\n",
    "        mask = mask if mask is not None else None\n",
    "        \n",
    "        # Precompute Gated GNN features (only once)\n",
    "        ggnn_feats = self.gggnn(inputs, adj, mask) if mask is not None else self.gggnn(inputs, adj, torch.ones_like(inputs[:, :, 0]))\n",
    "        \n",
    "        if self.training:\n",
    "            emb_list = [] \n",
    "            enhanced_outputs = []\n",
    "            adj_norm = self.normalize_adj(adj)\n",
    "            \n",
    "            for i in range(self.S):\n",
    "                # GRAND feature propagation with node dropout\n",
    "                grand_inputs = drop_node(inputs, self.node_dropout_rate, True, seed=int(int(seed)*10+i))\n",
    "                grand_prop = torch.stack([self.grand_conv(grand_inputs[b], adj_norm[b]) for b in range(grand_inputs.size(0))])\n",
    "                \n",
    "                # Pass through GRAND's MLP\n",
    "                grand_mlp_out = self.grand_mlp(grand_prop.view(-1, grand_prop.size(-1)))\n",
    "                grand_feats = grand_mlp_out.view(inputs.size(0), -1, grand_mlp_out.size(-1))\n",
    "                \n",
    "                # Gated fusion of GRAND and Gated GNN features\n",
    "                fused_feats = self.gate_fusion(grand_feats, ggnn_feats)\n",
    "                \n",
    "                # Apply mask if provided\n",
    "                if mask is not None:\n",
    "                    fused_feats = fused_feats * mask.unsqueeze(-1)\n",
    "                \n",
    "                # Aggregate to graph-level\n",
    "                graph_emb = self.aggregate(fused_feats, mask)\n",
    "                emb_list.append(graph_emb) \n",
    "                enhanced_outputs.append(graph_emb)\n",
    "            \n",
    "            # Compute consistency loss\n",
    "            # ps = [torch.softmax(output, dim=-1) for output in enhanced_outputs]\n",
    "            # avg_p = torch.mean(torch.stack(ps, dim=0), dim=0)\n",
    "            # sharp_p = (torch.pow(avg_p, 1./self.temp) / \n",
    "            #           torch.sum(torch.pow(avg_p, 1./self.temp), dim=-1, keepdim=True)).detach()\n",
    "            \n",
    "            # consistency_loss = sum(torch.mean((p - sharp_p).pow(2).sum(dim=-1)) for p in ps) / len(ps)\n",
    "            \n",
    "            # Return mean graph embedding and consistency loss\n",
    "            # return torch.mean(torch.stack(enhanced_outputs, dim=0), dim=0), consistency_loss\n",
    "\n",
    "            return torch.stack(emb_list, dim=0), None\n",
    "        \n",
    "        \n",
    "        else:  # Inference mode\n",
    "            # GRAND feature propagation without dropout\n",
    "            adj_norm = self.normalize_adj(adj)\n",
    "            grand_prop = torch.stack([self.grand_conv(inputs[b], adj_norm[b]) for b in range(inputs.size(0))])\n",
    "            \n",
    "            # Pass through GRAND's MLP\n",
    "            grand_mlp_out = self.grand_mlp(grand_prop.view(-1, grand_prop.size(-1)))\n",
    "            grand_feats = grand_mlp_out.view(inputs.size(0), -1, grand_mlp_out.size(-1))\n",
    "            \n",
    "            # Gated fusion\n",
    "            fused_feats = self.gate_fusion(grand_feats, ggnn_feats)\n",
    "            \n",
    "            # Apply mask if provided\n",
    "            if mask is not None:\n",
    "                fused_feats = fused_feats * mask.unsqueeze(-1)\n",
    "            \n",
    "            # Aggregate to graph-level\n",
    "            graph_emb = self.aggregate(fused_feats, mask)\n",
    "            return graph_emb, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn, torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, base_cfg, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = GRAND_GatedFusion(**base_cfg).float()\n",
    "        self.classifier = nn.Linear(self.encoder.out_dim, num_classes)\n",
    "        # self.classifier = nn.Linear(base_cfg['hid_dim']*base_cfg['num_heads'],  # out_dim\n",
    "        #                             num_classes)\n",
    "\n",
    "    def forward(self, x, adj, mask, seed=None, train_consistency=True):\n",
    "        if self.training and train_consistency:\n",
    "            # ---------- (1) 取 [S, B, D] ----------\n",
    "            emb_stack, _ = self.encoder(x, adj, mask, seed=seed)\n",
    "\n",
    "            # ---------- (2) 得到 [S, B, C] ----------\n",
    "            logits_stack = self.classifier(emb_stack)\n",
    "\n",
    "            # ---------- (3) 计算 Sharpen consistency ----------\n",
    "            ps = torch.softmax(logits_stack, dim=-1)       # [S,B,C]\n",
    "            avg_p = ps.mean(dim=0)                         # [B,C]\n",
    "\n",
    "            temp = self.encoder.temp                       # 与 cfg 保持一致\n",
    "            sharp_p = (avg_p.pow(1. / temp) /\n",
    "                    avg_p.pow(1. / temp).sum(dim=-1, keepdim=True)).detach()\n",
    "\n",
    "            consistency = ((ps - sharp_p) ** 2).sum(-1).mean()\n",
    "\n",
    "            # ---------- (4) 把 S 个 logits 取平均做分类 ----------\n",
    "            logits = logits_stack.mean(dim=0)              # [B,C]\n",
    "\n",
    "        else:                                              # Eval 或关闭一致性\n",
    "            emb, _ = self.encoder(x, adj, mask)\n",
    "            logits = self.classifier(emb)\n",
    "            consistency = torch.tensor(0., device=logits.device)\n",
    "\n",
    "        return logits, consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: http_proxy=http://10.254.25.18:7890\n",
      "env: https_proxy=http://10.254.25.18:7890\n",
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json, re, os, random\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from transformers import (RobertaForSequenceClassification, AutoTokenizer)\n",
    "# Jupyter Cell 2\n",
    "def clean_code(code: str) -> str:\n",
    "    \"\"\"去单/多行注释 + 空行\"\"\"\n",
    "    code = re.sub(r\"//.*?$\",     \"\", code, flags=re.MULTILINE)\n",
    "    code = re.sub(r\"/\\*.*?\\*/\",  \"\", code, flags=re.DOTALL)\n",
    "    code = re.sub(r\"^\\s*$\\n?\",   \"\", code, flags=re.MULTILINE)\n",
    "    return code.strip()\n",
    "\n",
    "@dataclass\n",
    "class InputFeatures:\n",
    "    input_ids:  List[int]\n",
    "    attention_mask: List[int]\n",
    "    label: int\n",
    "\n",
    "def convert_example(js, tokenizer, block_size):\n",
    "    code = ' '.join(clean_code(js['functionSource']).split())\n",
    "    tokens = tokenizer.tokenize(code)[: block_size - 2]\n",
    "    tokens = [tokenizer.cls_token] + tokens + [tokenizer.sep_token]\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    attn_mask = [1] * len(input_ids)\n",
    "\n",
    "    pad_len = block_size - len(input_ids)\n",
    "    input_ids += [tokenizer.pad_token_id] * pad_len\n",
    "    attn_mask += [0] * pad_len\n",
    "\n",
    "    return InputFeatures(\n",
    "        input_ids      = input_ids,\n",
    "        attention_mask = attn_mask,\n",
    "        label          = int(js['label'])\n",
    "    )\n",
    "%env http_proxy=http://10.254.25.18:7890\n",
    "%env https_proxy=http://10.254.25.18:7890\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using default unweighted graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "att_op_dict = {\n",
    "    'sum': 'sum',\n",
    "    'mul': 'mul',\n",
    "    'concat': 'concat'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "weighted_graph = False\n",
    "print('using default unweighted graph')\n",
    "\n",
    "TF_IDF = True\n",
    "PMI =True\n",
    "\n",
    "from transformers import RobertaTokenizer  # 确保导入tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('microsoft/graphcodebert-base')\n",
    "from collections import Counter\n",
    "\n",
    "def collect_global_stats(shuffle_doc_words_list, window_size=3):\n",
    "    token_freq  = Counter()      # P(w)\n",
    "    pair_freq   = Counter()      # P(w_i, w_j) 共现\n",
    "    total_windows = 0\n",
    "\n",
    "    for doc in shuffle_doc_words_list:\n",
    "        end = len(doc)\n",
    "        while end > 0 and doc[end-1] in {1, 2}:\n",
    "            end -= 1\n",
    "        doc = doc[:end]\n",
    "\n",
    "        # 更新 token 出现次数\n",
    "        token_freq.update(doc)\n",
    "\n",
    "        # 遍历窗口统计共现\n",
    "        if len(doc) <= window_size:\n",
    "            windows = [doc]\n",
    "        else:\n",
    "            windows = [doc[i:i+window_size] for i in range(len(doc)-window_size+1)]\n",
    "\n",
    "        for win in windows:\n",
    "            total_windows += 1\n",
    "            for i in range(1, len(win)):\n",
    "                for j in range(0, i):\n",
    "                    u, v = win[i], win[j]\n",
    "                    if u == v: \n",
    "                        continue\n",
    "                    pair_freq[(u, v)] += 1\n",
    "                    pair_freq[(v, u)] += 1   # 无向\n",
    "    return token_freq, pair_freq, total_windows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_graph(shuffle_doc_words_list, word_embeddings, window_size=3, weighted_graph=True,TF_IDF=False, PMI=False):\n",
    "    if TF_IDF:\n",
    "        token_freq, pair_freq, W = collect_global_stats(shuffle_doc_words_list, window_size=window_size)\n",
    "        def pmi(u, v, W, eps=1e-9):\n",
    "            # 频数 → 概率\n",
    "            p_uv = pair_freq[(u, v)] / W\n",
    "            p_u  = token_freq[u] / W\n",
    "            p_v  = token_freq[v] / W\n",
    "            val = np.log((p_uv + eps) / (p_u * p_v + eps))\n",
    "            return max(val, 0.)          # 常见做法：负 PMI 设 0（稀疏化）\n",
    "        \n",
    "\n",
    "    x_adj = []\n",
    "    x_feature = []\n",
    "    doc_len_list = []\n",
    "    vocab_set = set()\n",
    "\n",
    "    # 确保 word_embeddings 是 NumPy 数组\n",
    "    if isinstance(word_embeddings, torch.Tensor):\n",
    "        embeddings_np = word_embeddings.cpu().numpy()\n",
    "    else:\n",
    "        embeddings_np = word_embeddings\n",
    "\n",
    "    for i in range(len(shuffle_doc_words_list)):\n",
    "        doc_words = shuffle_doc_words_list[i]\n",
    "        end = len(doc_words)\n",
    "        while end > 0 and doc_words[end-1] in {1, 2}:  # 移除padding\n",
    "            end -= 1\n",
    "        doc_words = doc_words[:end]\n",
    "        doc_len = len(doc_words)\n",
    "\n",
    "        # 获取token字符串表示\n",
    "        tokens_str = tokenizer.convert_ids_to_tokens(doc_words)\n",
    "        \n",
    "        doc_vocab = list(set(doc_words))\n",
    "        doc_nodes = len(doc_vocab)\n",
    "\n",
    "        doc_len_list.append(doc_nodes)\n",
    "        vocab_set.update(doc_vocab)\n",
    "\n",
    "        doc_word_id_map = {}\n",
    "        for j in range(doc_nodes):\n",
    "            doc_word_id_map[doc_vocab[j]] = j\n",
    "\n",
    "        # 使用defaultdict简化边计数\n",
    "        word_pair_count = defaultdict(float)\n",
    "\n",
    "        # 1. 添加滑动窗口共现边\n",
    "        windows = []\n",
    "        if doc_len <= window_size:\n",
    "            windows.append(doc_words)\n",
    "        else:\n",
    "            for j in range(doc_len - window_size + 1):\n",
    "                window = doc_words[j: j + window_size]\n",
    "                windows.append(window)\n",
    "\n",
    "        for window in windows:\n",
    "            for p in range(1, len(window)):\n",
    "                for q in range(0, p):\n",
    "                    word_p_id = window[p]\n",
    "                    word_q_id = window[q]\n",
    "                    if word_p_id == word_q_id:\n",
    "                        continue\n",
    "                    # 共现边（双向添加）\n",
    "                    word_pair_count[(word_p_id, word_q_id)] += 1.0\n",
    "                    word_pair_count[(word_q_id, word_p_id)] += 1.0\n",
    "\n",
    "        # 2. 添加基本的数据流边（基于常见代码模式）\n",
    "        for pos in range(1, doc_len):\n",
    "            current_token = doc_words[pos]\n",
    "            prev_token = doc_words[pos-1]\n",
    "            current_token_str = tokens_str[pos]\n",
    "            \n",
    "            # 模式1: 赋值语句 (a = b)\n",
    "            # 处理带空格的等号 (Ġ=) 和普通等号 (=)\n",
    "            if current_token_str in [\"=\", \"Ġ=\"] and pos > 0 and pos < doc_len - 1:\n",
    "                # 连接左侧变量和右侧表达式\n",
    "                if pos >= 1 and pos < doc_len - 1:\n",
    "                    left_var = doc_words[pos-1]\n",
    "                    right_expr = doc_words[pos+1]\n",
    "                    word_pair_count[(left_var, right_expr)] += 2.0\n",
    "                    word_pair_count[(right_expr, left_var)] += 2.0\n",
    "            \n",
    "            # 模式2: 方法调用 (obj.method())\n",
    "            # 处理带空格的点 (Ġ.) 和普通点 (.)\n",
    "            if current_token_str in [\".\", \"Ġ.\"] and pos > 0 and pos < doc_len - 1:\n",
    "                # 连接对象和方法名\n",
    "                if pos >= 1 and pos < doc_len - 1:\n",
    "                    obj = doc_words[pos-1]\n",
    "                    method = doc_words[pos+1]\n",
    "                    word_pair_count[(obj, method)] += 1.5\n",
    "                    word_pair_count[(method, obj)] += 1.5\n",
    "            \n",
    "            # 模式3: 函数参数 (func(a, b))\n",
    "            # 处理带空格的开括号 (Ġ() 和普通开括号 (()\n",
    "            if current_token_str in [\"(\", \"Ġ(\"] and pos > 0:\n",
    "                # 连接函数名和参数\n",
    "                func_name = doc_words[pos-1]\n",
    "                # 添加函数名到下一个token的边\n",
    "                if pos < doc_len - 1:\n",
    "                    first_param = doc_words[pos+1]\n",
    "                    word_pair_count[(func_name, first_param)] += 1.2\n",
    "                    word_pair_count[(first_param, func_name)] += 1.2\n",
    "                # 添加函数名到所有后续参数\n",
    "                param_pos = pos + 1\n",
    "                # 处理带空格的闭括号 (Ġ)) 和普通闭括号 ())\n",
    "                while param_pos < doc_len and tokens_str[param_pos] not in [\")\", \"Ġ)\"]:\n",
    "                    if tokens_str[param_pos] not in [\",\", \"Ġ,\", \";\", \"Ġ;\"]:\n",
    "                        param_token = doc_words[param_pos]\n",
    "                        word_pair_count[(func_name, param_token)] += 0.8\n",
    "                        word_pair_count[(param_token, func_name)] += 0.8\n",
    "                    param_pos += 1\n",
    "            \n",
    "            # 模式4: 返回值 (return x)\n",
    "            # 检查带空格的return (Ġreturn) 和普通return (return)\n",
    "            if tokens_str[pos-1] in [\"return\", \"Ġreturn\"] and pos > 1:\n",
    "                return_value = current_token\n",
    "                word_pair_count[(prev_token, return_value)] += 1.3\n",
    "                word_pair_count[(return_value, prev_token)] += 1.3\n",
    "\n",
    "        # 3. 添加子词连接边（处理长变量名）\n",
    "        current_var_tokens = []  # 当前变量名的token序列\n",
    "        \n",
    "        for pos in range(doc_len):\n",
    "            token_id = doc_words[pos]\n",
    "            token_str = tokens_str[pos]\n",
    "            \n",
    "            # 检查是否是变量名的开始或延续\n",
    "            if token_str.startswith(\"Ġ\") or not current_var_tokens:\n",
    "                # 新token开始（以空格开头或当前序列为空）\n",
    "                if current_var_tokens:\n",
    "                    # 连接当前变量名的所有token\n",
    "                    for idx in range(1, len(current_var_tokens)):\n",
    "                        prev_id = current_var_tokens[idx-1]\n",
    "                        curr_id = current_var_tokens[idx]\n",
    "                        \n",
    "                        # 添加强连接（双向）\n",
    "                        word_pair_count[(prev_id, curr_id)] += 3.0\n",
    "                        word_pair_count[(curr_id, prev_id)] += 3.0\n",
    "                \n",
    "                # 重置当前变量名（跳过特殊token和运算符）\n",
    "                # 只将标识符加入变量名序列\n",
    "                if token_str not in [\"[CLS]\", \"[SEP]\", \"[PAD]\", \"(\", \")\", \"{\", \"}\", \"=\", \".\", \",\", \";\"] \\\n",
    "                   and not token_str.startswith(\"Ġ(\") \\\n",
    "                   and not token_str.startswith(\"Ġ)\") \\\n",
    "                   and not token_str.startswith(\"Ġ{\") \\\n",
    "                   and not token_str.startswith(\"Ġ}\") \\\n",
    "                   and not token_str.startswith(\"Ġ=\") \\\n",
    "                   and not token_str.startswith(\"Ġ.\") \\\n",
    "                   and not token_str.startswith(\"Ġ,\") \\\n",
    "                   and not token_str.startswith(\"Ġ;\"):\n",
    "                    current_var_tokens = [token_id]\n",
    "                else:\n",
    "                    current_var_tokens = []\n",
    "            elif token_str.startswith(\"##\") or token_str.isalnum() or '_' in token_str:\n",
    "                # 变量名延续（子词token或标识符）\n",
    "                current_var_tokens.append(token_id)\n",
    "            else:\n",
    "                # 其他token（标点、关键字等）\n",
    "                if current_var_tokens:\n",
    "                    # 连接当前变量名的所有token\n",
    "                    for idx in range(1, len(current_var_tokens)):\n",
    "                        prev_id = current_var_tokens[idx-1]\n",
    "                        curr_id = current_var_tokens[idx]\n",
    "                        \n",
    "                        word_pair_count[(prev_id, curr_id)] += 3.0\n",
    "                        word_pair_count[(curr_id, prev_id)] += 3.0\n",
    "                current_var_tokens = []\n",
    "        \n",
    "        # 处理文档末尾的变量名\n",
    "        if current_var_tokens:\n",
    "            for idx in range(1, len(current_var_tokens)):\n",
    "                prev_id = current_var_tokens[idx-1]\n",
    "                curr_id = current_var_tokens[idx]\n",
    "                \n",
    "                word_pair_count[(prev_id, curr_id)] += 3.0\n",
    "                word_pair_count[(curr_id, prev_id)] += 3.0\n",
    "\n",
    "        # 构建邻接矩阵\n",
    "        row, col, weight = [], [], []\n",
    "        for (u, v), w in word_pair_count.items():\n",
    "            if u in doc_word_id_map and v in doc_word_id_map:\n",
    "                row.append(doc_word_id_map[u])\n",
    "                col.append(doc_word_id_map[v])\n",
    "                if TF_IDF:\n",
    "                    weight.append(pmi(u, v, W))\n",
    "                else:\n",
    "                    weight.append(w if weighted_graph else 1.0)\n",
    "        \n",
    "        adj = sp.csr_matrix((weight, (row, col)), shape=(doc_nodes, doc_nodes))\n",
    "        x_adj.append(adj)\n",
    "\n",
    "        # 构建节点特征\n",
    "        features = []\n",
    "        for word_id in doc_vocab:\n",
    "            # 确保 word_id 是整数\n",
    "            word_id = int(word_id)\n",
    "            \n",
    "            # 检查索引是否在嵌入矩阵范围内\n",
    "            if word_id < embeddings_np.shape[0]:\n",
    "                features.append(embeddings_np[word_id])\n",
    "            else:\n",
    "                # 处理超出范围的索引 - 使用零向量\n",
    "                features.append(np.zeros(embeddings_np.shape[1]))\n",
    "        \n",
    "        x_feature.append(features)\n",
    "\n",
    "    return x_adj, x_feature\n",
    "\n",
    "class JsonlCodeDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, block_size=512, sample_percent=1.0):\n",
    "        self.features = []\n",
    "        with open(file_path) as f:\n",
    "            total = sum(1 for _ in f)\n",
    "        with open(file_path) as f:\n",
    "            for line in tqdm(f, total=total, desc=\"Building dataset\"):\n",
    "                js = json.loads(line)\n",
    "                feat = convert_example(js, tokenizer, block_size)\n",
    "                self.features.append(feat)\n",
    "\n",
    "        # 采样（可选）\n",
    "        if 0 < sample_percent < 1.0:\n",
    "            random.seed(42)\n",
    "            random.shuffle(self.features)\n",
    "            keep_num = int(sample_percent * len(self.features))\n",
    "            self.features = self.features[:keep_num]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feat = self.features[idx]\n",
    "        return (\n",
    "            torch.tensor(feat.input_ids,      dtype=torch.long),\n",
    "            torch.tensor(feat.attention_mask, dtype=torch.long),\n",
    "            torch.tensor(feat.label,          dtype=torch.long),\n",
    "        )\n",
    "    \n",
    "model = RobertaForSequenceClassification.from_pretrained('microsoft/graphcodebert-base')\n",
    "w_embeddings = model.get_input_embeddings().weight.data.cpu().detach().clone().numpy()\n",
    "def collate_graph(batch, window_size=3):\n",
    "    \"\"\"\n",
    "    batch 由 Dataset 返回的:\n",
    "        input_ids, attn_mask, label\n",
    "    本函数在 CPU 上:\n",
    "        1) 转成 numpy list\n",
    "        2) 调 build_graph\n",
    "        3) 把 scipy csr 转成 PyG/DGL 或留作训练时再转\n",
    "    \"\"\"\n",
    "    ids, masks, labels = zip(*batch)                 # tuple of Tensor\n",
    "    ids_np  = [x.numpy() for x in ids]               # 每条句子 token-id list\n",
    "    labels  = torch.stack(labels)                    # Tensor [B]\n",
    "\n",
    "    # --- 调你的 graph 构造 ---\n",
    "    x_adj, x_feat = build_graph(\n",
    "        shuffle_doc_words_list = ids_np,\n",
    "        word_embeddings        = w_embeddings,\n",
    "        window_size            = window_size,\n",
    "        weighted_graph         = True,\n",
    "        TF_IDF                 = True\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\" : torch.stack(ids),              # [B, L]\n",
    "        \"attention_mask\": torch.stack(masks),        # [B, L]\n",
    "        \"labels\": labels,                            # [B]\n",
    "        \"adjs\":  x_adj,                              # list\n",
    "        \"feats\": x_feat                              # list\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7a28502f6090>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, random, numpy as np, torch\n",
    "seed_number=42\n",
    "def set_global_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)        # Python 层哈希随机\n",
    "    random.seed(seed)                               # 内置 random\n",
    "    np.random.seed(seed)                            # numpy\n",
    "    torch.manual_seed(seed)                         # CPU\n",
    "    torch.cuda.manual_seed(seed)                    # 当前 GPU\n",
    "    torch.cuda.manual_seed_all(seed)                # 所有 GPU\n",
    "\n",
    "    # 额外：在部分算子中强制使用确定性实现\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False          # 禁止自动算法搜索\n",
    "    torch.use_deterministic_algorithms(True)        # ≥1.8，捕获非确定性算子\n",
    "\n",
    "    # CUDA ≥ 10.2：卷积类算子还需要这个环境变量\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "set_global_seed(seed_number)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    # 每个 worker 用不同 seed，但与主进程严格可重复\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building dataset:   0%|          | 0/18187 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 512). Running this sequence through the model will result in indexing errors\n",
      "Building dataset: 100%|██████████| 18187/18187 [00:19<00:00, 922.03it/s] \n",
      "Building dataset: 100%|██████████| 2273/2273 [00:02<00:00, 888.61it/s] \n",
      "Building dataset: 100%|██████████| 2274/2274 [00:02<00:00, 863.04it/s] \n",
      "/home/yt/anaconda3/envs/openr/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 20, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Cell 4\n",
    "# MODEL_NAME = \"Salesforce/codet5-base\"   # 或 graphcodebert-base\n",
    "MODEL_NAME = 'microsoft/graphcodebert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "BLOCK_SIZE = 2048        # <— 最大输入长度\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def filter_by_len(dataset, max_len=512):\n",
    "    filtered = []\n",
    "    for feat in dataset.features:\n",
    "        # 去掉 padding 后的真实长度\n",
    "        real_len = sum(feat.attention_mask)\n",
    "        if real_len < max_len:\n",
    "            filtered.append(feat)\n",
    "    dataset.features = filtered\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_ds = JsonlCodeDataset(\"dataset/reveal/train.jsonl\", tokenizer, block_size=BLOCK_SIZE)\n",
    "val_ds  = JsonlCodeDataset(\"dataset/reveal/valid.jsonl\", tokenizer, block_size=BLOCK_SIZE)\n",
    "test_ds  = JsonlCodeDataset(\"dataset/reveal/test.jsonl\", tokenizer, block_size=BLOCK_SIZE)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    sampler = RandomSampler(train_ds, generator=g), # generator 已锁定\n",
    "    batch_size = BATCH_SIZE,\n",
    "    collate_fn = collate_graph,\n",
    "    num_workers = 32,\n",
    "    pin_memory = True,\n",
    "    persistent_workers=True,\n",
    "    # prefetch_factor=4, \n",
    "    worker_init_fn = seed_worker                 # ★ 加这一行\n",
    ")\n",
    "\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    sampler = RandomSampler(val_ds, replacement=False),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    collate_fn = collate_graph,     # ⭐️ 重点\n",
    "    num_workers = 8,\n",
    "    pin_memory = True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4, \n",
    "    worker_init_fn = seed_worker \n",
    ")\n",
    "\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    sampler = RandomSampler(test_ds, replacement=False),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    collate_fn = collate_graph,     # ⭐️ 重点\n",
    "    num_workers = 8,\n",
    "    pin_memory = True,\n",
    "    worker_init_fn = seed_worker \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Building dataset:   0%|          | 0/18187 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 512). Running this sequence through the model will result in indexing errors\n",
    "# Building dataset: 100%|██████████| 18187/18187 [00:36<00:00, 498.52it/s]\n",
    "# Building dataset: 100%|██████████| 2273/2273 [00:04<00:00, 502.68it/s]\n",
    "# Building dataset: 100%|██████████| 2274/2274 [00:05<00:00, 444.60it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building dataset: 100%|██████████| 2274/2274 [00:03<00:00, 726.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# ---- 工具函数：计算真实长度（去掉 padding）----\n",
    "def real_len_from_mask(attn_mask):\n",
    "    # attn_mask 是 0/1，sum 即为真实长度\n",
    "    if torch.is_tensor(attn_mask):\n",
    "        return int(attn_mask.sum().item())\n",
    "    return int(sum(attn_mask))\n",
    "\n",
    "# ---- 第一步：过滤掉 >8k 的样本（也可设下限 >=3）----\n",
    "def filter_by_len(dataset, max_len=8192, min_len=3):\n",
    "    filtered = []\n",
    "    for feat in dataset.features:\n",
    "        L = real_len_from_mask(feat.attention_mask)\n",
    "        if min_len <= L <= max_len:\n",
    "            filtered.append(feat)\n",
    "    dataset.features = filtered\n",
    "    return dataset\n",
    "\n",
    "# ---- 第二步：把剩下样本统一截成 2k（包含 [CLS]/[SEP] 与 padding）----\n",
    "def truncate_inplace(dataset, to_len=2048, pad_token_id=1):  # GCBERT: pad_token_id=1\n",
    "    new_feats = []\n",
    "    for feat in dataset.features:\n",
    "        # 先根据 attn_mask 拿真实有效 token（含 [CLS] ... [SEP]）\n",
    "        L = real_len_from_mask(feat.attention_mask)\n",
    "        # 真实 token 截断到 to_len\n",
    "        keep = min(L, to_len)\n",
    "        input_ids = feat.input_ids[:keep]\n",
    "        attn_mask = feat.attention_mask[:keep]\n",
    "\n",
    "        # 末尾补 SEP：如果真实 token 里本就有 SEP 且被截走了，可加一个兜底\n",
    "        # 注意：你的 convert_example 已经在末尾加了 [SEP]，这里通常不必另加\n",
    "        # 仅在极端情况下（比如 L<2）需要修复，但我们上面的 min_len 已经保证 >=3\n",
    "\n",
    "        # padding 到 to_len\n",
    "        pad_needed = to_len - len(input_ids)\n",
    "        if pad_needed > 0:\n",
    "            input_ids = input_ids + [pad_token_id] * pad_needed\n",
    "            attn_mask = attn_mask + [0] * pad_needed\n",
    "        else:\n",
    "            # 完全等长就不补\n",
    "            pass\n",
    "\n",
    "        # 回写\n",
    "        feat.input_ids = input_ids\n",
    "        feat.attention_mask = attn_mask\n",
    "        # feat.label 保持不变\n",
    "        new_feats.append(feat)\n",
    "\n",
    "    dataset.features = new_feats\n",
    "    return dataset\n",
    "# 1) 先用较大的 block_size 读取全长（你已经这样做了）\n",
    "test_ds = JsonlCodeDataset(\"dataset/reveal/test.jsonl\", tokenizer, block_size=1024*8)\n",
    "\n",
    "# 2) 过滤掉 >8k 的样本（也可设下限 >=3，避免太短的无效样本）\n",
    "test_ds = filter_by_len(test_ds, max_len=8190, min_len=3)\n",
    "\n",
    "# 3) 统一把剩余样本截成 2k（GraphCodeBERT 的 pad_token_id=1）\n",
    "test_ds = truncate_inplace(test_ds, to_len=2048, pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "# 4) 之后再建 DataLoader（你的 collate_graph 会基于截后的 tokens 构图）\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    collate_fn = collate_graph,\n",
    "    num_workers = 8,\n",
    "    pin_memory = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss 0.3211 (cls) + 0.0075 (cons)  triain_acc 0.8956 | val_loss 0.2707 acc 0.8742 | P 0.3582 R 0.4571 F1 0.4017\n",
      "💾 Saved new best ckpt: F1=0.4017, acc=0.8742 @ epoch 001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | train_loss 0.2729 (cls) + 0.0079 (cons)  triain_acc 0.9011 | val_loss 0.2566 acc 0.8544 | P 0.3236 R 0.5286 F1 0.4014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | train_loss 0.2525 (cls) + 0.0086 (cons)  triain_acc 0.9038 | val_loss 0.2421 acc 0.8834 | P 0.3970 R 0.5048 F1 0.4444\n",
      "💾 Saved new best ckpt: F1=0.4444, acc=0.8834 @ epoch 003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | train_loss 0.2409 (cls) + 0.0092 (cons)  triain_acc 0.9070 | val_loss 0.2313 acc 0.9067 | P 0.4944 R 0.4238 F1 0.4564\n",
      "💾 Saved new best ckpt: F1=0.4564, acc=0.9067 @ epoch 004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | train_loss 0.2260 (cls) + 0.0099 (cons)  triain_acc 0.9108 | val_loss 0.2255 acc 0.8953 | P 0.4431 R 0.5190 F1 0.4781\n",
      "💾 Saved new best ckpt: F1=0.4781, acc=0.8953 @ epoch 005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | train_loss 0.2172 (cls) + 0.0105 (cons)  triain_acc 0.9141 | val_loss 0.2216 acc 0.9120 | P 0.5301 R 0.4190 F1 0.4681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | train_loss 0.2080 (cls) + 0.0112 (cons)  triain_acc 0.9159 | val_loss 0.3176 acc 0.8619 | P 0.3354 R 0.5048 F1 0.4030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | train_loss 0.2110 (cls) + 0.0120 (cons)  triain_acc 0.9143 | val_loss 0.2107 acc 0.9015 | P 0.4698 R 0.5190 F1 0.4932\n",
      "💾 Saved new best ckpt: F1=0.4932, acc=0.9015 @ epoch 008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | train_loss 0.1990 (cls) + 0.0120 (cons)  triain_acc 0.9177 | val_loss 0.2176 acc 0.9138 | P 0.5402 R 0.4476 F1 0.4896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | train_loss 0.1892 (cls) + 0.0125 (cons)  triain_acc 0.9213 | val_loss 0.2153 acc 0.9023 | P 0.4739 R 0.5190 F1 0.4955\n",
      "💾 Saved new best ckpt: F1=0.4955, acc=0.9023 @ epoch 010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | train_loss 0.1848 (cls) + 0.0127 (cons)  triain_acc 0.9216 | val_loss 0.2077 acc 0.9186 | P 0.5806 R 0.4286 F1 0.4932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | train_loss 0.1803 (cls) + 0.0128 (cons)  triain_acc 0.9224 | val_loss 0.2165 acc 0.9111 | P 0.5222 R 0.4476 F1 0.4821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | train_loss 0.1744 (cls) + 0.0131 (cons)  triain_acc 0.9234 | val_loss 0.2280 acc 0.8979 | P 0.4545 R 0.5238 F1 0.4867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | train_loss 0.1734 (cls) + 0.0135 (cons)  triain_acc 0.9258 | val_loss 0.2279 acc 0.9094 | P 0.5109 R 0.4476 F1 0.4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | train_loss 0.1663 (cls) + 0.0135 (cons)  triain_acc 0.9268 | val_loss 0.2315 acc 0.8909 | P 0.4312 R 0.5667 F1 0.4897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | train_loss 0.1636 (cls) + 0.0139 (cons)  triain_acc 0.9271 | val_loss 0.2281 acc 0.9059 | P 0.4898 R 0.4571 F1 0.4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | train_loss 0.1597 (cls) + 0.0141 (cons)  triain_acc 0.9274 | val_loss 0.2332 acc 0.8852 | P 0.4118 R 0.5667 F1 0.4770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | train_loss 0.1557 (cls) + 0.0143 (cons)  triain_acc 0.9297 | val_loss 0.2262 acc 0.9059 | P 0.4898 R 0.4571 F1 0.4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | train_loss 0.1543 (cls) + 0.0143 (cons)  triain_acc 0.9307 | val_loss 0.2270 acc 0.8931 | P 0.4353 R 0.5286 F1 0.4774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | train_loss 0.1487 (cls) + 0.0147 (cons)  triain_acc 0.9305 | val_loss 0.2272 acc 0.8685 | P 0.3746 R 0.6333 F1 0.4708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | train_loss 0.1439 (cls) + 0.0147 (cons)  triain_acc 0.9319 | val_loss 0.2502 acc 0.8658 | P 0.3691 R 0.6381 F1 0.4677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | train_loss 0.1418 (cls) + 0.0148 (cons)  triain_acc 0.9339 | val_loss 0.2653 acc 0.8627 | P 0.3607 R 0.6286 F1 0.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023 | train_loss 0.1412 (cls) + 0.0150 (cons)  triain_acc 0.9332 | val_loss 0.2589 acc 0.8737 | P 0.3808 R 0.5857 F1 0.4615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 | train_loss 0.1360 (cls) + 0.0153 (cons)  triain_acc 0.9329 | val_loss 0.2698 acc 0.8702 | P 0.3768 R 0.6190 F1 0.4685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | train_loss 0.1339 (cls) + 0.0155 (cons)  triain_acc 0.9365 | val_loss 0.2354 acc 0.8733 | P 0.3892 R 0.6524 F1 0.4875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 026 | train_loss 0.1310 (cls) + 0.0157 (cons)  triain_acc 0.9367 | val_loss 0.2637 acc 0.8557 | P 0.3479 R 0.6429 F1 0.4515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 152\u001b[0m\n\u001b[1;32m    149\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    150\u001b[0m seed   \u001b[38;5;241m=\u001b[39m init_seed \u001b[38;5;241m+\u001b[39m epoch\n\u001b[0;32m--> 152\u001b[0m logits, cons \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaskb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_consistency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m cls_loss \u001b[38;5;241m=\u001b[39m criterion_cls(logits, labels)\n\u001b[1;32m    156\u001b[0m loss \u001b[38;5;241m=\u001b[39m cls_loss \u001b[38;5;241m+\u001b[39m lam \u001b[38;5;241m*\u001b[39m cons\n",
      "File \u001b[0;32m~/anaconda3/envs/openr/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/openr/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x, adj, mask, seed, train_consistency)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, adj, mask, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, train_consistency\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m train_consistency:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# ---------- (1) 取 [S, B, D] ----------\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m         emb_stack, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# ---------- (2) 得到 [S, B, C] ----------\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         logits_stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(emb_stack)\n",
      "File \u001b[0;32m~/anaconda3/envs/openr/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/openr/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[3], line 146\u001b[0m, in \u001b[0;36mGRAND_GatedFusion.forward\u001b[0;34m(self, inputs, adj, mask, seed)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# GRAND feature propagation with node dropout\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     grand_inputs \u001b[38;5;241m=\u001b[39m drop_node(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dropout_rate, \u001b[38;5;28;01mTrue\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mint\u001b[39m(seed)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m+\u001b[39mi))\n\u001b[0;32m--> 146\u001b[0m     grand_prop \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrand_conv(grand_inputs[b], adj_norm[b]) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(grand_inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))])\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# Pass through GRAND's MLP\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     grand_mlp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrand_mlp(grand_prop\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, grand_prop\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "Cell \u001b[0;32mIn[3], line 146\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# GRAND feature propagation with node dropout\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     grand_inputs \u001b[38;5;241m=\u001b[39m drop_node(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dropout_rate, \u001b[38;5;28;01mTrue\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mint\u001b[39m(seed)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m+\u001b[39mi))\n\u001b[0;32m--> 146\u001b[0m     grand_prop \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrand_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrand_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_norm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(grand_inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))])\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# Pass through GRAND's MLP\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     grand_mlp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrand_mlp(grand_prop\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, grand_prop\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "Cell \u001b[0;32mIn[3], line 80\u001b[0m, in \u001b[0;36mGRAND_GatedFusion.grand_conv\u001b[0;34m(self, X, adj_norm)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK):\n\u001b[1;32m     79\u001b[0m     X \u001b[38;5;241m=\u001b[39m adj_norm \u001b[38;5;241m@\u001b[39m X\n\u001b[0;32m---> 80\u001b[0m     X_agg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_agg \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import math, time, random\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "config = {\n",
    "    'in_dim'       : 768,\n",
    "    'hid_dim'      : 128,           \n",
    "    'S'            : 5,\n",
    "    'K'            : 2,\n",
    "    'num_GNN_layers': 2,\n",
    "    'node_dropout' : 0.2,\n",
    "    'input_droprate': 0.3,\n",
    "    'hidden_droprate': 0.3,\n",
    "    'batchnorm'    : True,\n",
    "    'att_op'       : 'mul_head',\n",
    "    'num_heads'    : 6,\n",
    "    'temp'         : 0.6,\n",
    "    'lam'          : 1.4,          \n",
    "    'gnn_dropout'  : 0.2,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "lam = config['lam']\n",
    "\n",
    "model_path= \"best_model-reveal-test-redo-lookfenbu.pt\"\n",
    "\n",
    "\n",
    "# 1. 实例化网络（只一次）\n",
    "net = Net(config, num_classes).to(device)\n",
    "\n",
    "\n",
    "\n",
    "cls_weight = torch.tensor([1.0, 1.0], device=device)  \n",
    "criterion_cls  = nn.CrossEntropyLoss(weight=cls_weight)\n",
    "\n",
    "# 2. 绑定优化器 / 调度器\n",
    "\n",
    "optimizer = AdamW(net.parameters(), lr=5e-4, weight_decay=1e-2)\n",
    "\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "# 3. 训练循环\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "best_val_f1, best_val_acc = 0.0, 0.0\n",
    "best_state, patience, wait = None, 20, 0\n",
    "\n",
    "epochs = 180\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, threshold=0.5):\n",
    "    model.eval()\n",
    "    total_ex, correct, loss_sum = 0, 0, 0.0\n",
    "    all_probs, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            featb, adjb, maskb, labels = batch_to_tensor(batch, device)\n",
    "            logits, _ = model(featb, adjb, maskb, train_consistency=False)\n",
    "            prob_pos = torch.softmax(logits, dim=-1)[:, 1]   # 概率(正类)\n",
    "            loss_sum += criterion_cls(logits, labels).item() * labels.size(0)\n",
    "            all_probs.append(prob_pos.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_score = torch.cat(all_probs).numpy()\n",
    "    y_pred  = (y_score >= threshold).astype(int)\n",
    "\n",
    "    acc  = (y_pred == y_true).mean()\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    loss = loss_sum / len(y_true)\n",
    "    return acc, loss, prec, rec, f1, auc\n",
    "\n",
    "def find_best_threshold(model, dataloader):\n",
    "    model.eval()\n",
    "    all_probs, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            featb, adjb, maskb, labels = batch_to_tensor(batch, device)\n",
    "            logits, _ = model(featb, adjb, maskb, train_consistency=False)\n",
    "            all_probs.append(torch.softmax(logits, dim=-1)[:, 1].cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    y_true  = torch.cat(all_labels).numpy()\n",
    "    y_score = torch.cat(all_probs).numpy()\n",
    "    P, R, T = precision_recall_curve(y_true, y_score)\n",
    "    F1 = 2 * P * R / (P + R + 1e-12)\n",
    "    # precision_recall_curve 返回的 T 比 P/R 少一个元素，做对齐：\n",
    "    best_idx = int(np.nanargmax(F1))\n",
    "    best_thr = T[max(best_idx - 1, 0)] if best_idx > 0 else 0.0\n",
    "    return float(best_thr), float(F1[best_idx])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def batch_to_tensor(batch, device):\n",
    "    \"\"\"把 collate_graph 返回的 dict ⇢ (feat, adj, mask, label) 四张量\"\"\"\n",
    "    # 节点特征\n",
    "    feats_list = batch[\"feats\"]\n",
    "    adjs_list  = batch[\"adjs\"]\n",
    "    labels     = batch[\"labels\"].to(device)\n",
    "\n",
    "    N_max = max(a.shape[0] for a in adjs_list)\n",
    "    dim   = len(feats_list[0][0])           # 768\n",
    "\n",
    "    # 统一 Padding\n",
    "    featb = torch.zeros(len(feats_list), N_max, dim,  dtype=torch.float32, device=device)\n",
    "    adjb  = torch.zeros(len(adjs_list),  N_max, N_max, dtype=torch.float32, device=device)\n",
    "    maskb = torch.zeros(len(adjs_list),  N_max,        dtype=torch.float32, device=device)\n",
    "\n",
    "    for i, (adj, feat) in enumerate(zip(adjs_list, feats_list)):\n",
    "        n = adj.shape[0]\n",
    "        adjb [i, :n, :n] = torch.from_numpy(adj.toarray()).to(device)\n",
    "        featb[i, :n, :]  = torch.from_numpy(np.asarray(feat)).to(device)\n",
    "        maskb[i, :n]     = 1.\n",
    "\n",
    "    return featb, adjb, maskb, labels\n",
    "\n",
    "\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "wait = 0\n",
    "init_seed=42\n",
    "epoch = 0\n",
    "while True:\n",
    "    epoch+=1\n",
    "\n",
    "    # ===== Train =====\n",
    "    net.train()\n",
    "    tr_loss_sum, cons_loss_sum, tr_correct, tr_ex = 0.0, 0.0, 0, 0\n",
    "    bar = tqdm(train_loader, desc=f\"Train Ep{epoch:03d}\", leave=False)\n",
    "\n",
    "    for batch in bar:\n",
    "        featb, adjb, maskb, labels = batch_to_tensor(batch, device)\n",
    "        bs = labels.size(0)               \n",
    "        optimizer.zero_grad()\n",
    "        seed   = init_seed + epoch\n",
    "\n",
    "        logits, cons = net(featb, adjb, maskb, seed=seed, train_consistency=True)\n",
    "\n",
    "        cls_loss = criterion_cls(logits, labels)\n",
    "        \n",
    "        loss = cls_loss + lam * cons\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        tr_loss_sum += cls_loss.item() * bs\n",
    "        cons_loss_sum += cons.item() * bs\n",
    "        tr_correct  += (logits.argmax(1) == labels).sum().item()\n",
    "        tr_ex       += bs\n",
    "        bar.set_postfix(cls_loss=f\"{cls_loss.item() / bs:.4f}\", cons_loss=f\"{cons.item() / bs:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    train_loss = tr_loss_sum / tr_ex\n",
    "    train_cons_loss = cons_loss_sum / tr_ex\n",
    "    train_acc  = tr_correct  / tr_ex\n",
    "\n",
    "\n",
    "    # ===== Validate =====\n",
    "    net.eval()\n",
    "    val_loss_sum, val_correct, val_ex = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bar = tqdm(val_loader, desc=f\"Val Ep{epoch:03d}\", leave=False)\n",
    "        for batch in bar:\n",
    "            featb, adjb, maskb, labels = batch_to_tensor(batch, device)\n",
    "            logits, _ = net(featb, adjb, maskb, train_consistency=False)\n",
    "\n",
    "            bs = labels.size(0)\n",
    "            val_loss_sum += criterion_cls(logits, labels).item() * bs\n",
    "            preds = logits.argmax(1)\n",
    "\n",
    "            val_correct  += (preds == labels).sum().item()\n",
    "            val_ex       += bs\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    # 拼接所有 batch 结果\n",
    "    all_preds  = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    best_thr, _ = find_best_threshold(net, val_loader)\n",
    "    val_acc, val_loss, prec, rec, f1, auc = evaluate(net, val_loader, threshold=best_thr)\n",
    "\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    # ===== Log =====\n",
    "\n",
    "    tqdm.write(\n",
    "        f\"Epoch {epoch:03d} | \"\n",
    "        f\"train_loss {train_loss:.4f} (cls) + {train_cons_loss:.4f} (cons)  \"\n",
    "        f\"triain_acc {train_acc:.4f} | \"\n",
    "        f\"val_loss {val_loss:.4f} acc {val_acc:.4f} | \"\n",
    "        f\"P {prec:.4f} R {rec:.4f} F1 {f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    # ===== Early-stopping =====\n",
    "\n",
    "    improved = (f1 > best_val_f1 + 1e-6) or (abs(f1 - best_val_f1) <= 1e-6 and val_acc > best_val_acc)\n",
    "\n",
    "    if improved:\n",
    "        best_threshold = best_thr if improved else best_threshold\n",
    "        best_val_f1 = f1\n",
    "        best_val_acc = val_acc\n",
    "        best_state   = net.state_dict()\n",
    "        torch.save(net.state_dict(), model_path)\n",
    "        wait = 0\n",
    "        tqdm.write(f\"💾 Saved new best ckpt: F1={best_val_f1:.4f}, acc={best_val_acc:.4f} @ epoch {epoch:03d}\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            tqdm.write(f\"Early stop at epoch {epoch} | best F1={best_val_f1:.4f}, best acc={best_val_acc:.4f}\")\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_r = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "def to_float(x):\n",
    "    if torch.is_tensor(x):\n",
    "        return x.detach().cpu().item()\n",
    "    return float(x)\n",
    "\n",
    "val_vals   = [to_float(v) for v in val_losses]\n",
    "train_vals = [to_float(v) for v in train_losses]\n",
    "\n",
    "plt.plot(epochs_r, val_vals,   label='Val loss')\n",
    "plt.plot(epochs_r, train_vals, label='Train loss')\n",
    "\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training vs Validation loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs_r, train_accs, label='Train acc')\n",
    "plt.plot(epochs_r, val_accs,  label='Val acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training vs Validation accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "VAL   | loss   0.2164 | acc 0.9045 | P 0.4848 | R 0.5333 | F1 0.5079| AUC 0.8760\n",
      "TEST  | loss   0.2436 | acc 0.8953 | P 0.4820 | R 0.4652 | F1 0.4735| AUC 0.8438\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "# === 重新实例化网络，与训练时配置保持一致 ===\n",
    "best_net = Net(config, num_classes).to(device)\n",
    "\n",
    "# === 加载参数 ===\n",
    "best_net.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "best_net.eval()      # 切到推理模式（BN/Dropout 会自动关闭）\n",
    "\n",
    "\n",
    "\n",
    "def pretty_print(split_name, metrics):\n",
    "    acc, loss, prec, rec, f1, auc= metrics\n",
    "    print(\n",
    "        f\"{split_name:<5} | \"\n",
    "        f\"loss {loss:8.4f} | \"\n",
    "        f\"acc {acc:6.4f} | \"\n",
    "        f\"P {prec:6.4f} | \"\n",
    "        f\"R {rec:6.4f} | \"\n",
    "        f\"F1 {f1:6.4f}| \"\n",
    "        f\"AUC {auc:6.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 评估\n",
    "val_metrics  = evaluate(best_net, val_loader, threshold=best_threshold)\n",
    "test_metrics = evaluate(best_net, test_loader, threshold=best_threshold)\n",
    "\n",
    "# 打印\n",
    "print(\"=\"*55)\n",
    "pretty_print(\"VAL\",  val_metrics)\n",
    "pretty_print(\"TEST\", test_metrics)\n",
    "print(\"=\"*55)\n",
    "# =======================================================\n",
    "# VAL   | loss   0.2343 | acc 0.9023 | P 0.4725 | R 0.4905 | F1 0.4813| AUC 0.8700\n",
    "# TEST  | loss   0.2534 | acc 0.9063 | P 0.5470 | R 0.4304 | F1 0.4818| AUC 0.8476\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "—— TEST ——\n",
      "(0-512]    样本1756 | ACC  92.37% | P  48.15% | R  40.00% | F1  43.70% | AUC 0.8427\n",
      "(512-1k]   样本 285 | ACC  85.26% | P  44.68% | R  56.76% | F1  50.00% | AUC 0.8130\n",
      "(1k-2k]    样本 146 | ACC  73.97% | P  47.83% | R  61.11% | F1  53.66% | AUC 0.7376\n",
      "(2k-8k]    样本  75 | ACC  65.33% | P  40.91% | R  40.91% | F1  40.91% | AUC 0.6741\n",
      "(8k-inf]   样本   0 | ACC   0.00% | P   0.00% | R   0.00% | F1   0.00% | AUC 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "# === 重新实例化网络，与训练时配置保持一致 ===\n",
    "best_net = Net(config, num_classes).to(device)\n",
    "\n",
    "# === 加载参数 ===\n",
    "best_net.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "best_net.eval()      # 切到推理模式（BN/Dropout 会自动关闭）\n",
    "\n",
    "\n",
    "\n",
    "# —— 1. 设定长度分箱 ——（可自行调整）\n",
    "length_bins = {\n",
    "    \"(0-512]\"  : (1,   512),\n",
    "    \"(512-1k]\" : (513, 1023),\n",
    "    \"(1k-2k]\"  : (1024,2044),\n",
    "    \"(2k-8k]\"  : (2045,8191),\n",
    "    \"(8k-inf]\" : (8192,99999999),\n",
    "}\n",
    "\n",
    "def bucket_metrics(model, dataloader, bins=length_bins, device='cpu', threshold=0.5):\n",
    "    \"\"\"\n",
    "    逐区间统计 acc / precision / recall / f1 / auc。\n",
    "    返回 dict: {bucket_name: {'acc':…, 'pre':…, 'rec':…, 'f1':…, 'auc':…, 'total':…}}\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    from collections import defaultdict\n",
    "    stats = {b: defaultdict(list) for b in bins}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            featb, adjb, maskb, labels = batch_to_tensor(batch, device)\n",
    "            logits, _ = model(featb, adjb, maskb, train_consistency=False)\n",
    "\n",
    "            # === 概率 ===\n",
    "            probs = torch.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
    "            # === 基于阈值的预测 ===\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "\n",
    "            labels_np = labels.cpu().numpy()\n",
    "            lengths = batch[\"attention_mask\"].sum(dim=1).tolist()\n",
    "\n",
    "            for y, p, prob, L in zip(labels_np, preds, probs, lengths):\n",
    "                for bname, (lo, hi) in bins.items():\n",
    "                    if lo <= L <= hi:\n",
    "                        stats[bname]['y_true'].append(y)\n",
    "                        stats[bname]['y_pred'].append(p)\n",
    "                        stats[bname]['y_prob'].append(prob)\n",
    "\n",
    "    results = {}\n",
    "    for bname, d in stats.items():\n",
    "        y_true = np.array(d['y_true'])\n",
    "        y_pred = np.array(d['y_pred'])\n",
    "        y_prob = np.array(d['y_prob'])\n",
    "        total  = len(y_true)\n",
    "\n",
    "        if total == 0:\n",
    "            results[bname] = dict(acc=0, pre=0, rec=0, f1=0, auc=0, total=0)\n",
    "            continue\n",
    "\n",
    "        acc  = (y_true == y_pred).mean()\n",
    "        pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average='binary', zero_division=0)\n",
    "\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_prob)\n",
    "        except ValueError:\n",
    "            auc = 0.0\n",
    "\n",
    "        results[bname] = dict(acc=acc, pre=pre, rec=rec, f1=f1, auc=auc, total=total)\n",
    "    return results\n",
    "# —— 2. 调用示例 ——\n",
    "for name, loader in [(\"TEST\", test_loader)]:\n",
    "    metrics = bucket_metrics(best_net, loader, device=device, threshold=best_threshold)\n",
    "    print(f\"\\n—— {name} ——\")\n",
    "    for b, m in metrics.items():\n",
    "        print(f\"{b:<10} 样本{m['total']:4d} | \"\n",
    "              f\"ACC {m['acc']*100:6.2f}% | \"\n",
    "              f\"P {m['pre']*100:6.2f}% | R {m['rec']*100:6.2f}% | \"\n",
    "              f\"F1 {m['f1']*100:6.2f}% | AUC {m['auc']:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# —— TEST ——\n",
    "# (0-512]    样本1860 | ACC  67.31% | P  64.62% | R  60.29% | F1  62.38% | AUC 0.7369\n",
    "# (0-1k]     样本2361 | ACC  65.82% | P  63.91% | R  59.50% | F1  61.63% | AUC 0.7199\n",
    "# (0-2k]     样本2617 | ACC  65.42% | P  63.23% | R  59.93% | F1  61.54% | AUC 0.7135\n",
    "# all        样本2732 | ACC  65.04% | P  62.58% | R  59.44% | F1  60.97% | AUC 0.7080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COUNT] train: 18187  | val: 2273  | test: 2274\n",
      "[LABEL] train total=18187 | neg=16387 (90.10%) | pos= 1800 ( 9.90%)\n",
      "[LABEL] val   total= 2273 | neg= 2063 (90.76%) | pos=  210 ( 9.24%)\n",
      "[LABEL] test  total= 2274 | neg= 2044 (89.89%) | pos=  230 (10.11%)\n"
     ]
    }
   ],
   "source": [
    "# —— 统计三个数据集样本数（过滤 max_len 之后） ——\n",
    "print(f\"[COUNT] train: {len(train_ds)}  | val: {len(val_ds)}  | test: {len(test_ds)}\")\n",
    "\n",
    "# —— 可选：再看一下标签分布（正/负样本数量与占比） ——\n",
    "from collections import Counter\n",
    "def label_stats(ds, name):\n",
    "    cnt = Counter([feat.label for feat in ds.features])\n",
    "    total = len(ds)\n",
    "    neg = cnt.get(0, 0); pos = cnt.get(1, 0)\n",
    "    print(f\"[LABEL] {name:<5} total={total:5d} | neg={neg:5d} ({neg/total:6.2%}) | pos={pos:5d} ({pos/total:6.2%})\")\n",
    "\n",
    "label_stats(train_ds, \"train\")\n",
    "label_stats(val_ds,   \"val\")\n",
    "label_stats(test_ds,  \"test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
