{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import tempfile\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_node(feats, drop_rate,training=True,seed=42):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        feats (Tensor): 节点特征 [batch_size, num_nodes, feature_dim] 或 [num_nodes, feature_dim]\n",
    "        drop_rate (float): 丢弃概率。\n",
    "\n",
    "    Returns:\n",
    "        Tensor: 丢弃后的节点特征，与输入形状一致。\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    if not training or drop_rate <= 0.0:\n",
    "        return feats\n",
    "    if feats.dim() == 2:  # [num_nodes, feature_dim]\n",
    "        num_nodes, feature_dim = feats.shape\n",
    "        drop_rates = torch.full((num_nodes,), drop_rate, device=feats.device, dtype=feats.dtype)  # [num_nodes]\n",
    "        if training:\n",
    "            masks = torch.bernoulli(1. - drop_rates).unsqueeze(1).expand(-1, feature_dim)  # [num_nodes, feature_dim]\n",
    "            feats = masks * feats\n",
    "        else :\n",
    "            feats = feats * (1. - drop_rate)\n",
    "    elif feats.dim() == 3:  # [batch_size, num_nodes, feature_dim]\n",
    "        batch_size, num_nodes, feature_dim = feats.shape\n",
    "        drop_rates = torch.full((batch_size, num_nodes), drop_rate, device=feats.device, dtype=feats.dtype)  # [batch_size, num_nodes]\n",
    "        if training:\n",
    "            masks = torch.bernoulli(1. - drop_rates).unsqueeze(2).expand(-1, -1, feature_dim)  # [batch_size, num_nodes, feature_dim]\n",
    "            feats = masks * feats\n",
    "        else :\n",
    "            feats = feats * (1. - drop_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported feats dimension: {feats.dim()}\")\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, input_dropout, hidden_dropout, batchnorm):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, hid_dim)\n",
    "        self.layer2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.input_dropout = nn.Dropout(input_dropout)\n",
    "        self.hidden_dropout = nn.Dropout(hidden_dropout)\n",
    "        self.bn1 = nn.BatchNorm1d(in_dim) if batchnorm else None\n",
    "        self.bn2 = nn.BatchNorm1d(hid_dim) if batchnorm else None\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.layer1.reset_parameters()\n",
    "        self.layer2.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.bn1:\n",
    "            x = self.bn1(x)\n",
    "        x = self.input_dropout(x)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        if self.bn2:\n",
    "            x = self.bn2(x)\n",
    "        x = self.hidden_dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GGGNN(nn.Module):\n",
    "    def __init__(self, feature_dim_size, hidden_size, num_GNN_layers, dropout, act=nn.functional.relu):\n",
    "        super(GGGNN, self).__init__()\n",
    "        self.num_GNN_layers = num_GNN_layers\n",
    "        self.emb_encode = nn.Linear(feature_dim_size, hidden_size)\n",
    "        self.dropout_encode = nn.Dropout(dropout)\n",
    "        self.z0 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.z1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.r0 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.r1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h0 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.soft_att = nn.Linear(hidden_size, 1)\n",
    "        self.ln = nn.Linear(hidden_size, hidden_size)\n",
    "        self.act = act\n",
    "\n",
    "    def gatedGNN(self, x, adj):\n",
    "        a = torch.matmul(adj, x)\n",
    "        # update gate\n",
    "        z0 = self.z0(a)\n",
    "        z1 = self.z1(x)\n",
    "        z = torch.sigmoid(z0 + z1)\n",
    "        # reset gate\n",
    "        r = torch.sigmoid(self.r0(a) + self.r1(x))\n",
    "        # update embeddings\n",
    "        h = self.act(self.h0(a) + self.h1(r * x))\n",
    "\n",
    "        return h * z + x * (1 - z)\n",
    "\n",
    "    def forward(self, inputs, adj, mask):        # mask [B, N]\n",
    "        x = self.dropout_encode(inputs)\n",
    "        x = self.emb_encode(x)          # [B, N, H]\n",
    "        mask_3d = mask.unsqueeze(-1)             # [B, N, 1]\n",
    "\n",
    "        x = x * mask_3d                          # 广播到 [B, N, H]\n",
    "        for _ in range(self.num_GNN_layers):\n",
    "            x = self.gatedGNN(x, adj) * mask_3d  # 避免重复 unsqueeze\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRAND_GatedFusion(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim,\n",
    "                 hid_dim,\n",
    "                 S=5,\n",
    "                 K=3,\n",
    "                 num_GNN_layers=2,\n",
    "                 node_dropout=0.05,\n",
    "                 input_droprate=0.1,\n",
    "                 hidden_droprate=0.1,\n",
    "                 batchnorm=False,\n",
    "                 att_op='sum',\n",
    "                 num_heads=8,\n",
    "                 temp=0.5,\n",
    "                 lam=1.0,\n",
    "                 gnn_dropout=0.1,\n",
    "                 args=None):\n",
    "        super(GRAND_GatedFusion, self).__init__()\n",
    "        self.S = S\n",
    "        self.K = K\n",
    "        self.args = args\n",
    "        self.node_dropout_rate = node_dropout\n",
    "        self.att_op = att_op\n",
    "        self.temp = temp\n",
    "        self.lam = lam\n",
    "        \n",
    "        # GRAND components\n",
    "        self.grand_mlp = MLP(in_dim, hid_dim, hid_dim, input_droprate, hidden_droprate, batchnorm)\n",
    "        \n",
    "        # Gated GNN components\n",
    "        self.gggnn = GGGNN(in_dim, hid_dim, num_GNN_layers, gnn_dropout)\n",
    "        \n",
    "        # Fusion gate parameters\n",
    "        self.fusion_gate = nn.Linear(2 * hid_dim, hid_dim)\n",
    "        self.reset_gate = nn.Linear(2 * hid_dim, hid_dim)\n",
    "        self.update_gate = nn.Linear(2 * hid_dim, hid_dim)\n",
    "        self.output_gate = nn.Linear(2 * hid_dim, hid_dim)\n",
    "        \n",
    "        # Output layer parameters\n",
    "        if self.att_op == 'atten':\n",
    "            self.att_fc = nn.Linear(hid_dim, 1)\n",
    "            self.out_dim = hid_dim\n",
    "        elif self.att_op == 'mul_head':\n",
    "            self.att_fc = nn.Linear(hid_dim, num_heads)\n",
    "            self.out_dim = hid_dim * num_heads\n",
    "        elif self.att_op == 'concat':\n",
    "            self.out_dim = 2 * hid_dim\n",
    "        else:\n",
    "            self.out_dim = hid_dim\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def normalize_adj(self, adj):\n",
    "        # if adj.dim() == 3:\n",
    "        #     adj_norm = []\n",
    "        #     eye = torch.eye(adj.size(-1), device=adj.device)\n",
    "        #     adj = adj + eye\n",
    "        #     for i in range(adj.size(0)):\n",
    "        #         deg = adj[i].sum(dim=1).clamp(min=1)\n",
    "        #         deg_inv_sqrt = deg.pow(-0.5)\n",
    "        #         D_inv_sqrt = torch.diag(deg_inv_sqrt)\n",
    "        #         adj_norm.append(D_inv_sqrt @ adj[i] @ D_inv_sqrt)\n",
    "        #     return torch.stack(adj_norm)\n",
    "        if adj.dim() == 3:            # batched dense\n",
    "            eye = torch.eye(adj.size(-1), device=adj.device)\n",
    "            adj = adj + eye           # 加自环\n",
    "            deg = adj.sum(-1)         # [B,N]\n",
    "            deg_inv_sqrt = (deg + 1e-9).pow(-0.5)   # 避免除零\n",
    "            # 利用广播而不是显式 diag，加速\n",
    "            return deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n",
    "\n",
    "        # elif adj.dim() == 2:\n",
    "        #     deg = adj.sum(dim=1).clamp(min=1)\n",
    "        #     deg_inv_sqrt = deg.pow(-0.5)\n",
    "        #     D_inv_sqrt = torch.diag(deg_inv_sqrt)\n",
    "        #     return D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "        elif adj.dim() == 2:\n",
    "            N = adj.size(0)\n",
    "            eye = torch.eye(N, device=adj.device, dtype=adj.dtype)\n",
    "            adj = adj + eye\n",
    "            deg = adj.sum(dim=1)                      \n",
    "            deg_inv_sqrt = (deg + 1e-9).pow(-0.5)    \n",
    "            return deg_inv_sqrt.unsqueeze(1) * adj * deg_inv_sqrt.unsqueeze(0)\n",
    "\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported adj dimension: {adj.dim()}\")\n",
    "\n",
    "    def grand_conv(self, X, adj_norm):\n",
    "        X_agg = X.clone()\n",
    "        for _ in range(self.K):\n",
    "            X = adj_norm @ X\n",
    "            X_agg += X\n",
    "        return X_agg / (self.K + 1)\n",
    "\n",
    "    def gate_fusion(self, grand_feats, ggnn_feats):\n",
    "        \"\"\"Gated fusion mechanism combining GRAND and Gated GNN features\"\"\"\n",
    "        combined = torch.cat([grand_feats, ggnn_feats], dim=-1)\n",
    "        \n",
    "        # Gating mechanisms\n",
    "        reset = torch.sigmoid(self.reset_gate(combined))\n",
    "        update = torch.sigmoid(self.update_gate(combined))\n",
    "        \n",
    "        # Intermediate fusion state\n",
    "        intermediate = torch.tanh(self.fusion_gate(torch.cat([grand_feats, reset * ggnn_feats], dim=-1)))\n",
    "        \n",
    "        # Final fused output\n",
    "        fused_output = update * ggnn_feats + (1 - update) * intermediate\n",
    "        \n",
    "        # Output gate\n",
    "        output_gate = torch.sigmoid(self.output_gate(combined))\n",
    "        return output_gate * fused_output + (1 - output_gate) * grand_feats\n",
    "\n",
    "    def aggregate(self, x, mask=None):\n",
    "        \"\"\"Aggregate node features into graph-level embeddings\"\"\"\n",
    "        x_sum = torch.sum(x, dim=1, keepdim=True)\n",
    "        x_max = torch.amax(x, dim=1, keepdim=True)\n",
    "        x_mean = torch.mean(x, dim=1, keepdim=True)\n",
    "        \n",
    "        if self.att_op == 'sum':\n",
    "            return (x_sum + x_max).squeeze(1)\n",
    "        elif self.att_op == 'max+mean':\n",
    "            return (x_mean + x_max).squeeze(1)\n",
    "        elif self.att_op == 'concat':\n",
    "            return torch.cat((x_sum, x_max), dim=2).squeeze(1)\n",
    "        elif self.att_op == 'atten':            # 单头注意力\n",
    "            scores = self.att_fc(x).squeeze(-1)         # [B, N]\n",
    "            if mask is not None:\n",
    "                scores = scores.masked_fill(mask == 0, -1e9)\n",
    "            alpha = torch.softmax(scores, dim=1).unsqueeze(-1)\n",
    "            return (alpha * x).sum(dim=1)\n",
    "        elif self.att_op == 'mul_head':         # 多头注意力\n",
    "            scores = self.att_fc(x)                       # [B, N, H]\n",
    "            if mask is not None:\n",
    "                scores = scores.masked_fill(mask.unsqueeze(-1) == 0, -1e9)  \n",
    "            alpha = torch.softmax(scores, dim=1)\n",
    "            z_heads = (alpha.unsqueeze(-1) * x.unsqueeze(2)).sum(dim=1)\n",
    "            return z_heads.reshape(x.size(0), -1)\n",
    "        else:\n",
    "            # multiply\n",
    "            return (x_sum * x_max).squeeze(1)\n",
    "\n",
    "    def forward(self, inputs, adj, mask=None, seed=None):\n",
    "        inputs = inputs\n",
    "        adj = adj\n",
    "        mask = mask if mask is not None else None\n",
    "        \n",
    "        # Precompute Gated GNN features (only once)\n",
    "        ggnn_feats = self.gggnn(inputs, adj, mask) if mask is not None else self.gggnn(inputs, adj, torch.ones_like(inputs[:, :, 0]))\n",
    "        \n",
    "        if self.training:\n",
    "            emb_list = [] \n",
    "            enhanced_outputs = []\n",
    "            adj_norm = self.normalize_adj(adj)\n",
    "            \n",
    "            for i in range(self.S):\n",
    "                # GRAND feature propagation with node dropout\n",
    "                grand_inputs = drop_node(inputs, self.node_dropout_rate, True, seed=int(int(seed)*10+i))\n",
    "                grand_prop = torch.stack([self.grand_conv(grand_inputs[b], adj_norm[b]) for b in range(grand_inputs.size(0))])\n",
    "                \n",
    "                # Pass through GRAND's MLP\n",
    "                grand_mlp_out = self.grand_mlp(grand_prop.view(-1, grand_prop.size(-1)))\n",
    "                grand_feats = grand_mlp_out.view(inputs.size(0), -1, grand_mlp_out.size(-1))\n",
    "                \n",
    "                # Gated fusion of GRAND and Gated GNN features\n",
    "                fused_feats = self.gate_fusion(grand_feats, ggnn_feats)\n",
    "                \n",
    "                # Apply mask if provided\n",
    "                if mask is not None:\n",
    "                    fused_feats = fused_feats * mask.unsqueeze(-1)\n",
    "                \n",
    "                # Aggregate to graph-level\n",
    "                graph_emb = self.aggregate(fused_feats, mask)\n",
    "                emb_list.append(graph_emb) \n",
    "                enhanced_outputs.append(graph_emb)\n",
    "            \n",
    "            # Compute consistency loss\n",
    "            # ps = [torch.softmax(output, dim=-1) for output in enhanced_outputs]\n",
    "            # avg_p = torch.mean(torch.stack(ps, dim=0), dim=0)\n",
    "            # sharp_p = (torch.pow(avg_p, 1./self.temp) / \n",
    "            #           torch.sum(torch.pow(avg_p, 1./self.temp), dim=-1, keepdim=True)).detach()\n",
    "            \n",
    "            # consistency_loss = sum(torch.mean((p - sharp_p).pow(2).sum(dim=-1)) for p in ps) / len(ps)\n",
    "            \n",
    "            # Return mean graph embedding and consistency loss\n",
    "            # return torch.mean(torch.stack(enhanced_outputs, dim=0), dim=0), consistency_loss\n",
    "\n",
    "            return torch.stack(emb_list, dim=0), None\n",
    "        \n",
    "        \n",
    "        else:  # Inference mode\n",
    "            # GRAND feature propagation without dropout\n",
    "            adj_norm = self.normalize_adj(adj)\n",
    "            grand_prop = torch.stack([self.grand_conv(inputs[b], adj_norm[b]) for b in range(inputs.size(0))])\n",
    "            \n",
    "            # Pass through GRAND's MLP\n",
    "            grand_mlp_out = self.grand_mlp(grand_prop.view(-1, grand_prop.size(-1)))\n",
    "            grand_feats = grand_mlp_out.view(inputs.size(0), -1, grand_mlp_out.size(-1))\n",
    "            \n",
    "            # Gated fusion\n",
    "            fused_feats = self.gate_fusion(grand_feats, ggnn_feats)\n",
    "            \n",
    "            # Apply mask if provided\n",
    "            if mask is not None:\n",
    "                fused_feats = fused_feats * mask.unsqueeze(-1)\n",
    "            \n",
    "            # Aggregate to graph-level\n",
    "            graph_emb = self.aggregate(fused_feats, mask)\n",
    "            return graph_emb, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn, torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, base_cfg, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = GRAND_GatedFusion(**base_cfg).float()\n",
    "        self.classifier = nn.Linear(self.encoder.out_dim, num_classes)\n",
    "        # self.classifier = nn.Linear(base_cfg['hid_dim']*base_cfg['num_heads'],  # out_dim\n",
    "        #                             num_classes)\n",
    "\n",
    "    def forward(self, x, adj, mask, seed=None, train_consistency=True):\n",
    "        if self.training and train_consistency:\n",
    "            # ---------- (1) 取 [S, B, D] ----------\n",
    "            emb_stack, _ = self.encoder(x, adj, mask, seed=seed)\n",
    "\n",
    "            # ---------- (2) 得到 [S, B, C] ----------\n",
    "            logits_stack = self.classifier(emb_stack)\n",
    "\n",
    "            # ---------- (3) 计算 Sharpen consistency ----------\n",
    "            ps = torch.softmax(logits_stack, dim=-1)       # [S,B,C]\n",
    "            avg_p = ps.mean(dim=0)                         # [B,C]\n",
    "\n",
    "            temp = self.encoder.temp                       # 与 cfg 保持一致\n",
    "            sharp_p = (avg_p.pow(1. / temp) /\n",
    "                    avg_p.pow(1. / temp).sum(dim=-1, keepdim=True)).detach()\n",
    "\n",
    "            consistency = ((ps - sharp_p) ** 2).sum(-1).mean()\n",
    "\n",
    "            # ---------- (4) 把 S 个 logits 取平均做分类 ----------\n",
    "            logits = logits_stack.mean(dim=0)              # [B,C]\n",
    "\n",
    "        else:                                              # Eval 或关闭一致性\n",
    "            emb, _ = self.encoder(x, adj, mask)\n",
    "            logits = self.classifier(emb)\n",
    "            consistency = torch.tensor(0., device=logits.device)\n",
    "\n",
    "        return logits, consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: http_proxy=http://10.254.25.18:7890\n",
      "env: https_proxy=http://10.254.25.18:7890\n",
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json, re, os, random\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,\n",
    "                          BertConfig, BertForMaskedLM, BertTokenizer,\n",
    "                          GPT2Config, GPT2LMHeadModel, GPT2Tokenizer,\n",
    "                          OpenAIGPTConfig, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer,\n",
    "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer,\n",
    "                          DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizer,\n",
    "                          LongformerConfig, LongformerForSequenceClassification, LongformerTokenizer,\n",
    "                          AutoTokenizer)\n",
    "# Jupyter Cell 2\n",
    "def clean_code(code: str) -> str:\n",
    "    \"\"\"去单/多行注释 + 空行\"\"\"\n",
    "    code = re.sub(r\"//.*?$\",     \"\", code, flags=re.MULTILINE)\n",
    "    code = re.sub(r\"/\\*.*?\\*/\",  \"\", code, flags=re.DOTALL)\n",
    "    code = re.sub(r\"^\\s*$\\n?\",   \"\", code, flags=re.MULTILINE)\n",
    "    return code.strip()\n",
    "\n",
    "@dataclass\n",
    "class InputFeatures:\n",
    "    input_ids:  List[int]\n",
    "    attention_mask: List[int]\n",
    "    label: int\n",
    "    idx: str\n",
    "\n",
    "# def convert_example(js, tokenizer, block_size):\n",
    "#     code = ' '.join(clean_code(js['func']).split())\n",
    "#     tokens = tokenizer.tokenize(code)[: block_size - 2]\n",
    "#     tokens = [tokenizer.cls_token] + tokens + [tokenizer.sep_token]\n",
    "\n",
    "#     input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "#     attn_mask = [1] * len(input_ids)\n",
    "\n",
    "#     pad_len = block_size - len(input_ids)\n",
    "#     input_ids += [tokenizer.pad_token_id] * pad_len\n",
    "#     attn_mask += [0] * pad_len\n",
    "\n",
    "#     return InputFeatures(\n",
    "#         input_ids      = input_ids,\n",
    "#         attention_mask = attn_mask,\n",
    "#         label          = int(js['target']),\n",
    "#         idx            = str(js['idx'])\n",
    "#     )\n",
    "def convert_example(js, tokenizer, block_size):\n",
    "    code = ' '.join(clean_code(js['func']).split())\n",
    "    # 只截断，不做padding\n",
    "    tokens = tokenizer.tokenize(code)[: block_size - 2]\n",
    "    tokens = [tokenizer.cls_token] + tokens + [tokenizer.sep_token]\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    attn_mask = [1] * len(input_ids)  # 不再有pad，mask全1\n",
    "\n",
    "    return InputFeatures(\n",
    "        input_ids      = input_ids,           # 变长list\n",
    "        attention_mask = attn_mask,           # 变长list\n",
    "        label          = int(js['target']),\n",
    "        idx            = str(js['idx'])\n",
    "    )\n",
    "%env http_proxy=http://10.254.25.18:7890\n",
    "%env https_proxy=http://10.254.25.18:7890\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using default unweighted graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer =  RobertaTokenizer.from_pretrained('microsoft/graphcodebert-base')\n",
    "\n",
    "\n",
    "# ('Yutong001/graphcodebert-c-backup')\n",
    "att_op_dict = {\n",
    "    'sum': 'sum',\n",
    "    'mul': 'mul',\n",
    "    'concat': 'concat'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "weighted_graph = False\n",
    "print('using default unweighted graph')\n",
    "\n",
    "TF_IDF = True\n",
    "PMI =True\n",
    "\n",
    "from transformers import RobertaTokenizer  # 确保导入tokenizer\n",
    "# ('Yutong001/graphcodebert-c-backup')\n",
    "\n",
    "tokenizer =  RobertaTokenizer.from_pretrained('microsoft/graphcodebert-base')\n",
    "from collections import Counter\n",
    "\n",
    "def collect_global_stats(shuffle_doc_words_list, window_size=3):\n",
    "    token_freq  = Counter()      # P(w)\n",
    "    pair_freq   = Counter()      # P(w_i, w_j) 共现\n",
    "    total_windows = 0\n",
    "\n",
    "    for doc in shuffle_doc_words_list:\n",
    "        end = len(doc)\n",
    "        while end > 0 and doc[end-1] in {1, 2}:\n",
    "            end -= 1\n",
    "        doc = doc[:end]\n",
    "\n",
    "        # 更新 token 出现次数\n",
    "        token_freq.update(doc)\n",
    "\n",
    "        # 遍历窗口统计共现\n",
    "        if len(doc) <= window_size:\n",
    "            windows = [doc]\n",
    "        else:\n",
    "            windows = [doc[i:i+window_size] for i in range(len(doc)-window_size+1)]\n",
    "\n",
    "        for win in windows:\n",
    "            total_windows += 1\n",
    "            for i in range(1, len(win)):\n",
    "                for j in range(0, i):\n",
    "                    u, v = win[i], win[j]\n",
    "                    if u == v: \n",
    "                        continue\n",
    "                    pair_freq[(u, v)] += 1\n",
    "                    pair_freq[(v, u)] += 1   # 无向\n",
    "    return token_freq, pair_freq, total_windows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_graph(shuffle_doc_words_list, word_embeddings, window_size=3, weighted_graph=True,TF_IDF=False, PMI=False):\n",
    "    if TF_IDF:\n",
    "        token_freq, pair_freq, W = collect_global_stats(shuffle_doc_words_list, window_size=window_size)\n",
    "        def pmi(u, v, W, eps=1e-9):\n",
    "            # 频数 → 概率\n",
    "            p_uv = pair_freq[(u, v)] / W\n",
    "            p_u  = token_freq[u] / W\n",
    "            p_v  = token_freq[v] / W\n",
    "            val = np.log((p_uv + eps) / (p_u * p_v + eps))\n",
    "            return max(val, 0.)          # 常见做法：负 PMI 设 0（稀疏化）\n",
    "        \n",
    "\n",
    "    x_adj = []\n",
    "    x_feature = []\n",
    "    doc_len_list = []\n",
    "    vocab_set = set()\n",
    "\n",
    "    # 确保 word_embeddings 是 NumPy 数组\n",
    "    if isinstance(word_embeddings, torch.Tensor):\n",
    "        embeddings_np = word_embeddings.cpu().numpy()\n",
    "    else:\n",
    "        embeddings_np = word_embeddings\n",
    "\n",
    "    for i in range(len(shuffle_doc_words_list)):\n",
    "        doc_words = shuffle_doc_words_list[i]\n",
    "        end = len(doc_words)\n",
    "        while end > 0 and doc_words[end-1] in {1, 2}:  # 移除padding\n",
    "            end -= 1\n",
    "        doc_words = doc_words[:end]\n",
    "        doc_len = len(doc_words)\n",
    "\n",
    "        # 获取token字符串表示\n",
    "        tokens_str = tokenizer.convert_ids_to_tokens(doc_words)\n",
    "        \n",
    "        doc_vocab = list(set(doc_words))\n",
    "        doc_nodes = len(doc_vocab)\n",
    "\n",
    "        doc_len_list.append(doc_nodes)\n",
    "        vocab_set.update(doc_vocab)\n",
    "\n",
    "        doc_word_id_map = {}\n",
    "        for j in range(doc_nodes):\n",
    "            doc_word_id_map[doc_vocab[j]] = j\n",
    "\n",
    "        # 使用defaultdict简化边计数\n",
    "        word_pair_count = defaultdict(float)\n",
    "\n",
    "        # 1. 添加滑动窗口共现边\n",
    "        windows = []\n",
    "        if doc_len <= window_size:\n",
    "            windows.append(doc_words)\n",
    "        else:\n",
    "            for j in range(doc_len - window_size + 1):\n",
    "                window = doc_words[j: j + window_size]\n",
    "                windows.append(window)\n",
    "\n",
    "        for window in windows:\n",
    "            for p in range(1, len(window)):\n",
    "                for q in range(0, p):\n",
    "                    word_p_id = window[p]\n",
    "                    word_q_id = window[q]\n",
    "                    if word_p_id == word_q_id:\n",
    "                        continue\n",
    "                    # 共现边（双向添加）\n",
    "                    word_pair_count[(word_p_id, word_q_id)] += 1.0\n",
    "                    word_pair_count[(word_q_id, word_p_id)] += 1.0\n",
    "\n",
    "        # 2. 添加基本的数据流边（基于常见代码模式）\n",
    "        for pos in range(1, doc_len):\n",
    "            current_token = doc_words[pos]\n",
    "            prev_token = doc_words[pos-1]\n",
    "            current_token_str = tokens_str[pos]\n",
    "            \n",
    "            # 模式1: 赋值语句 (a = b)\n",
    "            # 处理带空格的等号 (Ġ=) 和普通等号 (=)\n",
    "            if current_token_str in [\"=\", \"Ġ=\"] and pos > 0 and pos < doc_len - 1:\n",
    "                # 连接左侧变量和右侧表达式\n",
    "                if pos >= 1 and pos < doc_len - 1:\n",
    "                    left_var = doc_words[pos-1]\n",
    "                    right_expr = doc_words[pos+1]\n",
    "                    word_pair_count[(left_var, right_expr)] += 2.0\n",
    "                    word_pair_count[(right_expr, left_var)] += 2.0\n",
    "            \n",
    "            # 模式2: 方法调用 (obj.method())\n",
    "            # 处理带空格的点 (Ġ.) 和普通点 (.)\n",
    "            if current_token_str in [\".\", \"Ġ.\"] and pos > 0 and pos < doc_len - 1:\n",
    "                # 连接对象和方法名\n",
    "                if pos >= 1 and pos < doc_len - 1:\n",
    "                    obj = doc_words[pos-1]\n",
    "                    method = doc_words[pos+1]\n",
    "                    word_pair_count[(obj, method)] += 1.5\n",
    "                    word_pair_count[(method, obj)] += 1.5\n",
    "            \n",
    "            # 模式3: 函数参数 (func(a, b))\n",
    "            # 处理带空格的开括号 (Ġ() 和普通开括号 (()\n",
    "            if current_token_str in [\"(\", \"Ġ(\"] and pos > 0:\n",
    "                # 连接函数名和参数\n",
    "                func_name = doc_words[pos-1]\n",
    "                # 添加函数名到下一个token的边\n",
    "                if pos < doc_len - 1:\n",
    "                    first_param = doc_words[pos+1]\n",
    "                    word_pair_count[(func_name, first_param)] += 1.2\n",
    "                    word_pair_count[(first_param, func_name)] += 1.2\n",
    "                # 添加函数名到所有后续参数\n",
    "                param_pos = pos + 1\n",
    "                # 处理带空格的闭括号 (Ġ)) 和普通闭括号 ())\n",
    "                while param_pos < doc_len and tokens_str[param_pos] not in [\")\", \"Ġ)\"]:\n",
    "                    if tokens_str[param_pos] not in [\",\", \"Ġ,\", \";\", \"Ġ;\"]:\n",
    "                        param_token = doc_words[param_pos]\n",
    "                        word_pair_count[(func_name, param_token)] += 0.8\n",
    "                        word_pair_count[(param_token, func_name)] += 0.8\n",
    "                    param_pos += 1\n",
    "            \n",
    "            # 模式4: 返回值 (return x)\n",
    "            # 检查带空格的return (Ġreturn) 和普通return (return)\n",
    "            if tokens_str[pos-1] in [\"return\", \"Ġreturn\"] and pos > 1:\n",
    "                return_value = current_token\n",
    "                word_pair_count[(prev_token, return_value)] += 1.3\n",
    "                word_pair_count[(return_value, prev_token)] += 1.3\n",
    "\n",
    "        # 3. 添加子词连接边（处理长变量名）\n",
    "        current_var_tokens = []  # 当前变量名的token序列\n",
    "        \n",
    "        for pos in range(doc_len):\n",
    "            token_id = doc_words[pos]\n",
    "            token_str = tokens_str[pos]\n",
    "            \n",
    "            # 检查是否是变量名的开始或延续\n",
    "            if token_str.startswith(\"Ġ\") or not current_var_tokens:\n",
    "                # 新token开始（以空格开头或当前序列为空）\n",
    "                if current_var_tokens:\n",
    "                    # 连接当前变量名的所有token\n",
    "                    for idx in range(1, len(current_var_tokens)):\n",
    "                        prev_id = current_var_tokens[idx-1]\n",
    "                        curr_id = current_var_tokens[idx]\n",
    "                        \n",
    "                        # 添加强连接（双向）\n",
    "                        word_pair_count[(prev_id, curr_id)] += 3.0\n",
    "                        word_pair_count[(curr_id, prev_id)] += 3.0\n",
    "                \n",
    "                # 重置当前变量名（跳过特殊token和运算符）\n",
    "                # 只将标识符加入变量名序列\n",
    "                if token_str not in [\"[CLS]\", \"[SEP]\", \"[PAD]\", \"(\", \")\", \"{\", \"}\", \"=\", \".\", \",\", \";\"] \\\n",
    "                   and not token_str.startswith(\"Ġ(\") \\\n",
    "                   and not token_str.startswith(\"Ġ)\") \\\n",
    "                   and not token_str.startswith(\"Ġ{\") \\\n",
    "                   and not token_str.startswith(\"Ġ}\") \\\n",
    "                   and not token_str.startswith(\"Ġ=\") \\\n",
    "                   and not token_str.startswith(\"Ġ.\") \\\n",
    "                   and not token_str.startswith(\"Ġ,\") \\\n",
    "                   and not token_str.startswith(\"Ġ;\"):\n",
    "                    current_var_tokens = [token_id]\n",
    "                else:\n",
    "                    current_var_tokens = []\n",
    "            elif token_str.startswith(\"##\") or token_str.isalnum() or '_' in token_str:\n",
    "                # 变量名延续（子词token或标识符）\n",
    "                current_var_tokens.append(token_id)\n",
    "            else:\n",
    "                # 其他token（标点、关键字等）\n",
    "                if current_var_tokens:\n",
    "                    # 连接当前变量名的所有token\n",
    "                    for idx in range(1, len(current_var_tokens)):\n",
    "                        prev_id = current_var_tokens[idx-1]\n",
    "                        curr_id = current_var_tokens[idx]\n",
    "                        \n",
    "                        word_pair_count[(prev_id, curr_id)] += 3.0\n",
    "                        word_pair_count[(curr_id, prev_id)] += 3.0\n",
    "                current_var_tokens = []\n",
    "        \n",
    "        # 处理文档末尾的变量名\n",
    "        if current_var_tokens:\n",
    "            for idx in range(1, len(current_var_tokens)):\n",
    "                prev_id = current_var_tokens[idx-1]\n",
    "                curr_id = current_var_tokens[idx]\n",
    "                \n",
    "                word_pair_count[(prev_id, curr_id)] += 3.0\n",
    "                word_pair_count[(curr_id, prev_id)] += 3.0\n",
    "\n",
    "        # 构建邻接矩阵\n",
    "        row, col, weight = [], [], []\n",
    "        for (u, v), w in word_pair_count.items():\n",
    "            if u in doc_word_id_map and v in doc_word_id_map:\n",
    "                row.append(doc_word_id_map[u])\n",
    "                col.append(doc_word_id_map[v])\n",
    "                if TF_IDF:\n",
    "                    weight.append(pmi(u, v, W))\n",
    "                else:\n",
    "                    weight.append(w if weighted_graph else 1.0)\n",
    "        \n",
    "        adj = sp.csr_matrix((weight, (row, col)), shape=(doc_nodes, doc_nodes))\n",
    "        x_adj.append(adj)\n",
    "\n",
    "        # 构建节点特征\n",
    "        features = []\n",
    "        for word_id in doc_vocab:\n",
    "            # 确保 word_id 是整数\n",
    "            word_id = int(word_id)\n",
    "            \n",
    "            # 检查索引是否在嵌入矩阵范围内\n",
    "            if word_id < embeddings_np.shape[0]:\n",
    "                features.append(embeddings_np[word_id])\n",
    "            else:\n",
    "                # 处理超出范围的索引 - 使用零向量\n",
    "                features.append(np.zeros(embeddings_np.shape[1]))\n",
    "        \n",
    "        x_feature.append(features)\n",
    "\n",
    "    return x_adj, x_feature\n",
    "\n",
    "class JsonlCodeDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, block_size=512, sample_percent=1.0):\n",
    "        self.features = []\n",
    "        with open(file_path) as f:\n",
    "            total = sum(1 for _ in f)\n",
    "        with open(file_path) as f:\n",
    "            for line in tqdm(f, total=total, desc=\"Building dataset\"):\n",
    "                js = json.loads(line)\n",
    "                feat = convert_example(js, tokenizer, block_size)\n",
    "                self.features.append(feat)\n",
    "\n",
    "        # 采样（可选）\n",
    "        if 0 < sample_percent < 1.0:\n",
    "            random.seed(42)\n",
    "            random.shuffle(self.features)\n",
    "            keep_num = int(sample_percent * len(self.features))\n",
    "            self.features = self.features[:keep_num]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feat = self.features[idx]\n",
    "        # 直接返回python list，保留变长\n",
    "        return (\n",
    "            feat.input_ids,        # list[int]\n",
    "            feat.attention_mask,   # list[int]（虽然后面用不到也保留）\n",
    "            int(feat.label),       # int\n",
    "        )\n",
    "    \n",
    "model = RobertaForSequenceClassification.from_pretrained('microsoft/graphcodebert-base').to('cpu')\n",
    "w_embeddings = model.get_input_embeddings().weight.data.cpu().detach().clone().numpy()\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2) collate：对每个样本生成若干 chunk 的 adj/feat 列表\n",
    "# -----------------------\n",
    "def collate_graph_split_chunks(batch, window_size=3, chunk_size=512, weighted_graph=True, TF_IDF=True):\n",
    "    \"\"\"\n",
    "    batch: List[ (input_ids(list[int]), attn_mask(list[int]), label(int)) ]\n",
    "    \"\"\"\n",
    "    ids, masks, labels = zip(*batch)              # 现在 ids 是 List[List[int]]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    all_adjs, all_feats, chunks_per_sample = [], [], []\n",
    "\n",
    "    for doc_ids in ids:\n",
    "        # 这里不再依赖 padding 长度；只按有效 token 切分\n",
    "        chunks = split_into_chunks(\n",
    "            doc_ids,\n",
    "            chunk_size=chunk_size,\n",
    "            pad_id=tokenizer.pad_token_id,\n",
    "            cls_id=tokenizer.cls_token_id,\n",
    "            sep_id=tokenizer.sep_token_id\n",
    "        )\n",
    "        sample_adjs, sample_feats = [], []\n",
    "\n",
    "        for chunk in chunks:\n",
    "            x_adj, x_feat = build_graph(\n",
    "                shuffle_doc_words_list=[chunk],\n",
    "                word_embeddings=w_embeddings,\n",
    "                window_size=window_size,\n",
    "                weighted_graph=weighted_graph,\n",
    "                TF_IDF=TF_IDF,\n",
    "                PMI=PMI\n",
    "            )\n",
    "            sample_adjs.append(x_adj[0])\n",
    "            sample_feats.append(x_feat[0])\n",
    "\n",
    "        all_adjs.append(sample_adjs)\n",
    "        all_feats.append(sample_feats)\n",
    "        chunks_per_sample.append(len(chunks))\n",
    "\n",
    "    return {\n",
    "        # 这两个原本没被下游用到，就不返回stack后的Tensor了，避免变长问题\n",
    "        # \"input_ids\": ids,\n",
    "        # \"attention_mask\": masks,\n",
    "        \"labels\": labels,\n",
    "        \"adjs\": all_adjs,\n",
    "        \"feats\": all_feats,\n",
    "        \"chunks_per_sample\": chunks_per_sample\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 1) 切分 util\n",
    "# -----------------------\n",
    "def split_into_chunks(id_list, chunk_size=512, pad_id=None, cls_id=None, sep_id=None):\n",
    "    \"\"\"\n",
    "    只从有效token切分：\n",
    "      - 去掉首个 [CLS]（如果存在）\n",
    "      - 去掉末尾的 [SEP]（如果存在）\n",
    "      - 去掉所有 [PAD]\n",
    "    最后再按 chunk_size 均匀切分（不够则右侧pad为 pad_id）\n",
    "    \"\"\"\n",
    "    # 缺省从 tokenizer 获取\n",
    "    if pad_id is None: pad_id = tokenizer.pad_token_id\n",
    "    if cls_id is None: cls_id = tokenizer.cls_token_id\n",
    "    if sep_id is None: sep_id = tokenizer.sep_token_id\n",
    "\n",
    "    ids = list(id_list)\n",
    "\n",
    "    # 1) 去掉首个 [CLS]\n",
    "    if len(ids) > 0 and ids[0] == cls_id:\n",
    "        ids = ids[1:]\n",
    "\n",
    "    # 2) 去掉末尾 [SEP]\n",
    "    if len(ids) > 0 and ids[-1] == sep_id:\n",
    "        ids = ids[:-1]\n",
    "\n",
    "    # 3) 删除所有 [PAD]（通常只在末尾，但这里更稳健）\n",
    "    ids = [t for t in ids if t != pad_id]\n",
    "\n",
    "    # 4) 空样本兜底：返回一个全pad chunk，避免出现空图\n",
    "    if len(ids) == 0:\n",
    "        return [[pad_id] * chunk_size]\n",
    "\n",
    "    # 5) 定长切分，不把pad当切分依据\n",
    "    chunks = []\n",
    "    for i in range(0, len(ids), chunk_size):\n",
    "        chunk = ids[i:i+chunk_size]\n",
    "        if len(chunk) < chunk_size:\n",
    "            chunk = chunk + [pad_id] * (chunk_size - len(chunk))\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 3) flatten: 把 batch 的 chunks 拉平成单一 batch，并返回映射 sample->chunk ranges\n",
    "# -----------------------\n",
    "def batch_chunks_to_tensor(batch, device):\n",
    "    \"\"\"\n",
    "    输入 batch（来自 collate_graph_split_chunks）\n",
    "    返回:\n",
    "      featb_flat: Tensor [B_chunks, N_max, D]\n",
    "      adjb_flat:  Tensor [B_chunks, N_max, N_max]\n",
    "      maskb_flat: Tensor [B_chunks, N_max]\n",
    "      labels_flat: Tensor [B_chunks]           # 每个 chunk 对应的 label（训练时复制，推理时仍用原样本标签）\n",
    "      sample2chunk_ranges: list of tuples (start_idx, end_idx) for each original sample\n",
    "    \"\"\"\n",
    "    all_adjs = batch[\"adjs\"]    # list length B, each is list of csr\n",
    "    all_feats = batch[\"feats\"]  # same shape\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    B = len(all_adjs)\n",
    "\n",
    "    # flatten\n",
    "    flat_adjs = []\n",
    "    flat_feats = []\n",
    "    labels_flat = []\n",
    "    sample2chunk_ranges = []\n",
    "    cur = 0\n",
    "    for i in range(B):\n",
    "        chunks_adjs = all_adjs[i]\n",
    "        chunks_feats = all_feats[i]\n",
    "        k = len(chunks_adjs)\n",
    "        start = cur\n",
    "        for j in range(k):\n",
    "            flat_adjs.append(chunks_adjs[j])\n",
    "            flat_feats.append(chunks_feats[j])\n",
    "            labels_flat.append(labels[i].item())\n",
    "            cur += 1\n",
    "        end = cur\n",
    "        sample2chunk_ranges.append((start, end))\n",
    "\n",
    "    # convert to tensors (pad node count)\n",
    "    N_max = max(adj.shape[0] for adj in flat_adjs)\n",
    "    D = len(flat_feats[0][0])\n",
    "    B_chunks = len(flat_adjs)\n",
    "\n",
    "    featb = torch.zeros(B_chunks, N_max, D, dtype=torch.float32, device=device)\n",
    "    adjb  = torch.zeros(B_chunks, N_max, N_max, dtype=torch.float32, device=device)\n",
    "    maskb = torch.zeros(B_chunks, N_max, dtype=torch.float32, device=device)\n",
    "\n",
    "    for i, (adj, feat) in enumerate(zip(flat_adjs, flat_feats)):\n",
    "        n = adj.shape[0]\n",
    "        adjb[i, :n, :n] = torch.from_numpy(adj.toarray()).to(device)\n",
    "        featb[i, :n, :]  = torch.from_numpy(np.asarray(feat)).to(device)\n",
    "        maskb[i, :n]     = 1.\n",
    "\n",
    "    labels_flat = torch.tensor(labels_flat, dtype=torch.long, device=device)\n",
    "    return featb, adjb, maskb, labels_flat, sample2chunk_ranges\n",
    "\n",
    "\n",
    "\n",
    "# （我把它写成按 sample 聚合取 max prob 的 OR 规则）：\n",
    "@torch.no_grad()\n",
    "def collect_logits_per_sample(model, dataloader, device='cpu', max_samples=None, chunk_collate=True):\n",
    "    \"\"\"\n",
    "    返回样本级 logits/probs 与 labels\n",
    "    若 dataloader 使用 collate_graph_split_chunks，则 batch['adjs'] 等为 list[list]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sample_preds = []\n",
    "    sample_probs = []\n",
    "    sample_labels = []\n",
    "    seen = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # 把 batch 的 chunk flatten\n",
    "        featb, adjb, maskb, labels_flat, sample2chunk_ranges = batch_chunks_to_tensor(batch, device)\n",
    "        # 对所有 chunk 一次前向\n",
    "        logits_chunks, _ = model(featb, adjb, maskb, train_consistency=False)   # [B_chunks, C]\n",
    "        probs_chunks = torch.softmax(logits_chunks, dim=-1)[:, 1].detach().cpu().numpy()  # positive prob\n",
    "\n",
    "        # 对每个原样本聚合（OR 规则：任一 chunk prob > 0.5 则正类）\n",
    "        for (s,e), sample_label in zip(sample2chunk_ranges, batch[\"labels\"].numpy()):\n",
    "            chunk_probs = probs_chunks[s:e]\n",
    "            if len(chunk_probs) == 0:\n",
    "                sample_prob = 0.0\n",
    "                sample_pred = 0\n",
    "            else:\n",
    "                sample_prob = float(np.max(chunk_probs))   # OR: use max prob\n",
    "                sample_pred = int(sample_prob > 0.5)       # threshold 可改为 argmax 行为\n",
    "            sample_probs.append(sample_prob)\n",
    "            sample_preds.append(sample_pred)\n",
    "            sample_labels.append(int(sample_label))\n",
    "            seen += 1\n",
    "            if max_samples is not None and seen >= max_samples:\n",
    "                break\n",
    "        if max_samples is not None and seen >= max_samples:\n",
    "            break\n",
    "\n",
    "    return np.array(sample_preds), np.array(sample_probs), np.array(sample_labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f88d7047ef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, random, numpy as np, torch\n",
    "seed_number=42\n",
    "def set_global_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)        # Python 层哈希随机\n",
    "    random.seed(seed)                               # 内置 random\n",
    "    np.random.seed(seed)                            # numpy\n",
    "    torch.manual_seed(seed)                         # CPU\n",
    "    torch.cuda.manual_seed(seed)                    # 当前 GPU\n",
    "    torch.cuda.manual_seed_all(seed)                # 所有 GPU\n",
    "\n",
    "    # 额外：在部分算子中强制使用确定性实现\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False          # 禁止自动算法搜索\n",
    "    torch.use_deterministic_algorithms(True)        # ≥1.8，捕获非确定性算子\n",
    "\n",
    "    # CUDA ≥ 10.2：卷积类算子还需要这个环境变量\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "set_global_seed(seed_number)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    # 每个 worker 用不同 seed，但与主进程严格可重复\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building dataset:   0%|          | 0/21854 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
      "Building dataset: 100%|██████████| 21854/21854 [00:26<00:00, 818.94it/s]\n",
      "Building dataset: 100%|██████████| 2732/2732 [00:03<00:00, 808.58it/s]\n",
      "Building dataset: 100%|██████████| 2732/2732 [00:03<00:00, 772.54it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL_NAME = ('microsoft/graphcodebert-base')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# ---------- 配置区（修改） ----------\n",
    "BLOCK_SIZE = 2048            # 训练/验证最大 token（2k）\n",
    "TEST_BLOCK_SIZE = 8192       # 测试时的 block_size（设大一点以避免被 convert_example 截断）\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# 把 filter_by_len 改为 <=（允许正好等于 max_len 的样本）\n",
    "def filter_by_len(dataset, max_len=512):\n",
    "    filtered = []\n",
    "    for feat in dataset.features:\n",
    "        real_len = sum(feat.attention_mask)\n",
    "        if real_len <= max_len:      # <= 而不是 <\n",
    "            filtered.append(feat)\n",
    "    dataset.features = filtered\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_ds = JsonlCodeDataset(\"dataset/train.jsonl\", tokenizer, block_size=BLOCK_SIZE)\n",
    "val_ds  = JsonlCodeDataset(\"dataset/valid.jsonl\", tokenizer, block_size=BLOCK_SIZE)\n",
    "test_ds  = JsonlCodeDataset(\"dataset/test.jsonl\", tokenizer, block_size=1024*39)\n",
    "\n",
    "\n",
    "\n",
    "train_ds = filter_by_len(train_ds, max_len=2047)\n",
    "val_ds   = filter_by_len(val_ds, max_len=2047)\n",
    "test_ds  = filter_by_len(test_ds, 1024*39)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    sampler = RandomSampler(train_ds, generator=g),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    collate_fn = lambda batch: collate_graph_split_chunks(batch, window_size=3, chunk_size=2048,\n",
    "                                                          weighted_graph=True, TF_IDF=True),\n",
    "    num_workers = 32,\n",
    "    pin_memory = True,\n",
    "    persistent_workers=True,\n",
    "    worker_init_fn = seed_worker\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    sampler = RandomSampler(val_ds, replacement=False),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    collate_fn = lambda batch: collate_graph_split_chunks(batch, window_size=3, chunk_size=2048,\n",
    "                                                          weighted_graph=True, TF_IDF=True),\n",
    "    num_workers = 8,\n",
    "    pin_memory = True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=4,\n",
    "    worker_init_fn = seed_worker\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    sampler = RandomSampler(test_ds, replacement=False),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    collate_fn = lambda batch: collate_graph_split_chunks(batch, window_size=3, chunk_size=2048,\n",
    "                                                          weighted_graph=True, TF_IDF=True),\n",
    "    num_workers = 8,\n",
    "    pin_memory = True,\n",
    "    worker_init_fn = seed_worker\n",
    ")\n",
    "# 38s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== dataset length stats ==\n",
      "[train] samples=20866, min=12, max=2046, mean=408.6, >BLOCK(2048)=0, >CHUNK(2048)=0, top5=[2046, 2046, 2046, 2045, 2045]\n",
      "[val] samples=2597, min=16, max=2046, mean=402.8, >BLOCK(2048)=0, >CHUNK(2048)=0, top5=[2046, 2040, 2028, 2023, 2010]\n",
      "[test] samples=2732, min=11, max=38735, mean=579.8, >BLOCK(2048)=115, >CHUNK(2048)=115, top5=[38735, 27602, 18619, 15554, 12509]\n"
     ]
    }
   ],
   "source": [
    "# 检查脚本：检验 train/val/test 是否在 convert 或 collate 阶段被切片\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import math\n",
    "import torch\n",
    "\n",
    "# 配置（与你训练时一致）\n",
    "CHUNK_SIZE = 2048   # collate_graph_split_chunks 使用的 chunk_size\n",
    "BLOCK_SIZE = 2048   # 你为 train/val 设定的 block_size\n",
    "TEST_BLOCK_SIZE = 8192  # 你为 test 设定的 block_size（脚本中可能不一致）\n",
    "\n",
    "# helper: 计算 dataset 中每个样本的真实 token 长度（基于 attention_mask）\n",
    "def dataset_length_stats(ds, topk=5):\n",
    "    lengths = []\n",
    "    for feat in ds.features:\n",
    "        lm = sum(feat.attention_mask) if hasattr(feat, \"attention_mask\") or isinstance(feat.attention_mask, (list,tuple)) else sum(feat.attention_mask)\n",
    "        lengths.append(int(lm))\n",
    "    arr = np.array(lengths, dtype=int)\n",
    "    return {\n",
    "        \"n_samples\": len(arr),\n",
    "        \"min\": int(arr.min()) if arr.size>0 else 0,\n",
    "        \"max\": int(arr.max()) if arr.size>0 else 0,\n",
    "        \"mean\": float(arr.mean()) if arr.size>0 else 0.0,\n",
    "        \"pct_gt_BLOCK\": int((arr > BLOCK_SIZE).sum()),\n",
    "        \"pct_gt_CHUNK\": int((arr > CHUNK_SIZE).sum()),\n",
    "        \"top5_lengths\": sorted(arr, reverse=True)[:topk] if arr.size>0 else []\n",
    "    }\n",
    "\n",
    "# helper: inspect one batch from a dataloader (batch is already collated)\n",
    "def inspect_loader_batch(loader, device='cpu', n_batches=1):\n",
    "    it = iter(loader)\n",
    "    info = {\"batches_checked\":0, \"chunks_per_sample_vals\": Counter(), \"max_chunks_in_batch\":0, \"avg_chunks_per_sample\": None}\n",
    "    total_chunks_counts = []\n",
    "    for _ in range(n_batches):\n",
    "        try:\n",
    "            batch = next(it)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        # batch 应按你的 collate 返回 dict with \"chunks_per_sample\"\n",
    "        cps = batch.get(\"chunks_per_sample\", None)\n",
    "        if cps is None:\n",
    "            # 有些 collate 可能返回 different key layout -> try to infer from adjs\n",
    "            adjs = batch.get(\"adjs\", None)\n",
    "            if adjs is not None:\n",
    "                # adjs: list (B) of list (chunks)\n",
    "                cps = [len(x) for x in adjs]\n",
    "        if cps is None:\n",
    "            info[\"note\"] = \"无法找到 chunks_per_sample，也无法从 adjs 推断。collate_fn 返回结构未知。\"\n",
    "            break\n",
    "        # record stats\n",
    "        for v in cps:\n",
    "            info[\"chunks_per_sample_vals\"][v] += 1\n",
    "            total_chunks_counts.append(v)\n",
    "        info[\"batches_checked\"] += 1\n",
    "        info[\"max_chunks_in_batch\"] = max(info[\"max_chunks_in_batch\"], max(cps))\n",
    "    if total_chunks_counts:\n",
    "        info[\"avg_chunks_per_sample\"] = float(np.mean(total_chunks_counts))\n",
    "    return info\n",
    "\n",
    "# ---- run checks ----\n",
    "print(\"== dataset length stats ==\")\n",
    "for name, ds in [(\"train\", train_ds), (\"val\", val_ds), (\"test\", test_ds)]:\n",
    "    stats = dataset_length_stats(ds)\n",
    "    print(f\"[{name}] samples={stats['n_samples']}, min={stats['min']}, max={stats['max']}, mean={stats['mean']:.1f}, \"\n",
    "          f\">BLOCK({BLOCK_SIZE})={stats['pct_gt_BLOCK']}, >CHUNK({CHUNK_SIZE})={stats['pct_gt_CHUNK']}, top5={stats['top5_lengths']}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdasdas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 74\u001b[0m\n\u001b[1;32m     70\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m180\u001b[39m\n\u001b[1;32m     71\u001b[0m best_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.57\u001b[39m\n\u001b[0;32m---> 74\u001b[0m \u001b[43masdasdas\u001b[49m\n\u001b[1;32m     76\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     77\u001b[0m train_accs, val_accs \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asdasdas' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import math, time, random\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def evaluate_sample_level(model, dataloader, device='cpu'):\n",
    "    preds, probs, labels = collect_logits_per_sample(model, dataloader, device=device)\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    return acc, prec, rec, f1, auc\n",
    "\n",
    "# 先放在训练循环外，定义一次\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def mil_noisyor_bag_loss(logits_chunks, sample2chunk_ranges, labels_per_sample, eps=1e-7):\n",
    "    probs_pos = torch.softmax(logits_chunks, dim=-1)[:, 1]  # [B_chunks]\n",
    "    bag_probs = []\n",
    "    for (s, e) in sample2chunk_ranges:\n",
    "        p = probs_pos[s:e]\n",
    "        bag_p = 1.0 - torch.clamp(1.0 - p, min=0.0, max=1.0).prod()\n",
    "        bag_probs.append(bag_p)\n",
    "    bag_probs = torch.stack(bag_probs, dim=0)               # [B_samples]\n",
    "    labels = labels_per_sample.float().to(bag_probs.device)\n",
    "    bag_probs = torch.clamp(bag_probs, eps, 1 - eps)\n",
    "    return F.binary_cross_entropy(bag_probs, labels)\n",
    "\n",
    "\n",
    "config = {\n",
    "    'in_dim'       : 768,\n",
    "    'hid_dim'      : 128,     #      64 128 256 \n",
    "    'S'            : 5,       #      2 3 4\n",
    "    'K'            : 2,       #       2 4 6\n",
    "    'num_GNN_layers': 2,     \n",
    "    'node_dropout' : 0.2,     #      0.1 0.3 0.5 0.7\n",
    "    'input_droprate': 0.3,\n",
    "    'hidden_droprate': 0.3,\n",
    "    'batchnorm'    : True,\n",
    "    'att_op'       : 'mul_head',\n",
    "    'num_heads'    : 6,\n",
    "    'temp'         : 0.6,          \n",
    "    'lam'          : 1.4,          # 0.8 1.0 1.4 1.6 2.0\n",
    "    'gnn_dropout'  : 0.2, \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "lam = config['lam']\n",
    "\n",
    "model_path= \"best_model-devign-1-cut512-all.pt\"\n",
    "# 1. 实例化网络（只一次）\n",
    "net = Net(config, num_classes).to(device)\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "# 2. 绑定优化器 / 调度器\n",
    "\n",
    "optimizer = AdamW(net.parameters(), lr=5e-4, weight_decay=1e-2,no_deprecation_warning=True )\n",
    "\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "# 3. 训练循环\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "best_val_acc, best_state, patience, wait = 0.6, None, 20, 0\n",
    "epochs = 180\n",
    "best_f1 = 0.57\n",
    "\n",
    "\n",
    "asdasdas\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "wait = 0\n",
    "init_seed=2345\n",
    "epoch = 0\n",
    "while True:\n",
    "    epoch+=1\n",
    "\n",
    "    # ===== Train =====\n",
    "    net.train()\n",
    "    tr_loss_sum, cons_loss_sum, tr_correct, tr_ex = 0.0, 0.0, 0, 0\n",
    "    bar = tqdm(train_loader, desc=f\"Train Ep{epoch:03d}\", leave=False)\n",
    "\n",
    "    for batch in bar:\n",
    "    # flatten chunks -> (B_chunks, N_max, D), labels_flat 对应每个 chunk\n",
    "        featb, adjb, maskb, labels_flat, sample2chunk_ranges = batch_chunks_to_tensor(batch, device)\n",
    "        bs = labels_flat.size(0)    # 注意：现在 bs 表示 chunk 数量（实际模型前向样本数）\n",
    "        optimizer.zero_grad()\n",
    "        seed   = init_seed + epoch\n",
    "\n",
    "        # logits, cons = net(featb, adjb, maskb, seed=seed, train_consistency=True)\n",
    "        # cls_loss = criterion_cls(logits, labels_flat)   # 每个 chunk 当独立样本训练\n",
    "\n",
    "        # loss = cls_loss + lam * cons\n",
    "\n",
    "        logits, cons = net(featb, adjb, maskb, seed=seed, train_consistency=True)\n",
    "        cls_loss = mil_noisyor_bag_loss(logits, sample2chunk_ranges, batch[\"labels\"])\n",
    "        loss = cls_loss + lam * cons\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss_sum += cls_loss.item() * bs\n",
    "        cons_loss_sum += cons.item() * bs\n",
    "        tr_correct  += (logits.argmax(1) == labels_flat).sum().item()\n",
    "        tr_ex       += bs\n",
    "        bar.set_postfix(cls_loss=f\"{cls_loss.item() / max(bs,1):.4f}\", cons_loss=f\"{cons.item() / max(bs,1):.4f}\")\n",
    "\n",
    "\n",
    "    scheduler.step()\n",
    "    train_loss = tr_loss_sum / tr_ex\n",
    "    train_cons_loss = cons_loss_sum / tr_ex\n",
    "    train_acc  = tr_correct  / tr_ex\n",
    "\n",
    "\n",
    "    # ===== Validate =====\n",
    "    net.eval()\n",
    "    val_loss_sum, val_ex = 0.0, 0  # val_ex 统计“样本（bag）数”，不是 chunk 数\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bar = tqdm(val_loader, desc=f\"Val Ep{epoch:03d}\", leave=False)\n",
    "        for batch in bar:\n",
    "            # 展平本 batch 的所有 chunk\n",
    "            featb, adjb, maskb, labels_flat, sample2chunk_ranges = batch_chunks_to_tensor(batch, device)\n",
    "            # 前向（验证时不做一致性）\n",
    "            logits, _ = net(featb, adjb, maskb, train_consistency=False)\n",
    "\n",
    "            # —— 用 MIL 的 bag-level 验证损失 —— #\n",
    "            labels_per_sample = batch[\"labels\"].to(device)   # [B_samples]\n",
    "            batch_bag_loss = mil_noisyor_bag_loss(logits, sample2chunk_ranges, labels_per_sample)\n",
    "\n",
    "            # 以“样本数”做加权累计\n",
    "            b_samples = len(sample2chunk_ranges)\n",
    "            val_loss_sum += batch_bag_loss.item() * b_samples\n",
    "            val_ex       += b_samples\n",
    "\n",
    "    # bag-level 验证损失（与训练目标一致）\n",
    "    val_loss = val_loss_sum / max(val_ex, 1)\n",
    "\n",
    "    # —— 样本级指标（保持不变，仍用 OR 聚合/你的 evaluate_sample_level）——\n",
    "    val_acc_s, prec_s, rec_s, f1_s, auc_s = evaluate_sample_level(net, val_loader, device=device)\n",
    "\n",
    "    # 记录并打印（用样本级指标作为真实验证信号）\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc_s)   # 注意这里换成样本级 acc\n",
    "\n",
    "    tqdm.write(\n",
    "        f\"Epoch {epoch:03d} | \"\n",
    "        f\"train_loss {train_loss:.4f} (cls) + {train_cons_loss:.4f} (cons)  \"\n",
    "        f\"triain_acc {train_acc:.4f} | \"\n",
    "        f\"val_loss {val_loss:.4f} acc {val_acc_s:.4f} | \"\n",
    "        f\"P {prec_s:.4f} R {rec_s:.4f} F1 {f1_s:.4f}\"\n",
    "    )\n",
    "\n",
    "    # ===== Early-stopping =====\n",
    "\n",
    "    if val_acc_s > best_val_acc:\n",
    "        best_f1 = f1_s\n",
    "        best_val_acc = val_acc_s\n",
    "        best_state = net.state_dict()\n",
    "        torch.save(net.state_dict(), model_path)\n",
    "        tqdm.write(f\"💾 Saved new best ckpt: acc={best_val_acc:.4f} @ epoch {epoch:03d}\")\n",
    "        wait = 0\n",
    "    elif val_acc_s == best_val_acc:\n",
    "        if f1_s > best_f1:\n",
    "            best_f1= f1_s\n",
    "            best_state = net.state_dict()\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            tqdm.write(f\"💾 Saved better ckpt by F1: acc={best_val_acc:.4f} F1={best_f1:.4f} @ epoch {epoch:03d}\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            tqdm.write(f\"Early stop at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAGJCAYAAADIVkprAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABrM0lEQVR4nO3dd3iT9d7H8XfSke6W7j0oZUPZe2qRJQKiIqIMUY8KKuJxPQ4QB+e4FXErTqbK8IDsvWfZFMpqGd107+R+/rjbQGkpbUmbju/runK1uVd+6V3Ip7+pURRFQQghhBDChLTmLoAQQggh6h8JGEIIIYQwOQkYQgghhDA5CRhCCCGEMDkJGEIIIYQwOQkYQgghhDA5CRhCCCGEMDkJGEIIIYQwOQkYQgghhDA5CRhCmNiECRMIDg6u0rkzZsxAo9GYtkD1VFk/q+DgYCZMmHDLc3/66Sc0Gg3nz583WXnOnz+PRqPhp59+Mtk1K+p2fueEqC4SMESDodFoKvTYtGmTuYtaryQkJGBpacnDDz9802MyMjKwtbXl3nvvrcGSVc28efP49NNPzV0MIWo9S3MXQIia8uuvv5Z4/ssvv7B27dpS21u0aHFbr/Pdd99hMBiqdO7rr7/OK6+8cluvX9t4enoyYMAAli1bRnZ2NnZ2dqWO+euvv8jNzS03hFREVFQUWm31/t00b948jh49ytSpU0tsDwoKIicnBysrq2p9fSHqCgkYosG48cNr165drF279pYfajf7ULyZ2/mAsbS0xNKy/v2zHDt2LKtWrWL58uU8+OCDpfbPmzcPZ2dnhg4deluvo9Ppbuv826HRaLCxsTHb6wtR20gTiRDX6devH61bt2b//v306dMHOzs7/u///g+AZcuWMXToUHx9fdHpdISGhvL222+j1+tLXOPG9vDitvkPP/yQb7/9ltDQUHQ6HZ07d2bv3r0lzi2rX4FGo2HKlCksXbqU1q1bo9PpaNWqFatWrSpV/k2bNtGpUydsbGwIDQ3lm2++qVC/jilTpuDg4EB2dnapfWPGjMHb29v4Pvft28fAgQNxd3fH1taWkJAQHn300XKvP3LkSOzt7Zk3b16pfQkJCaxfv5777rsPnU7H1q1buf/++wkMDESn0xEQEMDzzz9PTk5Oua8BZffBOHbsGHfccQe2trb4+/vzzjvvlFnDVJH7269fP1asWMGFCxeMTWrF9/pmfTA2bNhA7969sbe3x8XFheHDh3PixIkSxxTfo+joaCZMmICLiwvOzs5MnDixzHtSEVlZWbzwwgsEBASg0+lo1qwZH374ITcuoL127Vp69eqFi4sLDg4ONGvWzPg7X2z27Nm0atUKOzs7GjVqRKdOncq8l0Jcr/79qSTEbUpOTmbw4ME8+OCDPPzww3h5eQFqx0AHBwemTZuGg4MDGzZs4M033yQ9PZ0PPvjgltedN28eGRkZ/Otf/0Kj0fD+++9z7733cvbs2VvWemzbto2//vqLp59+GkdHRz7//HNGjRpFTEwMbm5uABw8eJBBgwbh4+PDW2+9hV6vZ+bMmXh4eNyybKNHj2bOnDmsWLGC+++/37g9Ozubv//+mwkTJmBhYUFCQgJ33XUXHh4evPLKK7i4uHD+/Hn++uuvcq9vb2/P8OHD+eOPP0hJScHV1dW4b+HChej1esaOHQvA4sWLyc7O5qmnnsLNzY09e/Ywe/ZsLl68yOLFi2/5Xq4XFxdH//79KSws5JVXXsHe3p5vv/0WW1vbUsdW5P6+9tprpKWlcfHiRT755BMAHBwcbvr669atY/DgwTRu3JgZM2aQk5PD7Nmz6dmzJwcOHCjVMfOBBx4gJCSEWbNmceDAAb7//ns8PT3573//W6n3rSgK99xzDxs3bmTSpEm0a9eO1atX8+KLL3Lp0iVj2Y8dO8bdd99N27ZtmTlzJjqdjujoaLZv32681nfffcezzz7Lfffdx3PPPUdubi6HDx9m9+7dPPTQQ5Uql2hgFCEaqMmTJys3/hPo27evAihff/11qeOzs7NLbfvXv/6l2NnZKbm5ucZt48ePV4KCgozPz507pwCKm5ubkpKSYty+bNkyBVD+/vtv47bp06eXKhOgWFtbK9HR0cZthw4dUgBl9uzZxm3Dhg1T7OzslEuXLhm3nT59WrG0tCx1zRsZDAbFz89PGTVqVIntixYtUgBly5YtiqIoypIlSxRA2bt3b7nXK8uKFSsUQPnmm29KbO/WrZvi5+en6PV6RVHK/jnPmjVL0Wg0yoULF4zbyvpZBQUFKePHjzc+nzp1qgIou3fvNm5LSEhQnJ2dFUA5d+6ccXtF7+/QoUNL3N9ixfd57ty5xm3t2rVTPD09leTkZOO2Q4cOKVqtVhk3blyp9/Loo4+WuObIkSMVNze3Uq91oxt/55YuXaoAyjvvvFPiuPvuu0/RaDTG36VPPvlEAZTExMSbXnv48OFKq1atblkGIW4kTSRC3ECn0zFx4sRS26//qzcjI4OkpCR69+5NdnY2J0+evOV1R48eTaNGjYzPe/fuDcDZs2dveW5ERAShoaHG523btsXJycl4rl6vZ926dYwYMQJfX1/jcU2aNGHw4MG3vL5Go+H+++9n5cqVZGZmGrcvXLgQPz8/evXqBYCLiwsA//vf/ygoKLjlda9XXPNxfdX6uXPn2LVrF2PGjDF2zrz+55yVlUVSUhI9evRAURQOHjxYqddcuXIl3bp1o0uXLsZtHh4extqS693u/b3RlStXiIyMZMKECSVqbNq2bcuAAQNYuXJlqXOefPLJEs979+5NcnIy6enplXrtlStXYmFhwbPPPlti+wsvvICiKPzzzz/Atfu5bNmym3ZMdnFx4eLFi6Wa84S4FQkYQtzAz88Pa2vrUtuPHTvGyJEjcXZ2xsnJCQ8PD2MH0bS0tFteNzAwsMTz4rBx9erVSp9bfH7xuQkJCeTk5NCkSZNSx5W1rSyjR48mJyeH5cuXA5CZmcnKlSu5//77jX04+vbty6hRo3jrrbdwd3dn+PDhzJ07l7y8vFte39LSktGjR7N161YuXboEYAwb13/gx8TEGD+UHRwc8PDwoG/fvkDFfs7Xu3DhAmFhYaW2N2vWrNS2272/Zb32zV6rRYsWJCUlkZWVVWL77fyO3Pjavr6+ODo6lnrd68s2evRoevbsyWOPPYaXlxcPPvggixYtKhE2Xn75ZRwcHOjSpQthYWFMnjy5RBOKEDcjAUOIG5TVPp+amkrfvn05dOgQM2fO5O+//2bt2rXGtvGKDEu1sLAoc7tyQ6c7U59bUd26dSM4OJhFixYB8Pfff5OTk8Po0aONx2g0Gv744w927tzJlClTuHTpEo8++igdO3YsUfNxMw8//DAGg4H58+cDMH/+fFq2bEm7du0AtSZmwIABrFixgpdffpmlS5eydu1aY8fJqg7/vRVT3F9TqIn7fD1bW1u2bNnCunXreOSRRzh8+DCjR49mwIABxs6tLVq0ICoqigULFtCrVy/+/PNPevXqxfTp06ulTKL+kIAhRAVs2rSJ5ORkfvrpJ5577jnuvvtuIiIiSjR5mJOnpyc2NjZER0eX2lfWtpt54IEHWLVqFenp6SxcuJDg4GC6detW6rhu3brx7rvvsm/fPn7//XeOHTvGggULbnn9rl27Ehoayrx58zh06BDHjh0rUXtx5MgRTp06xUcffcTLL7/M8OHDiYiIKNHsUxlBQUGcPn261PaoqKgSzytzfys602pQUFCZrwVw8uRJ3N3dsbe3r9C1KisoKIjLly+TkZFR6nWvLxuAVqvlzjvv5OOPP+b48eO8++67bNiwgY0bNxqPsbe3Z/To0cydO5eYmBiGDh3Ku+++S25ubrWUX9QPEjCEqIDivyyv/0syPz+fL7/80lxFKsHCwoKIiAiWLl3K5cuXjdujo6ON7e0VMXr0aPLy8vj5559ZtWoVDzzwQIn9V69eLfXXdHHtQ0WaSUBtDjl48CDTp09Ho9GUGIlQ1s9ZURQ+++yzCr+H6w0ZMoRdu3axZ88e47bExER+//33EsdV5v7a29tXqMnEx8eHdu3a8fPPP5OammrcfvToUdasWcOQIUMq+3YqbMiQIej1er744osS2z/55BM0Go2xX05KSkqpc2+8n8nJySX2W1tb07JlSxRFqXQ/HNGwyDBVISqgR48eNGrUiPHjx/Pss8+i0Wj49ddfq63quipmzJjBmjVr6NmzJ0899ZTxA6Z169ZERkZW6BodOnSgSZMmvPbaa+Tl5ZVoHgH4+eef+fLLLxk5ciShoaFkZGTw3Xff4eTkVOEPzIcffpiZM2eybNkyevbsWWKoZvPmzQkNDeXf//43ly5dwsnJiT///LPSfRCKvfTSS/z6668MGjSI5557zjhMNSgoiMOHDxuPq8z97dixIwsXLmTatGl07twZBwcHhg0bVubrf/DBBwwePJju3bszadIk4zBVZ2dnZsyYUaX3VBHDhg2jf//+vPbaa5w/f57w8HDWrFnDsmXLmDp1qrHD8MyZM9myZQtDhw4lKCiIhIQEvvzyS/z9/Y0de++66y68vb3p2bMnXl5enDhxgi+++IKhQ4eW6uMhRAlmGbsiRC1ws2GqNxuSt337dqVbt26Kra2t4uvrq7z00kvK6tWrFUDZuHGj8bibDVP94IMPSl0TUKZPn258frNhqpMnTy517o1DMhVFUdavX6+0b99esba2VkJDQ5Xvv/9eeeGFFxQbG5ub/BRKe+211xRAadKkSal9Bw4cUMaMGaMEBgYqOp1O8fT0VO6++25l3759Fb6+oihK586dFUD58ssvS+07fvy4EhERoTg4OCju7u7K448/bhyWe/0Q0IoMU1UURTl8+LDSt29fxcbGRvHz81Pefvtt5Ycffig1TLWi9zczM1N56KGHFBcXFwUw3uuyhqkqiqKsW7dO6dmzp2Jra6s4OTkpw4YNU44fP17imOL3cuNw0blz55YqZ1lu/J1TFEXJyMhQnn/+ecXX11exsrJSwsLClA8++EAxGAzGY9avX68MHz5c8fX1VaytrRVfX19lzJgxyqlTp4zHfPPNN0qfPn0UNzc3RafTKaGhocqLL76opKWllVsmITSKUov+BBNCmNyIESM4duxYmX0RhBCiukgfDCHqkRun0z59+jQrV66kX79+5imQEKLBkhoMIeoRHx8fJkyYQOPGjblw4QJfffUVeXl5HDx4sMz5IIQQorpIJ08h6pFBgwYxf/584uLi0Ol0dO/enffee0/ChRCixkkNhhBCCCFMTvpgCCGEEMLkJGAIIYQQwuQaXB8Mg8HA5cuXcXR0rPCUv0IIIYRQZ7vNyMjA19fXuALyzTS4gHH58mUCAgLMXQwhhBCizoqNjcXf37/cYxpcwCie2jY2NhYnJyczl0YIIYSoO9LT0wkICKjQNPENLmAUN4s4OTlJwBBCCCGqoCJdDKSTpxBCCCFMTgKGEEIIIUxOAoYQQgghTK7B9cGoCEVRKCwsRK/Xm7soogosLCywtLSUYchCCGFGEjBukJ+fz5UrV8jOzjZ3UcRtsLOzw8fHB2tra3MXRQghGiQJGNcxGAycO3cOCwsLfH19sba2lr+C6xhFUcjPzycxMZFz584RFhZ2y8lghBBCmJ4EjOvk5+djMBgICAjAzs7O3MURVWRra4uVlRUXLlwgPz8fGxsbcxdJCCEaHPnTrgzyF2/dJ/dQCCHMS/4XFkIIIYTJScAQQggh6qGVR66w7XQSOfnmGREpAUMY9evXj6lTp950/4wZM2jXrl2NlUcIIUTVKIrCO/87zsM/7GbfhRSzlEECRj0wbNgwBg0aVOa+rVu3otFoOHz4cA2XSgghhLlcvJrD5bRcLLUaOgY1MksZJGDUA5MmTWLt2rVcvHix1L65c+fSqVMn2rZta4aSCSGEMIddZ5MBaOPvjJ21eQaMSsC4BUVRyM4vNMtDUZQKlfHuu+/Gw8ODn376qcT2zMxMFi9ezKRJk0hOTmbMmDH4+flhZ2dHmzZtmD9//m39bAwGAzNnzsTf3x+dTke7du1YtWqVcX9+fj5TpkzBx8cHGxsbgoKCmDVrlvHnOmPGDAIDA9HpdPj6+vLss8/eVnmEEEKodp9Tm0W6hriZrQwyD8Yt5BToafnmarO89vGZAyuUPC0tLRk3bhw//fQTr732mnFysMWLF6PX6xkzZgyZmZl07NiRl19+GScnJ1asWMEjjzxCaGgoXbp0qVL5PvvsMz766CO++eYb2rdvz48//sg999zDsWPHCAsL4/PPP2f58uUsWrSIwMBAYmNjiY2NBeDPP//kk08+YcGCBbRq1Yq4uDgOHTpUpXIIIYQoafc5tQajW2NXs5VBAkY98eijj/LBBx+wefNm+vXrB6jNI6NGjcLZ2RlnZ2f+/e9/G49/5plnWL16NYsWLapywPjwww95+eWXefDBBwH473//y8aNG/n000+ZM2cOMTExhIWF0atXLzQaDUFBQcZzY2Ji8Pb2JiIiAisrKwIDA6tcDiGEENdcTs0hNiUHC62GTsESMGotWysLjs8caLbXrqjmzZvTo0cPfvzxR/r160d0dDRbt25l5syZAOj1et577z0WLVrEpUuXyM/PJy8vr8ozlqanp3P58mV69uxZYnvPnj2NNRETJkxgwIABNGvWjEGDBnH33Xdz1113AXD//ffz6aef0rhxYwYNGsSQIUMYNmwYlpbyKymEELejuPaita8TDjrz/Z8qfTBuQaPRYGdtaZZHZddBmTRpEn/++ScZGRnMnTuX0NBQ+vbtC8AHH3zAZ599xssvv8zGjRuJjIxk4MCB5OfnV8ePDYAOHTpw7tw53n77bXJycnjggQe47777AAgICCAqKoovv/wSW1tbnn76afr06UNBQUG1lUcIIRqC3WeL+l80Nl//C5CAUa888MADaLVa5s2bxy+//MKjjz5qDCnbt29n+PDhPPzww4SHh9O4cWNOnTpV5ddycnLC19eX7du3l9i+fft2WrZsWeK40aNH891337Fw4UL+/PNPUlLUX35bW1uGDRvG559/zqZNm9i5cydHjhypcpmEEEJc38HTfM0jIE0k9YqDgwOjR4/m1VdfJT09nQkTJhj3hYWF8ccff7Bjxw4aNWrExx9/THx8fIkwUFkvvvgi06dPJzQ0lHbt2jF37lwiIyP5/fffAfj444/x8fGhffv2aLVaFi9ejLe3Ny4uLvz000/o9Xq6du2KnZ0dv/32G7a2tiX6aQghhKic+PRcziVlodFg1v4XIAGj3pk0aRI//PADQ4YMwdfX17j99ddf5+zZswwcOBA7OzueeOIJRowYQVpaWpVf69lnnyUtLY0XXniBhIQEWrZsyfLlywkLCwPA0dGR999/n9OnT2NhYUHnzp1ZuXIlWq0WFxcX/vOf/zBt2jT0ej1t2rTh77//xs3NvFV6QghRlxXPf9HSxwlnWyuzlkWjVHSyhXoiPT0dZ2dn0tLScHJyKrEvNzeXc+fOERISIkt813FyL4UQDdH/LTnCvN0xPNozhDeHVb2G+mbK+wy9kfTBEEIIIeqJ3WfNP/9FMQkYQgghRD2QmJHHmUS1/0UXM3fwBAkYQgghRL2wp2j0SDMvR1zsrM1cGgkYQgghRL1wbXrw2tFZXgKGEEIIUQ8YJ9iqBc0jIAFDCCGEqPNSsvKJis8Aakf/C5CAIYQQQtR5e4qaR8I8HXBz0Jm5NCoJGEIIIUQdt6uoeaS29L8ACRhCCCGE2ekNCvd+uZ2hn28lt0Bf6fON64/UgvkviknAEDcVHBzMp59+avZrCCFEfXcg5ioHYlI5djmdRftiK3VuWnYBJ+PSgdrT/wIkYNQLGo2m3MeMGTOqdN29e/fyxBNPmLawQgghSll3PN74/VebzpBXWPFajD3nU1AUaOxhj6dj7VkaQRY7qweuXLli/H7hwoW8+eabREVFGbc5ODgYv1cUBb1ej6XlrW+9h4eHaQsqhBCiTGtPqAFDq4Erabn8uf8SD3UNrNC5xdODdw2pPf0vQGowbk1RID/LPI8KrkPn7e1tfDg7O6PRaIzPT548iaOjI//88w8dO3ZEp9Oxbds2zpw5w/Dhw/Hy8sLBwYHOnTuzbt26Ete9sXlDo9Hw/fffM3LkSOzs7AgLC2P58uWV+nHGxMQwfPhwHBwccHJy4oEHHiA+/lpyP3ToEP3798fR0REnJyc6duzIvn37ALhw4QLDhg2jUaNG2Nvb06pVK1auXFmp1xdCiNrmTGImZxOzsLLQ8HxEUwC+3BRNgd5QofOL+1/UhvVHric1GLdSkA3v+d76uOrwf5fB2t4kl3rllVf48MMPady4MY0aNSI2NpYhQ4bw7rvvotPp+OWXXxg2bBhRUVEEBt48Nb/11lu8//77fPDBB8yePZuxY8dy4cIFXF1v/YttMBiM4WLz5s0UFhYyefJkRo8ezaZNmwAYO3Ys7du356uvvsLCwoLIyEisrNQlhydPnkx+fj5btmzB3t6e48ePl6idEUKIuqi4eaRbYzce692Yn3de4OLVHJYcvMQDnQLKPTc9t4Bjl9OA2leDIQGjgZg5cyYDBgwwPnd1dSU8PNz4/O2332bJkiUsX76cKVOm3PQ6EyZMYMyYMQC89957fP755+zZs4dBgwbdsgzr16/nyJEjnDt3joAA9R/NL7/8QqtWrdi7dy+dO3cmJiaGF198kebNmwMQFhZmPD8mJoZRo0bRpk0bABo3blyJn4AQQtRO64qaRwa09MLW2oIn+oTw3sqTfLkxmnvb+2FpcfPGhn3nUzAoEORmh7dz7el/ARIwbs3KTq1JMNdrm0inTp1KPM/MzGTGjBmsWLGCK1euUFhYSE5ODjExMeVep23btsbv7e3tcXJyIiEhoUJlOHHiBAEBAcZwAdCyZUtcXFw4ceIEnTt3Ztq0aTz22GP8+uuvREREcP/99xMaGgrAs88+y1NPPcWaNWuIiIhg1KhRJcojhBB1TXJmHvsvXAXgzhZeAIztGsRXm85wPjmb/x2+woj2fjc9v3h68G61rPYCzNwHY8uWLQwbNgxfX180Gg1Lly695TmbNm2iQ4cO6HQ6mjRpwk8//VS9hdRo1GYKczw0GpO9DXv7kk0t//73v1myZAnvvfceW7duJTIykjZt2pCfn1/udYqbK679eDQYDBVrJ6yIGTNmcOzYMYYOHcqGDRto2bIlS5YsAeCxxx7j7NmzPPLIIxw5coROnToxe/Zsk722EELUtI1RiRgUaOnjhJ+LLQD2Okse663W0M7ecBq94eb98XbVwvkvipk1YGRlZREeHs6cOXMqdPy5c+cYOnQo/fv3JzIykqlTp/LYY4+xevXqai5p/bN9+3YmTJjAyJEjadOmDd7e3pw/f75aX7NFixbExsYSG3ttjPfx48dJTU2lZcuWxm1Nmzbl+eefZ82aNdx7773MnTvXuC8gIIAnn3ySv/76ixdeeIHvvvuuWssshBDVqbj/RURLrxLbx3UPwtnWijOJWfxz9EpZp5KZV8jRS0X9L2rRDJ7FzNpEMnjwYAYPHlzh47/++mtCQkL46KOPAPUDa9u2bXzyyScMHDiwuopZL4WFhfHXX38xbNgwNBoNb7zxhklrIsoSERFBmzZtGDt2LJ9++imFhYU8/fTT9O3bl06dOpGTk8OLL77IfffdR0hICBcvXmTv3r2MGjUKgKlTpzJ48GCaNm3K1atX2bhxIy1atKjWMgsh6o+dZ5KxttTSxs8Za0vzD6LMLdCz5XQiAHfdEDAcbayY2DOYT9ed5osN0Qxp7YNWW7JWe/+Fq+gNCv6NbI21H7VJneqDsXPnTiIiIkpsGzhwIFOnTr3pOXl5eeTl5Rmfp6enV1fx6pSPP/6YRx99lB49euDu7s7LL79c7T8bjUbDsmXLeOaZZ+jTpw9arZZBgwYZmzksLCxITk5m3LhxxMfH4+7uzr333stbb70FgF6vZ/LkyVy8eBEnJycGDRrEJ598Uq1lFkLUDxtOxvPoT+qQdxsrLR0CG9ElxJWuIW60D3TBxsqixsu080wy2fl6vJ1saOXrVGr/xB4hfL/1HCfjMlhzPJ5Brb1L7K+t818Uq1MBIy4uDi+vkinPy8uL9PR0cnJysLUtneBmzZpl/IBqCCZMmMCECROMz/v164dSxnwawcHBbNiwocS2yZMnl3h+Y5NJWddJTU0ttzw3XiMwMJBly5aVeay1tTXz58+/6bWkv4UQdd+200k88es+3rqnFfffYgimKf2w7RwAVhYacgsM7DiTzI4zycBprCw0hPu70CXElS4hrnQKdsVBV/0fj8WTa0W09ERTRp87ZzsrJvQI5ouN0czecJqBrbxKHFcb1x+5nvnriKrZq6++SlpamvFxffu/EEKImvXj9nNk5+v5bP1pDOV0XjSl6IQMtkcno9XAhhf6sfb5PrwzojX3hPvi5aSjQK+w78JVvtx0hglz99J2xmoe+3kf0QkZ1VYmg0FhfXHAaOF10+Me7RWCnbUFxy6nszHq2oi9nHw9hy+mArVzBAnUsRoMb2/vErM+AsTHx+Pk5FRm7QWATqdDp9PVRPGEEEKUIz23gK1FfQ4uXs1hW3QSfZpW/5IEP++4AKgf5AGu6vD/MC9HHu4WhKIoxKbksOtcMnvOpbDnXAoxKdmsOxHPxqgExnQJYGpEU9wdTPs5cvRyGvHpedhbW9A99OYBwdXemke6BfHNlrN8tj6a/s3U2o4DMVcp0Cv4ONsQ4Fr7+l9AHavB6N69O+vXry+xbe3atXTv3t1MJRJCCFFRG04kUKC/VmuxYG/58+6YQnpuAX8euAjA+B7BpfZrNBoC3ex4oFMAH94fzpaX+rNuWl/uaumF3qDw264Y+n2wiTkbo6u0jPrNFI8e6dPUA51l+f0/HuvdGBsrLYdiU9l6OgmAXUX9L7o1diuzeaU2MGvAyMzMJDIyksjISEAdhhoZGWmc7OnVV19l3LhxxuOffPJJzp49y0svvcTJkyf58ssvWbRoEc8//7w5ii+EEKISiodbRrTwBGDt8XiSMvPKO+W2/bn/Itn5epp4OtCjnJqC6zXxdODbcZ1Y+EQ32vo7k5lXyAero+j/4Sb+OnDRJE07a45fm73zVjwcdTzUJQiAz9efRlEU4wRbXWvR8uw3MmvA2LdvH+3bt6d9+/YATJs2jfbt2/Pmm28C6iqh188sGRISwooVK1i7di3h4eF89NFHfP/99yYfolpWZ0ZRt8g9FKJ2yc4vZPMptXnk+QFNCfd3pkCv8Of+i9X2mgaDwq871eaR8d2DKv2XftfGbix9uiefPdgOPxdbrqTlMm3RIe6Zs42dZ5KrXK7YlGxOxmWg1UD/Zp4VOudffRtjball34WrbDqVSGRsqrGMtZVZ+2DcbIRDsbJm6ezXrx8HDx6slvIUz1KZnZ190z4dom7Izs4GSs88KoQwj01RieQWGAh0taOljxMPdgnk0MUjLNwbyxN9GldLNf+26CTOJmXhqLPk3g7+VbqGVqtheDs/BrbyZu7283y5MZqjl9IZ890uIlp48trQloS4V25RyuLOnZ2CXWlkb12hc7ycbHiwcwC/7LzAS38cJl9vwNNRR7Cb6ZaUMLU61cmzullYWODi4mJcW8POzq7Wtm2JsimKQnZ2NgkJCbi4uGBhUfNj24UQpf1zNA6Awa290Wg0DAv35e3/HedsUha7z6XQrRr+Ev95x3kARnX0x/42h53aWFnwVL9QHujkz+frT/Pb7hjWnUjgQEwqq6b2xtOx4guNrTuhfsYMKGf0SFme7BvK/D0xJGaozUpda3H/C5CAUYq3tzqRSUUX8BK1k4uLi/FeCiHMK7dAz4aiv9qLJ4ty0FlyT7gvC/bGsmBPjMkDRkxyNhuKhnWO6x5ksuu6Oeh4a3hrxvUI5unfDhAVn8GLiw/z08TOFfqwT88tMHbQvHF68FvxdbHlvo7+zN+jTrdQm/tfgASMUjQaDT4+Pnh6elJQUGDu4ogqsLKykpoLIWqRbaeTyMrX4+NsQ7i/i3H7g10CWbA3lpVH45iRnY+LXcWaCyri113nURR1lEZjDweTXbdYqIcDsx9qz7DZ29h8KpFfdl4oc5TKjTZHJVJoUAj1sK900wrA0/2asGjfRfQGpdzhrbWBBIybsLCwkA8pIYQwgZVFo0cGtvIusZ5GuL8zzb0dORmXwZKDl5jYM8Qkr5eTr2fhXvWv/Ak9TFd7caOmXo68Org5M/4+znsrT9Aj1I0wL8dyz1lrHD1StRrWAFc7vn2kI6nZBYRWQ3AypTo1D4YQQoi6Jb/QYJzzYfANa2loNBrGdAkEYMGeWJON/loaeYn03EICXe3o27RiozSqanyPYPo29SCv0MCzCyLJK7z5XBkFeoNxNs4BLaterjtbeDGqY9U6rdYkCRhCCCGqzc6zyaTnFuLuYE2n4NJ9Bka080NnqSUqPoODRUMvb4eiKMbOneO6B2Ghrd5OkBqNhg/ub4urvTUnrqTz8ZpTNz1277kUMnILcbO3pl1Ao2otV20gAUMIIUS1WVXUPHJXK+8yP+yd7awY2sYHgAV7bn9mz73nr3IyLgNbKwvu71gzi6l5Otrwn3vbAPDt1rPsOJNU5nHFi5vd0dyz2oNPbSABQwghRLXQGxTWHCu7eeR6DxY1k/x96AoZubfXub649mJEez+c7WpuHpy7WnkzpksAigIvLDpEWnbJ96EoCuuMq6dWbvRIXSUBQwghRLXYcy6F5Kx8nG2tyh2G2jm4EaEe9uQU6Fl+6HKVXy8uLZdVx9T5Nkw5NLWi3rhbnXTrSlou/7f0SIk+JafiM4lNyUFnqaV3mHuNl80cJGAIIYSoFsbmkZZeWFnc/ONGo9HwYOdrnT2r6vfdF9AbFLqEuNLCx6nK16kqO2tLPh3dDkuthhWHr/DXgUvGfWuPq8GnVxN37KwbxgBOCRhCCCFMzmBQjLUJg9vcekjmvR38sLLQcORSGkcvpVX69fIK9cwv6sMxoQLzUVSX8AAXpkaEATB9+TFiU9RlC9YWzd7ZUJpHQAKGEEKIanAwNpX49DwcdZb0bHLrJgE3Bx13tVKDSFWWcV955ApJmfl4O9lUaIXS6vRUvyZ0CmpEZl4hzy+M5EpaDoeKRsjc2bx6h83WJhIwhBBCmNw/R9TmkTtaeKKzrNikhQ8VdfZcdvAy2fmFlXq9n3eoq6Y+3C2w3OaYmmCh1fDJ6HY46CzZd+Eqk37aB6i1G55OFV+zpK6TgCGEEMKkFEUpsbhZRXVv7Eagqx0ZeYWsOHylwucdik0lMjYVawutcUSKuQW42jFzeCsAjl9JB2BAi4ZTewESMIQQQpjY0UvpXErNwdbKolIzaWq1GkZ3VueuWLC34p09f955HoC72/rg7qCrVFmr08j2ftzd1sf4vKrTg9dVEjCEEEKY1D9Fo0f6NfPA1rpyazrd39EfC62G/Reucio+o9xjcwv0rD0ez/8Oqa83zoydO8ui0Wh4d0Qb2vg5c2dzT5p61e61Q0ytYYyVEUIIUSMURWFVUfPIoEo0jxTzdLLhzuaerDkez4I9sbw5rGWJ/YkZeWw8mcDaE/FsPZ1IboEBgPaBLrQLcLnt8puas50Vfz/Ty9zFMAsJGEIIIUzmVHwmZ5OysLbQckcVR0yM6RLImuPx/HXwIi8NakZMSjZrj8ez7kQ8kbGpXL8mmp+LLXe28GRK/yYmegfCVCRgCCGEMJni5pHeYe442lRtqu4+TT3wdbbhclouPf+zgeSs/BL72/o7E9HCi4gWXrTwcUSjqf/retRFEjCEEEKYzO00jxSz0Gp4oHMAn647TXJWPtaWWnqGuhHR0os7m3vh7dxwhnrWZRIwhBBCmMTZxExOxmVgqdXc9mRXT/YNxUFniX8jO3qHuWOvk4+rukbumBBCCJMonvuie6gbLnbWt3UtGysLHuvd2BTFEmYiw1SFEEKYxCrj5Fo+tzhSNAQSMIQQQty22JRsjlxKQ6uBu1o1nAW9xM1JwBBCCHFbCvUGvtgQDUDnYNdaNZumMB/pgyGEEKLKUrLymTLvADvOJAPwSPcgM5dI1BYSMIQQQlTJ0Utp/OvX/VxKzcHO2oIP7w9nSBvpfyFUEjCEEEJU2l8HLvLqX0fIKzQQ4m7PN490pKmXo7mLJWoRCRhCCFGPKIqCoqgrk1aHAr2Bd1ec4Kcd5wG4o7knn4xuh7Nt1WbtFPWXBAwhhKgD9AaF6IRMEjPySMosfuQbv08u+j45Mx+dlZZXB7dgTJcAk06jnZiRx+R5B9hzLgWAZ+8MY+qdYdUWZkTdJgFDCCHqgKd/38/qY/EVOjZfb+D/lhxh19lk3ru3DQ4mmAXzUGwqT/62nytpuTjoLPn4gXDualX16cBF/ScBQwgharkLyVnGcBHm6YC7gw53Rx3uDtbq98av6vb/HbrM+6ujWH7oMkcvpTFnbAda+DhV+fUX7Y3l9WVHyS800NjDnm8f6UQTTwdTvT1RT0nAEEKIWm7B3lgA+jb14OdHu9zy+H/1DaVjUCOemX+Qs0lZjJiznbfuacXozhVvMlEUhR1nkvlmy1m2nEoEYEBLLz5+ILzKq6SKhkUChhBC1GL5hQYW71MDxpgugRU+r1OwKyue7c20RZFsikrklb+OsPtcCu+MaF3uwmEFegMrDl/h2y1nOX4lHQCtBqZGNGVK/ybS30JUmAQMIYSoxdafiCcpMx8PRx13tvCs1Lmu9tb8OL4zX285w0drTrHk4CUOX0zly7EdaeZdckhpRm4BC/bE8uP2c1xJywXA1sqCBzr5M6lXYwLd7Ez2nkTDIAFDCCFqsXl7YgB4oJM/VhaVX91Bq9XwdL8mdApy5Zn5BziTmMXwOduYObw1D3QK4EpaDj9tP8+83TFk5BUC4O6gY0KPIMZ2DaKR/e2tiioaLo2iKIq5C1GT0tPTcXZ2Ji0tDSenqnd6EkKI6habkk3v9zcCsPWl/gS43l4tQnJmHs8vOmTsU9EuwIWjl9IoNKgfA6Ee9jzRpzHD2/lhY2Vxe4UX9VJlPkOlBkMIIWqpBXvV2oveYe63HS4A3Bx0/DShM19uiubjtaeIjE0FoFtjV57o05h+TT2lj4UwGQkYQghRCxXoDSzadxGAhyrRufNWtFoNU+4Io2tjN9Yci2NYuC9t/V1Mdn0hiknAEEKIWmj9iQQSM/Jwd9AR0dLL5NfvHOxK52BXk19XiGKV7zEkhBCi2s0v6tx5fxU7dwphbvJbK4QQtUxsSjZbTqsdMR/sHGDm0ghRNRIwhBCillm0LxZFgV5N3Alyszd3cYSoEgkYQghRixTqDSzcW/mZO4WobSRgCCFELbLhZAIJGXm42VszoBo6dwpRUyRgCCFELVLcufO+Tv5YW8p/0aLukt9eIYSoJS6l5rDpVHHnTmkeEXWbBAwhhKglFu5VO3f2CHUjxF06d4q6TQKGEELUAoV6A4uKOnc+KJ07RT0gAUMIIWqBTVGJxKXn0sjOioGtpHOnqPskYAghRC1g7NzZ0R+dpaxkKuo+CRhCCGFml1Nz2BiVAEjziKg/JGAIIeqtAr2BqQsO8p9/Tpq7KOVatC8WgwJdQ1wJ9XAwd3GEMAkJGEKIWiM2JZtO76zl/5YcMcn1tkcnsTTyMl9vPsOecykmuaap6Q2KsXPnQ12l9kLUHxIwhBC1xoK9MSRl5rNobyxpOQW3fb01x+ON33+0JgpFUW77mqa25VQil9NycbGzYmArb3MXRwiTkYAhhKgVFEVhWeRlAAoNChtOxt/ijPIZDAprrwsYu8+lsONM8m1dszr8uusCAKM6+GNjJZ07Rf0hAUMIUSvsv3CVi1dzjM9XHY27retFXkwlMSMPR52lsemhttVibDgZz4aTCWg1srCZqH/MHjDmzJlDcHAwNjY2dO3alT179pR7/KeffkqzZs2wtbUlICCA559/ntzc3BoqrRCiuiw5eAmANn7OAGw+lUh2fmGVr7fmmFp70b+5J1PvDENnqeVATCqbohJvv7AmkJlXyOtLjgIwqVcITTylc6eoX8waMBYuXMi0adOYPn06Bw4cIDw8nIEDB5KQkFDm8fPmzeOVV15h+vTpnDhxgh9++IGFCxfyf//3fzVcciGEKeUXGlhx5AoALw1qRoCrLbkFBracqnoYWHNcrQG5q5UXnk42jOseBMDHa0/VilqM91ed5HJaLoGudkwb0MzcxRHC5MwaMD7++GMef/xxJk6cSMuWLfn666+xs7Pjxx9/LPP4HTt20LNnTx566CGCg4O56667GDNmzC1rPYQQtduWU4mkZhfg4aijR6g7g4o6O1a1mSQ6IYOziVlYW2jp29QDgCf7hmJnbcGRS2klOn+aw77zKca+F7PubYOttfS9EPWP2QJGfn4++/fvJyIi4lphtFoiIiLYuXNnmef06NGD/fv3GwPF2bNnWblyJUOGDLnp6+Tl5ZGenl7iIYSoXZZEqs0j94T7YqHVMKi1GjDWn0ggr1Bf6eutLmoe6dHEDUcbKwDcHHRM7BkMwCdrT2EwmKcWI7dAz8t/HkZR4IFO/vRs4m6WcghR3cwWMJKSktDr9Xh5lZxz38vLi7i4sv9qeeihh5g5cya9evXCysqK0NBQ+vXrV24TyaxZs3B2djY+AgICTPo+hBC3JyO3gHVFNQoj2vkB0D6gEZ6OOjLyCqs08qO4huKuliWHfT7euzGOOktOxmUYm2Rq2pyN0ZxJzMLDUcdrQ1qapQxC1ASzd/KsjE2bNvHee+/x5ZdfcuDAAf766y9WrFjB22+/fdNzXn31VdLS0oyP2NjYGiyxEOJWVh+LJ6/QQGMPe1r7OQGg1WqMc0KsrmQzSVxaLodiU9FoIKKlZ4l9LnbWTOodAsCn606hr+FajBNX0vlq0xkA3h7eCmc7qxp9fSFqktkChru7OxYWFsTHl2wLjY+Px9u77Mlm3njjDR555BEee+wx2rRpw8iRI3nvvfeYNWsWBoOhzHN0Oh1OTk4lHkKI2mNp0eiRke380Gg0xu3FzSRrjsdXKgisPaH+n9IhsBGejjal9j/aKwQXOyvOJGaxrKhppiYU6g28/OdhCg0Kg1p5M6i1T429thDmYLaAYW1tTceOHVm/fr1xm8FgYP369XTv3r3Mc7Kzs9FqSxbZwkLtHFUbeoULISonIT2XHWeSABhe1DxSrEuIKy52VqRk5bP3fMWn+V5zrGj0SMuylzx3srHiiT6NAfhs/WkK9GX/cWJqc7ef5/DFNJxsLJk5vFWNvKYQ5mTWJpJp06bx3Xff8fPPP3PixAmeeuopsrKymDhxIgDjxo3j1VdfNR4/bNgwvvrqKxYsWMC5c+dYu3Ytb7zxBsOGDTMGDSFE3bH80GUMCnQIdCHQza7EPisLLREt1JBQ0dEkaTkF7Czqs3FXOdNuj+8ejJu9NReSs/lz/8Uqlr7iLiRn8dHaKABeG9oCT6fSNStC1DeW5nzx0aNHk5iYyJtvvklcXBzt2rVj1apVxo6fMTExJWosXn/9dTQaDa+//jqXLl3Cw8ODYcOG8e6775rrLQghbsPSoiaKke39ytw/qJU3f+y/yOpjcUwf1rJEE0pZNkUlUGhQCPN0IMTd/qbH2esseapfKO+sOMHsDdGM7OCHzrJ6/khRFIVX/zpCboGBHqFuPNBJOpqLhkGjNLC2hfT0dJydnUlLS5P+GEKYUXRCBhEfb8FSq2HPaxG42luXOia3QE+Ht9eSna9n2eSehAe4lHvNyfMOsOLwFSb3D+XFgc3LPTa3QE/fDzYSn57H28Nb8Uj34Nt4Nze3aG8sL/15GBsrLaun9iHI7ebBR4jarjKfoXVqFIkQov5YelBd2KxPU48ywwWAjZUF/ZurI0FWHSu/mSSvUM+mk+oswDcOT73ZtSf3bwLA7A3R5BZUfr6NW0lIz+WdFccBmDagqYQL0aBIwBBC1DhFUVh2SG0eGXGT5pFi18/qWV6F647oZLLy9Xg72RjXM7mV0Z0D8HOxJSEjj9+KZtY0penLj5GeW0gbP2ce7Rli8usLUZtJwBBC1LgDMVeJTcnB3tqCAS3KHu1RrH9zT6wttJxLyuJUfOZNjytee2RASy+02vL7ahTTWVrwzB1qLcbXm8/c1uJq10vPLWDR3lj+ORqHpVbDf0e1xdJC/rsVDYtZO3kKIRqm4pVTB7byvuU6HA46S3qHubP+ZAKrjsbRzNux1DF6g8La4tk7W5UfWG40qqM/X246Q0xKNp+vj2Zkez90llpsrCxKfL0+tCiKQmJGHhdSsjmflEVMSjYXkrO5kJJNTHIWV7MLjMf+q29jWvpKfy/R8EjAEEKUUqg3sPpYPH2auhvX8jCVAr2BFYfVabpv1TxSbFBrbzVgHIvjuYiwUvsjY6+SlJmPo40lXUPcKlUeKwstUyPCmLboEF9vPsPXm8+UeZy1hRadlRadpQVZeYXk3KLPhruDjj5N3XnmjtLlFaIhkIAhhCjl261neX9VFHc09+THCZ1Neu0tpxK5ml2Au4OOHqEVCwMRLbyw0Go4cSWdC8lZpTpLrila3OyO5p5YW1a+KWJ4Oz/Wn0zg4IWr5BUayC3Qk1dooPC6GUTz9Qby9QYyUJtRtBrwdbElyM2OIDd7glztCHKzI9DVnkA3Oxx08t+raNjkX4AQogSDQWHBHnXNng0nE9h2OoleYaZb8bO4eWRYuE+F+yU0sremW2NXtkcns/pYHE/0CTXuUxSF1UUjTAaWM7lWeSy0GuY81KHU9kK9oUTgKP6qs9Ti38iuSmFGiIZC/nUIIUrYcz6FmJRs4/N3Vhw32aJgmXmFrCtaK+Rmk2vdzPWjSa4XnZDJ+eRsrC219GnqYZJyFrO00GKvs8TNQYeviy2NPRxo4eNEYw8HCRdC3IL8CxFClLB4nzp19sBWXjjZqEub/3nANNNprz4aR26Bgcbu9hUeSlqseOrvAzGpxKfnGrcXL83eq4m7NEsIUYtIwBBCGGXlFfLPUbUD5uO9Gxs7KH64OsokQziLpwYffsPKqRXh5WRDh0AX4NqCZtd/f7PFzYQQ5iEBQwhhtOLIFbLz9TR2t6djUCPG9QgiwFWdiOrbLWdv69oJGblsj1ZXTh3R3rdK1yhewv2fomaSK2k5HLqYhkYDd95iPg0hRM2SgCGEMPqjqHlkVEd/NBoNOksLXh6krunxzeazJFzXNFFZfx+6gkGB9oEuVZ4yu7gT5+5zKaRk5RvnvugY2AgPR12VyyaEMD0JGEIIAM4nZbHnfApaDYzq4G/cPrSNDx0CXcgp0PPRmlNVvv7SotEjI9pVrnPn9YLc7Gnh44TeoLDuRLxxeGplJ9cSQlQ/CRhCCAD+2K/WXvQO88Db2ca4XaPR8NrQlgAs2h/LiSvplb52ZGwqRy6lYaHVcHdbn9sqZ/FoksX7Ytl1NhmAARVY3EwIUbMkYAgh0BsU40iR+zv5l9rfMagRQ9v6oCjw3soTlbr2wZirjPthNwADWnjh5nB7TRnF/TD2nr9KoUGhqZcDIe6ySqkQtY0EDCEE26OTuJKWi7OtFRE36Sz58sDmWFto2Xo6iU1RCRW67o4zSYz9fjfpuYV0DGrEf+9re9tlberlQOPrAkVFlmYXQtQ8CRhCCBYXNY/cE+6LjVXZi48FutkxvkcQoNZiFOoN5V5z3fF4JszdS3a+nl5N3Pl1UhecbW9/XRONRsPA1tdCRVVn7xRCVC8JGEI0cGnZBcaptstqHrnelP5huNhZcSo+k0X7bj751rLISzz5237yCw3c1dKL78d3ws7adJNg3d3WB40Ggt3saO0nK5UKURtJwBCigVt++DL5hQaaeTnecnZNZzsrni2afOvjtafIzCs9+da83TFMXRhJoUFhZHs/vhzb4aa1IlXVyteZP57szq+TulZ6wi4hRM2QgCFEA/fHPnVhs/s7+Vfow/rhbkEEu9mRlJnHNzcsbf7tljP835IjKAo83C2Qj+4Pr/CCZpXVMciVAFe7arm2EOL2ScAwkeOX0zGYaEEoIWrKqfgMDl1Mw1KrYUQFFx+zttTyyuAWAHy39SxX0nJQFIWP10Tx3sqTADzZN5S3h7dGq5XaBSEaKlkZyASeW3CQZZGX+WpsBwa3ub0x/kLUpOK5L/o398S9EsNHB7byokuwK3vOp/DBqiic7ayYu/08AC8ObMbk/k2qo7hCiDqkSjUYsbGxXLx4rYPXnj17mDp1Kt9++63JClaXFE97PHtDNIoitRiibijQG/jrgDq75v0dy+/ceSN18i21FuOvg5eM4WLm8FYSLoQQQBUDxkMPPcTGjRsBiIuLY8CAAezZs4fXXnuNmTNnmrSAdcGjPYOxt7bg+JV0Npys2PwAQpjb5qhEkjLzcHewpn9zz0qfHx7gwvB26qJlWg18dH8447oHm7iUQoi6qkoB4+jRo3Tp0gWARYsW0bp1a3bs2MHvv//OTz/9ZMry1QkudtY80k2dH+BzqcUQdcTi/WrnzhHt/LCqYkfMN+9uySPdgpg7sQujKlkLIoSo36r0v0pBQQE6ndpeu27dOu655x4AmjdvzpUrV0xXurriymFeuPgM/lbpHIpNZVvRktRC1FbJmXmsP6HWtt3fKaDK13Fz0PH2iNb0bephqqIJIeqJKgWMVq1a8fXXX7N161bWrl3LoEGDALh8+TJubm4mLWCtpyiwbDJWl/fyp/37OJPJ7PXR5i6VEOVaGnmZQoNCW39nmnk7mrs4Qoh6qEoB47///S/ffPMN/fr1Y8yYMYSHhwOwfPlyY9NJg6HRwAM/g4M3Xrln+dX6vxw7f8m4yqMQtY2iKCwunvtCmjWEENWkSsNU+/XrR1JSEunp6TRq1Mi4/YknnsDOrgFOfOPaGMYthblDaJtzhh+sP+Sb9Z50a9zH3CUTopRjl9M5GZeBtYWWYeG+5i6OEKKeqlINRk5ODnl5ecZwceHCBT799FOioqLw9Kx8b/R6wbMFPPIXBmsHumlP8EjMGxw8F2/uUonboCgKZxMz+XnHeR77eS8Pf7+bf45cqfMTqhXXXgxo5YWLnbWZSyOEqK+qVIMxfPhw7r33Xp588klSU1Pp2rUrVlZWJCUl8fHHH/PUU0+Zupx1g297tGMXk//TCO6wiGTv4sfg30tBa9p1GET1ScspYEd0EltOJ7H1dCIXr+aU2L8tOommXg48c0cYQ9r4YFHHZqrMK9Sz7NBlQJpHhBDVS6NUYUylu7s7mzdvplWrVnz//ffMnj2bgwcP8ueff/Lmm29y4sSJ6iirSaSnp+Ps7ExaWhpOTtWzCmPc/hW4Ln8Ea42eq01H0+jBr0Ers7LXRnqDQmRsKltOJbL1dCKRsalcX0FhbaGlU3Ajeod5kJ1fyE87zpORqy7wFephzzN3hHF3W59qW2/DVJIy89hxJpnVR+NYceQK3k42bH/ljjoXkIQQ5lWZz9Aq1WBkZ2fj6Kj2PF+zZg333nsvWq2Wbt26ceHChapcsl7x7jiUHw9MZ/zF6TQ6tRBWu8KgWWqHUFFr5BXqefj73ew9f7XE9lAPe/o09aBPmAddG7uWWGb8sd6N+XnHeX7Ydo4ziVlMXRjJZ+tPM7l/E0a08601QSM9t4DdZ1PYcSaJHdHJRMVnlNg/unOAhAshRLWqUg1G27Zteeyxxxg5ciStW7dm1apVdO/enf379zN06FDi4uKqo6wmURM1GADRCRl89dk7fGT1tbqh78vQ//+q7fVE5c1YfoyfdpzHztqC/s086R3mTu+mHvi52N7y3IzcAn7ZeYHvt57lanYBAIGudkzuH8rI9v5YW9Zs0DAYFHadTWZbdBLbzyRz5GLJmhiAFj5O9Ah1o1cTd/o09ZCAIYSotMp8hlYpYPzxxx889NBD6PV67rjjDtauXQvArFmz2LJlC//880/VSl4DaipgAEz+/QBux39iptXP6oYBb0PPZ6v1NUXFrDp6hSd/OwDA3AmdqzRVNkBWXiG/7brAt1vOkpyVD4Cfiy1P9gvl/o7+2FhVf/+bvEI9z8w7yJrjJTsVh7jb0z3UjZ6h7nRr7IpbJRYzE0KIslR7wAB1DZIrV64QHh6Otqh/wZ49e3BycqJ58+ZVuWSNqMmAcfxyOkM+38pky2W8aLlQ3Xj3p9BpYrW+rihfbEo2Qz7fSkZuIf/q05hXh7S47Wtm5xcyb3cM32w5S2JGHgCejjqe6NOYh7oGlmhmMaWcfD3/+m0/W04lYm2p5e42PvRo4k73ULcK1cQIIURl1EjAKFa8qqq/f93okV6TAQPgsZ/3se5EPD/4reDO5N8BDQx8D7o9VeU+GTn5es4nZ3E+KYur2QVEtPTE09HGtAWvp/ILDdz/zU4OxabSPtCFRf/qXuV1OMqSW6Bn0b5Yvt50hstpuQC42lszqVcIj3QPwsnGymSvlZlXyKSf9rL7XAq2VhZ8P74TPZu4m+z6Qghxo2oPGAaDgXfeeYePPvqIzMxMABwdHXnhhRd47bXXjDUatVFNB4xDsakMn7MdCy1EdlqL4+G56o4Ww+CeL8DWpczzcguKQ0S2MUycS8riQnI2cem5JY71dbZh/hPdjMvGi5t7d8Vxvtt6DicbS1Y+1xv/RtUzMVx+oYElBy/y5aYzXEjOBsDRxpKJPYKZ2DOERva3N/9EWk4BE+bu4WBMKo46S+ZO7EynYFdTFF0IIW6q2gPGq6++yg8//MBbb71Fz549Adi2bRszZszg8ccf5913361ayWtATQcMgHE/7mHLqUTGdA5glv9OWP0aGArAJUidZty3PaDWTKw5HsdfBy6xLToJfTkTOjnbWhHsbk9SRh6XUnPwcbZh/uPdCHaXkHEz60/EM+nnfQB880hHBrbyrvbXLNQb+N/hK3yxMZroBDWM21tb8HC3ICb1DqlSzVNKVj6P/LCbY5fTcba14tdJXWjr72LikgshRGnVHjB8fX35+uuvjauoFlu2bBlPP/00ly5dquwla4w5Asbe8ync//VOrCw0bHmpPz4Zx+GPCZAag2JhzbmO/8eXmf1ZdSyezLxC43lONpaEuNsT5GZPsLs9Ie52BLvZE+xmb/wLOCE9lzHf7eJMYhbeTmpNRoiEjFIup+Yw5POtpGYXMLFnMNOHtarR1zcYFFYfi2P2hmiOX0kHQGep5d4OfjzaM4Qwr4otOJaQnsvY73dzOiETdwdrfp3UlRY+NfN7LIQQ1R4wbGxsOHz4ME2bNi2xPSoqinbt2pGTk3OTM83PHAED4MFvd7LrbAoTegQz455WnI2JRb/kacKubgHgf/quvFLwOC6N3Li3vR8j2vsR4m6PpgL9NBIz8njou12cTsjE01HH/Ce6EerhUN1vqc4o1Bt48Ntd7LtwlTZ+zvzxVHd0luaZXVVRFDZGJTB7QzQHY1KN2/s182BSrxB6NXG/6T2/nJrD2O93cy4pCy8nHb8/1o0mnnKfhRA1p9oDRteuXenatSuff/55ie3PPPMMe/bsYffu3ZW9ZI0xV8DYHp3E2O93o7PU0szbkcMX0wCFSRb/8IrVfKzQk+sYjPWYX9D6hlf6+kmZasg4Fa+GjHmPy4dPsQ9Wn2TOxjM46iz537O9akVfFUVR2HfhKt9vPcua4/EU/yts7u3Io71CuCfct8QQ1wvJWTz03W4upebg38iWeY91I9CtAS4sKIQwq2oPGJs3b2bo0KEEBgbSvXt3AHbu3ElsbCwrV66kd+/eVSt5DTBXwFAUhVFf7eBA0V+tlloN/Zp5MLK9PxFOF9AteQzSYsFCB4P/Ax0nVnqUSXJmHmO/383JuAw8HHXMf7wrTTwrVvVuDrkFevadv8r2M0nsOZeCl5OOZ+8Mo7m36e7LllOJjJ+7B0WBLx5qz91ta9/qoReSs5i7/TyL9sWSna8HwN3Bmke6BfNwt0CuZhcw9vtdxKfnEeJuz++PdcVXhqAKIcygRoapXr58mTlz5nDy5EkAWrRowRNPPME777zDt99+W5VL1ghzBQyAqLgMZm84TaegRgwL9y058VF2Cix9Ck6tUp+3vg/u/hhsnCv1GilZ+Tz03S5OxmXg7qCGjIq271e3Qr2BI5fS2HEmmW2nk9gfc5X8QkOJYzQaGNnej2kDmt72CI+E9FwGf7aV5Kx8xnYN5N2RbW7retUtLaeABXti+GnHea4UDXG1ttRiY6klPbeQpl4O/PZYVxmSLIQwmxqdB+N6hw4dokOHDuj1elNd0uTMGTBuyWCAnbNh3Vug6MHWFfq+BJ0eBcuKz8J4NSufsd/v5viVdNzsrZn3eDeaeZsnZJxNzGTLqUS2n0lm15lkMq7rxArg7WRDjyZudAtxY/OpRFYcuQKoi4yN6x7E5P5NqjSkU29QePj73ew8m0xzb0eWTu5ZI7NqmkKB3sA/R+P4YetZDl1MA6C1nxO/PNoV19sc3iqEELdDAkY5anXAKBazC5ZNgeTT6nOXILjzTWh1b4VXZU3NVkPGsctqyPj98a4mbXooT3x6Ln8fuszSyEscvZReYp+TjaU6fXUTd3qEuhPqUbIja2RsKv/95yQ7zyYD4Kiz5Ml+oUzsGVyh2TCz8go5cimNpQcvsWBvLHbWFvz9TK862elVURT2X7hKZGwqD3QOMOkkXUIIURUSMMpRJwIGgL4QDv4Km2ZBZtEaEz7tYMBb0LhfhS6Rmp3PIz/s4cilNFztrfn3Xc1o4ulAiLs97g7WFRqhUlHpuQWsOhrHsshL7DiTbOy0aKnV0LWxKz2buNOriTutfJ1vuciWoihsOZ3Ef/45yYmiIZ2ejjqmRjTlgU7+xhVL8wr1nLySweGLqRy6mMbhi6lEJ2SWWOTrk9HhjGxfN2aZFUKI2k4CRjnqTMAolp8FO7+E7Z9CvjpRE6F3qkHD+9Z9CtKyCxj3425jVXsxB506x8aNj2B3e5xsLCsUPvIK9WyKSmRZ5CXWnUgo0Z+iY1AjRrTzZWhb3ypX6xsMCssPXebDNVFcvKoOfW5ctIDX0UtpnLiSQb7eUOo8H2cb2vo7M7i1DyPa+1XptYUQQpRWbQHj3nvvLXd/amoqmzdvloBRHTITYcv7sO9HMBQCGgh/EPq/Bi4B5Z6allPA15vPcPRSGueTs7h4NYfy7rqFVoONpRZbawt0lhbYWltgY6XFpuh7naUFFlrYdTaFtJwC43lNPB0Y0c6X4e38CHA13RDKvEI983bHMHtDNClFK5YWc7Gzoq2/C+H+zoT7u9A2wFk6QQohRDWptoAxcWLFVgGdO3duRS9Z4+pswCiWfAY2vA3HlqjPLXTQbBA0GQBhA8Dx1tNf5xboiU3J5mzStTVOzhZ9LV4JtKI8HXXcE+7LiPZ+tPJ1Mmmzy40ycguYtzuG5Kx82vipgSLA1bZaX1MIIcQ1ZmsiqQvqfMAodmk/rJ0O57eW3O7dVg0aYXeBXyewqNwy4Vl5hWTlFZJToCe3wEBOgZ6cfD25hXpyi77m5BvIK9TT1MuRbo3dbtmnQgghRP0gAaMc9SZgACgKXD4Ap9bA6TXq99ezcYHQO9Sw0SQCHDzMUkwhhBD1gwSMctSrgHGjzEQ4s14NG9HrITe15P4298Og/4K9m1mKJ4QQom6TgFGOeh0wrqcvVJtRoteqgePKIXW7nTsM/RBajTRv+YQQQtQ5EjDK0WACxo0uHYBlkyHhuPq8xT0w9CNw8DRvuYQQQtQZlfkMrdi0kKLu8+sAT2yCvi+D1hJOLIc5XeDwIsodsyqEEEJUgQSMhsRSB/3/Dx7fqE7SlXMV/noc5o+B9MvmLp0QQoh6xOwBY86cOQQHB2NjY0PXrl3Zs2dPucenpqYyefJkfHx80Ol0NG3alJUrV9ZQaesJn7ZqyLjjddBawal/YE43OPib1GYIIYQwCbMGjIULFzJt2jSmT5/OgQMHCA8PZ+DAgSQkJJR5fH5+PgMGDOD8+fP88ccfREVF8d133+HnJ9NBV5qFFfR5EZ7cCr4dIC9N7aPx2yhIPGXu0gkhhKjjzNrJs2vXrnTu3JkvvvgCAIPBQEBAAM888wyvvPJKqeO//vprPvjgA06ePImVVdVWlmywnTzLoy+EnV/AxvdAXzSTp39ndSryVveCnat5yyeEEKJWqBOdPPPz89m/fz8RERHXCqPVEhERwc6dO8s8Z/ny5XTv3p3Jkyfj5eVF69atee+998pd+yQvL4/09PQSD3EDC0voNRWe2g5NB4HGAi7uhRUvwIdNYeHDcHIFFObf8lJCCCEEQOXmkTahpKQk9Ho9Xl5eJbZ7eXlx8uTJMs85e/YsGzZsYOzYsaxcuZLo6GiefvppCgoKmD59epnnzJo1i7feesvk5a+X3MPgoYWQEQ9H/4BD8yHuCJz4W33YukKb+9SaDd8OIGuACCGEuAmzNZFcvnwZPz8/duzYQffu3Y3bX3rpJTZv3szu3btLndO0aVNyc3M5d+4cFhYWAHz88cd88MEHXLlypczXycvLIy/v2gJe6enpBAQESBNJRcUdhcML1OGsmfHXtrs3hc6PQccJ6ugUIYQQ9V5lmkjMVoPh7u6OhYUF8fHxJbbHx8fj7V32iqA+Pj5YWVkZwwVAixYtiIuLIz8/H2tr61Ln6HQ6dDr5AKwy79bg/Q7cOQPOblJrNU7+D5JOwT8vwfbPoe9L0O4hteOoEEIIgRn7YFhbW9OxY0fWr19v3GYwGFi/fn2JGo3r9ezZk+joaAwGg3HbqVOn8PHxKTNcCBOysISwCLjvB/j3aRjyITj6QvpF+PvZa5N2GW7eH0YIIUTDYdZhqtOmTeO7777j559/5sSJEzz11FNkZWUxceJEAMaNG8err75qPP6pp54iJSWF5557jlOnTrFixQree+89Jk+ebK630DDZOEGXx+HZgzBwlrq+ScpZddKur3rC8eUyn4YQQjRwZmsiARg9ejSJiYm8+eabxMXF0a5dO1atWmXs+BkTE4NWey0DBQQEsHr1ap5//nnatm2Ln58fzz33HC+//LK53kLDZmUD3Z+GDuNgzzew/TNIPAGLHgGfcLjjDXWZeOkMKoQQDY4sdiZMJycVds6BXV9Cfqa6LaAb3PkmBPc0a9GEEELcvjoxD4aoh2xd4I7X4LlD0H0KWNpA7C74aQgsGgdXz5u7hEIIIWqIBAxhevbuMPBdeDYSOk4EjRaOL4MvOsO6GZCXYe4SCiGEqGYSMET1cfKBYZ/Ck9sgpC/o82HbJ/B5BzjwK1w3GkgIIUT9IgFDVD+vVjBuGTw4H1wbQ1YCLJ8C3/WDCzvMXTohhBDVQAKGqBkaDTQfAk/vhrveAZ0TXDkEcwfDovFw9YK5SyiEEMKEZBSJMI/MRNj4Lhz4GRQDWOig9b3g0VxdE8UtDFxDZHZQIYSoRSrzGSoBQ5hX3FFY/Sqc21J6n8YCGgUXBY4m14KHdxt1si8hhBA1qk6sRSIEoK51Mm45nN0IsXsg6TQkn4akaCjIgpQz6uN6VvbqTKI9nlFHrAghhKh1pAZD1E6KAumXi8LGaUiOVr8mnoT0S+oxVnbQeRL0eBYcPM1bXiGEaACkiaQcEjDqOEWBU6tg03/gSqS6zdIWOj0KPZ8DRy+zFk8IIeozCRjlkIBRTygKnF4Lm/8Dl/ar2yxtoOME6DlVnYNDCCGESUnAKIcEjHpGUeDMetj0X7i4R91moVMXYOv5HLgEmLd8QghRj0jAKIcEjHpKUeDsJtj8X4jZeW27Xyd1/o3md4N7U1nZVQghboMEjHJIwKjnFAXOb4UtH5Qe+uoaCs2Hqg//zqC1ME8ZhRCijpKAUQ4JGA1I+hU49Q+cXAnnNqtroRSz94Cmg9SajcZ9wcrWfOUUQog6QgJGOSRgNFC56WpfjZMr4NQayEu7ts/GGbpNhm5Pqt8LIYQokwSMckjAEOgL4Pw2iFqpBo7ieTVsXKD7FOj6L5kpVAghyiABoxwSMEQJBj0cW6J2Dk06pW6zcYEeU6CLBA0hhLieBIxySMAQZSoraNg2ulajoXM0b/mEEKIWkIBRDgkYolwGPRz9Sw0ayafVbbaN1HVPujwhQUMI0aBJwCiHBAxRIQY9HP2zKGhEq9usHSG4JwT3hpDe4NUGtFrzllMIIWqQBIxySMAQlaIvvBY0blzV1cYFgntBSB81dHi2kIm8hBD1mgSMckjAEFVi0EPcYTi3VZ3I68IOyM8seYyduxo4gnuBTzh4tQJre/OUVwghqoEEjHJIwBAmoS9UV3M9t1kNHTG7oDDnhoM04NYEvNuoD5+24N1WlpYXQtRZEjDKIQFDVIvCfHVV1/NbIXY3xB2FzLiyj3XwUgOHf2fo+iTYutRoUYUQoqokYJRDAoaoMZkJarNK3JFrj6TTwHX/5Jz8YeTXaqdRIYSo5SRglEMChjCr/CyIPw5xh2DnHEg5C2jUYbB3vA6WOnOXUAghbqoyn6Eyxk6ImmRtDwGdofNj8K+t0GE8oMCOz+G7OyHhhLlLKIQQJiEBQwhz0TnAPZ/Dg/PBzg3ij8A3fWHXV2AwmLt0QghxWyRgCGFuzYfAUzsh7C7Q58GqV+C3e9Xl5oUQoo6SgCFEbeDoBQ8tgqEfgaUtnN0IX3WHY0vNXTIhhKgSCRhC1BYajdo348mt4NMOcq7C4vGw5EmIPwYNqz+2EKKOk1EkQtRGhfnq9OTbPgalqD+GSxA0HwrNhkBgd7CwNG8ZhRANjgxTLYcEDFGnxOyCbZ+qTSaFude22zaCpoPUsBF6h9phVAghqpkEjHJIwBB1Un4WnNkAJ1fCqVWQk3Jtn4UOGvdTazdaDAM7V7MVUwhRv0nAKIcEDFHn6QvV6chProCoFXD1/LV9FtZqzUb4GGgSAZbWZiumEKL+kYBRDgkYol5RFHVyrqgV6oiT+KPX9tm5Qev7IPxB8G0vS8kLIW6bBIxySMAQ9VrcETi0AI4shsz4a9s9mqtBo80D4OxnvvIJIeo0CRjlkIAhGgR9IZzdBIfmqU0pxg6iGmjcV52ivPnd0oQihKgUCRjlkIAhGpzcNDi+TK3ZuLD92nYHLzVodJwgtRpCiAqRgFEOCRiiQbt6Hg7+Bgd+udaEorGAZoPVSb5C+oJW5t8TQpRNAkY5JGAIgTqR18n/wd4f4MK2a9vdmkCnSdBujDrXhhBCXEcCRjkkYAhxg4QTatA4tADyM9RtlrbQ5j7oMA78O8sIFCEEIAGjXBIwhLiJvAx19Mme7yHh2LXtbk3UEShtR4NLoPnKJ4QwOwkY5ZCAIcQtKIo6kde+uXBiORRkX9sX3FudxKvlPaBzNF8ZhRBmIQGjHBIwhKiEvAw48TdEzoPzW69tt7JTpyUPHwMhfUBrYb4yCiFqjASMckjAEKKKUmPg8EKInA8pZ65td/JT59RoehcE9QIrG/OVUQhRrSRglEMChhC3SVHg4j51Eq+jf6rzbBSzslMXXgu7S33I/BpC1CsSMMohAUMIEyrIheh1cHo1nF4LGVdK7vdqo9ZshA0E/07SlCJEHScBoxwSMISoJooCcYfh1Bo1cFzcB1z334utK/h1BM8W6sOjOXg0A2t7sxVZCFE5EjDKIQFDiBqSlQTR69WwEb2uZFOKkQYaBYFHi9LBw1JX40UWQpRPAkY5JGAIYQb6Qrh8QF1OPuHEtUd2UtnHay3BvSl4tQbv1kVf24CDZ82WWwhRggSMckjAEKIWyUq6FjYST0DCSUg4DrmpZR/v4HVd6Gijdih18KjJEgvRoEnAKIcEDCFqOUWB9MsQdwTij0DcUbXmI/kMJfp0AFg7QP/XoMsTYGFpluIK0ZBIwCiHBAwh6qj8LLWmI+6I+ojZqdZ2gFqbcffHENDFvGUUop6TgFEOCRhC1BMGAxz8BdZOv9ak0mEcRLwFdq5mLZoQ9VVlPkO1NVQmIYQwLa0WOk6AZ/ZDu4fVbQd+gdkd4cCvagARQphNrQgYc+bMITg4GBsbG7p27cqePXsqdN6CBQvQaDSMGDGiegsohKi97N1hxByYuAo8W0JOCiyfAnMHq/03hBBmYfaAsXDhQqZNm8b06dM5cOAA4eHhDBw4kISEhHLPO3/+PP/+97/p3bt3DZVUCFGrBXWHf22BAW+DlT3E7oJv+sDq19RF24QQNcrsfTC6du1K586d+eKLLwAwGAwEBATwzDPP8Morr5R5jl6vp0+fPjz66KNs3bqV1NRUli5dWuaxeXl55OXlGZ+np6cTEBAgfTCEqM/SLsKqV9SVYEENHE3vghb3qGuk6BzMWz4h6qg60wcjPz+f/fv3ExERYdym1WqJiIhg586dNz1v5syZeHp6MmnSpFu+xqxZs3B2djY+AgICTFJ2IUQt5uwPo3+DhxaDaygUZMGxJfDHRHi/Mcwfo64Km3PV3CUVot4y68DxpKQk9Ho9Xl5eJbZ7eXlx8uTJMs/Ztm0bP/zwA5GRkRV6jVdffZVp06YZnxfXYAghGoCmd0HYALh0AE4sVx8pZyFqpfrQWkJIX2h5j7rkvL27uUssRL1Rp2amycjI4JFHHuG7777D3b1i/xHodDp0OlnTQIgGS6MB/47qI2IGxB8rCht/q/NonFmvPv73PAT1VJtRWgwDJx9zl1yIOs2sAcPd3R0LCwvi4+NLbI+Pj8fb27vU8WfOnOH8+fMMGzbMuM1QNBTN0tKSqKgoQkNDq7fQQoi6S6NRpxn3bg39/w+SouHEMji+HK5Ewvmt6uOflyCgq1qz0eIecJFaTyEqq1Z08uzSpQuzZ88G1MAQGBjIlClTSnXyzM3NJTo6usS2119/nYyMDD777DOaNm2KtbV1ua8nE20JIcp09YJaq3FiOcTuLrnPr6MaNFreA66NzVM+IWqBynyGmr2JZNq0aYwfP55OnTrRpUsXPv30U7Kyspg4cSIA48aNw8/Pj1mzZmFjY0Pr1q1LnO/i4gJQarsQQlRKoyDoMUV9pF9Ww8bx5XBhO1zarz7WTVdXdW05XA0cHs3MXWohai2zB4zRo0eTmJjIm2++SVxcHO3atWPVqlXGjp8xMTFotWafrkMI0ZA4+ULXf6mPjHg4+T+1ZuPc1mtroWx4R11SvsUwNWz4hKtNMEIIoBY0kdQ0aSIRQlRZVjJErVBrN85sBEPBtX3OgUVhY5i66JrWwnzlFKKayGJn5ZCAIYQwidw0OL1Wrdk4vRYKsq/ts/eE5kPVppSQPhI2RL0hAaMcEjCEECZXkANnNqg1G1Er1fBRzMkf2o2Bdg9JB1FR50nAKIcEDCFEtdIXqENdjy9XZw8tXkoe1Hk22o1VazZkunJRB0nAKIcEDCFEjSnIVWs0Dv6m1nBQ9N+ttQO0GqEuMx/YTTqHijpDAkY5JGAIIcwi7RIcmg+Rv6vTlRdzDVWbUFrfB64h5iufEBUgAaMcEjCEEGalKBCzCyJ/g2NLIT/z2j6/TtDmPmg1EhxLz2YshLlJwCiHBAwhRK2RlwnHl8GRRXBuCyiGoh0aCO6lho0W94Cdq1mLKUQxCRjlkIAhhKiVMuLh+FI48gdc3HNtu9YKmtypNqE0GyydQ4VZScAohwQMIUStd/UCHP1TfcQfvbZdowVHX3Vac5eg0l8dfUBmPhbVSAJGOSRgCCHqlISTRWHjj5KdQ8tiYQ3O/uoU5s0GQ/NhYO9WM+UUDYIEjHJIwBBC1EmKApkJkHpBreFIPV/0teh52kVQ9CXP0VhA475qp9Hmd0tfDnHbJGCUQwKGEKJe0hdC+iVIjVH7cBxbCnGHr+3XWkJIcdgYKmFDVIkEjHJIwBBCNBjJZ9TZRI8vVVeALaa1hMb9oeU94N8F3MNkvRRRIRIwyiEBQwjRICVFw/Elas3G9R1HAazswKu1uuR88cOjOVham6WoovaSgFEOCRhCiAYv6bQaNKLXqTUbBVmlj7GwBs+Watjwba82qzh41nhRRe0iAaMcEjCEEOI6Br06OuXKIbgSWfT1UMkVYUHtMBp2lzqtedNBYKkzS3GFeUnAKIcEDCGEuAVFUUenFIeNs5vg0v5r+20bQZv71SXofdrJYm0NiASMckjAEEKIKkg8BYfmwaEFkHHl2naPFmrQaPuArJ/SAEjAKIcEDCGEuA0GPZzdCJHz4MT/QJ+nbtdoIfROdRn6sIHg4GHWYorqIQGjHBIwhBDCRHJS1WGwkfNKrp+CBgK6qLOJNhuiziwqzSj1ggSMckjAEEKIapB0Wl2o7dQ/ar+N67k2VoNG00EQ2B0sLM1TRnHbJGCUQwKGEEJUs7SLcGoVRP2jLkOvz7+2z8YFwgZAYDfwaQ9ercDKxmxFFZUjAaMcEjCEEKIG5WXAmQ0QtUoNHTkpJfdrLdWOor7h6ogU3+LQYWuW4oryScAohwQMIYQwE4MeYveoE3xdPqjOu5GdXPo4jQV4tlADR2A3CO4FjYKlH0ctIAGjHBIwhBCillAUtTnlSiRcjrz2NTup9LFO/mrQKH5I4DALCRjlkIAhhBC1mKKoq8JejlQn97qwAy7tA0NhyeMkcJiFBIxySMAQQog6Jj9LbVo5v019XNoPhoKSx1jZqyHDNUT92igYGhV97xIoC7eZiASMckjAEEKIOq4igaMEDTj7FwWQxuDW5NqjUbCEj0qQgFEOCRhCCFHPFOZBagxcPa8+Us4VfV/0tSD75udqtOASdF3oCFUf7k3ByU+aXW5Qmc9Qme1ECCFE3WapA/cw9XEjRYGsxKLQcQ6Sz0BydNHjjLpU/dWifdFrS55r7ahe06M5eDS79nAJAq1Fzby3OkwChhBCiPpLowEHT/UR2LXkPkWBjLjrAkdR6Eg+rQaS/Ay4fEB9XM/SBtzC1LDhEw5BPcGnLVhY1dz7qgOkiUQIIYS4UWE+pJyFxJOQdEr9mnhK/b54gbfrWdmr668E9YSgHuDXsV7OUCpNJEIIIcTtsLQGz+bq43oGPaRegMQoSDgBF/eqQ2lzU9VVZs9uVI+zsAa/TmrYCOqh9umwslNDh6UtaLU1/pZqmtRgCCGEELfDYIDEE2rQuLBd/ZoZX/45Fjo1bFjZqU0uxeHDwVttdil+OHrXqo6mMoqkHBIwhBBCVCtFUZtXisPGhR1qX4+ymlZuxd6jZODwCVc7mZopdEjAKIcEDCGEEGZh0ENhLhTkqI/CXHUIbUHx1xy1+eXKIfWReBIUQ+nr2DiDV+uiIbVFw2tdQ9VJxix11foWpA+GEEIIUdtoLcDaXn1URH42JBxX12gpDh3xxyE3rah2ZHvJ4zVacA4oHTwCOquhpIZJDYYQQghRVxTmq/09EqNuGFp7Rh1WW5ZH15QeoltFUoMhhBBC1EeW1tf6YlxPUSAzAVLOlA4ebk3MU1SzvKoQQgghTEejAUcv9RHUw9ylAaD+D8QVQgghRI2TgCGEEEIIk5OAIYQQQgiTk4AhhBBCCJOTgCGEEEIIk5OAIYQQQgiTk4AhhBBCCJOTgCGEEEIIk5OAIYQQQgiTk4AhhBBCCJOTgCGEEEIIk2twa5EULx6bnp5u5pIIIYQQdUvxZ2dFFmJvcAEjI0NdzjYgIMDMJRFCCCHqpoyMDJydncs9RqNUJIbUIwaDgcuXL+Po6IhGoyn32PT0dAICAoiNjb3luveiZsg9qX3kntQucj9qn/p0TxRFISMjA19fX7Ta8ntZNLgaDK1Wi7+/f6XOcXJyqvO/FPWN3JPaR+5J7SL3o/apL/fkVjUXxaSTpxBCCCFMTgKGEEIIIUxOAkY5dDod06dPR6fTmbsooojck9pH7kntIvej9mmo96TBdfIUQgghRPWTGgwhhBBCmJwEDCGEEEKYnAQMIYQQQpicBAwhhBBCmJwEjHLMmTOH4OBgbGxs6Nq1K3v27DF3kRqMLVu2MGzYMHx9fdFoNCxdurTEfkVRePPNN/Hx8cHW1paIiAhOnz5tnsI2ALNmzaJz5844Ojri6enJiBEjiIqKKnFMbm4ukydPxs3NDQcHB0aNGkV8fLyZSlz/ffXVV7Rt29Y4eVP37t35559/jPvlfpjXf/7zHzQaDVOnTjVua2j3RALGTSxcuJBp06Yxffp0Dhw4QHh4OAMHDiQhIcHcRWsQsrKyCA8PZ86cOWXuf//99/n888/5+uuv2b17N/b29gwcOJDc3NwaLmnDsHnzZiZPnsyuXbtYu3YtBQUF3HXXXWRlZRmPef755/n7779ZvHgxmzdv5vLly9x7771mLHX95u/vz3/+8x/279/Pvn37uOOOOxg+fDjHjh0D5H6Y0969e/nmm29o27Ztie0N7p4ookxdunRRJk+ebHyu1+sVX19fZdasWWYsVcMEKEuWLDE+NxgMire3t/LBBx8Yt6Wmpio6nU6ZP3++GUrY8CQkJCiAsnnzZkVR1J+/lZWVsnjxYuMxJ06cUABl586d5ipmg9OoUSPl+++/l/thRhkZGUpYWJiydu1apW/fvspzzz2nKErD/DciNRhlyM/PZ//+/URERBi3abVaIiIi2LlzpxlLJgDOnTtHXFxcifvj7OxM165d5f7UkLS0NABcXV0B2L9/PwUFBSXuSfPmzQkMDJR7UgP0ej0LFiwgKyuL7t27y/0wo8mTJzN06NASP3tomP9GGtxiZxWRlJSEXq/Hy8urxHYvLy9OnjxpplKJYnFxcQBl3p/ifaL6GAwGpk6dSs+ePWndujWg3hNra2tcXFxKHCv3pHodOXKE7t27k5ubi4ODA0uWLKFly5ZERkbK/TCDBQsWcODAAfbu3VtqX0P8NyIBQwhRKZMnT+bo0aNs27bN3EVp8Jo1a0ZkZCRpaWn88ccfjB8/ns2bN5u7WA1SbGwszz33HGvXrsXGxsbcxakVpImkDO7u7lhYWJTq3RsfH4+3t7eZSiWKFd8DuT81b8qUKfzvf/9j48aN+Pv7G7d7e3uTn59PampqiePlnlQva2trmjRpQseOHZk1axbh4eF89tlncj/MYP/+/SQkJNChQwcsLS2xtLRk8+bNfP7551haWuLl5dXg7okEjDJYW1vTsWNH1q9fb9xmMBhYv3493bt3N2PJBEBISAje3t4l7k96ejq7d++W+1NNFEVhypQpLFmyhA0bNhASElJif8eOHbGysipxT6KiooiJiZF7UoMMBgN5eXlyP8zgzjvv5MiRI0RGRhofnTp1YuzYscbvG9o9kSaSm5g2bRrjx4+nU6dOdOnShU8//ZSsrCwmTpxo7qI1CJmZmURHRxufnzt3jsjISFxdXQkMDGTq1Km88847hIWFERISwhtvvIGvry8jRowwX6HrscmTJzNv3jyWLVuGo6Ojsc3Y2dkZW1tbnJ2dmTRpEtOmTcPV1RUnJyeeeeYZunfvTrdu3cxc+vrp1VdfZfDgwQQGBpKRkcG8efPYtGkTq1evlvthBo6OjsY+ScXs7e1xc3Mzbm9w98Tcw1hqs9mzZyuBgYGKtbW10qVLF2XXrl3mLlKDsXHjRgUo9Rg/fryiKOpQ1TfeeEPx8vJSdDqdcueddypRUVHmLXQ9Vta9AJS5c+caj8nJyVGefvpppVGjRoqdnZ0ycuRI5cqVK+YrdD336KOPKkFBQYq1tbXi4eGh3HnnncqaNWuM++V+mN/1w1QVpeHdE1muXQghhBAmJ30whBBCCGFyEjCEEEIIYXISMIQQQghhchIwhBBCCGFyEjCEEEIIYXISMIQQQghhchIwhBBCCGFyEjCEEEIIYXISMIQQ9YJGo2Hp0qXmLoYQoogEDCHEbZswYQIajabUY9CgQeYumhDCTGSxMyGESQwaNIi5c+eW2KbT6cxUGiGEuUkNhhDCJHQ6Hd7e3iUejRo1AtTmi6+++orBgwdja2tL48aN+eOPP0qcf+TIEe644w5sbW1xc3PjiSeeIDMzs8QxP/74I61atUKn0+Hj48OUKVNK7E9KSmLkyJHY2dkRFhbG8uXLq/dNCyFuSgKGEKJGvPHGG4waNYpDhw4xduxYHnzwQU6cOAFAVlYWAwcOpFGjRuzdu5fFixezbt26EgHiq6++YvLkyTzxxBMcOXKE5cuX06RJkxKv8dZbb/HAAw9w+PBhhgwZwtixY0lJSanR9ymEKGLu5VyFEHXf+PHjFQsLC8Xe3r7E491331UURV3u/cknnyxxTteuXZWnnnpKURRF+fbbb5VGjRopmZmZxv0rVqxQtFqtEhcXpyiKovj6+iqvvfbaTcsAKK+//rrxeWZmpgIo//zzj8nepxCi4qQPhhDCJPr3789XX31VYpurq6vx++7du5fY1717dyIjIwE4ceIE4eHh2NvbG/f37NkTg8FAVFQUGo2Gy5cvc+edd5ZbhrZt2xq/t7e3x8nJiYSEhKq+JSHEbZCAIYQwCXt7+1JNFqZia2tboeOsrKxKPNdoNBgMhuookhDiFqQPhhCiRuzatavU8xYtWgDQokULDh06RFZWlnH/9u3b0Wq1NGvWDEdHR4KDg1m/fn2NllkIUXVSgyGEMIm8vDzi4uJKbLO0tMTd3R2AxYsX06lTJ3r16sXvv//Onj17+OGHHwAYO3Ys06dPZ/z48cyYMYPExESeeeYZHnnkEby8vACYMWMGTz75JJ6engwePJiMjAy2b9/OM888U7NvVAhRIRIwhBAmsWrVKnx8fEpsa9asGSdPngTUER4LFizg6aefxsfHh/nz59OyZUsA7OzsWL16Nc899xydO3fGzs6OUaNG8fHHHxuvNX78eHJzc/nkk0/497//jbu7O/fdd1/NvUEhRKVoFEVRzF0IIUT9ptFoWLJkCSNGjDB3UYQQNUT6YAghhBDC5CRgCCGEEMLkpA+GEKLaSUusEA2P1GAIIYQQwuQkYAghhBDC5CRgCCGEEMLkJGAIIYQQwuQkYAghhBDC5CRgCCGEEMLkJGAIIYQQwuQkYAghhBDC5P4f7oUsC23to/oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_r = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "def to_float(x):\n",
    "    if torch.is_tensor(x):\n",
    "        return x.detach().cpu().item()\n",
    "    return float(x)\n",
    "\n",
    "val_vals   = [to_float(v) for v in val_losses]\n",
    "train_vals = [to_float(v) for v in train_losses]\n",
    "\n",
    "plt.plot(epochs_r, val_vals,   label='Val loss')\n",
    "plt.plot(epochs_r, train_vals, label='Train loss')\n",
    "\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training vs Validation loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs_r, train_accs, label='Train acc')\n",
    "plt.plot(epochs_r, val_accs,  label='Val acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training vs Validation accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "VAL   | acc 0.6546 | P 0.6041 | R 0.6025 | F1 0.6033| AUC 0.7135\n",
      "TEST  | acc 0.6307 | P 0.5972 | R 0.6024 | F1 0.5998| AUC 0.6994\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "# # === 重新实例化网络，与训练时配置保持一致 ===\n",
    "best_net = Net(config, num_classes).to(device)\n",
    "\n",
    "# # === 加载参数 ===\n",
    "best_net.load_state_dict(torch.load(model_path, map_location=device,weights_only=False))\n",
    "\n",
    "# best_net=copy.deepcopy(best_model)\n",
    "best_net.eval()      # 切到推理模式\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pretty_print(split_name, metrics):\n",
    "    acc, prec, rec, f1, auc= metrics\n",
    "    print(\n",
    "        f\"{split_name:<5} | \"\n",
    "        f\"acc {acc:6.4f} | \"\n",
    "        f\"P {prec:6.4f} | \"\n",
    "        f\"R {rec:6.4f} | \"\n",
    "        f\"F1 {f1:6.4f}| \"\n",
    "        f\"AUC {auc:6.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 评估\n",
    "val_metrics  = evaluate_sample_level(best_net, val_loader, device=device)\n",
    "test_metrics = evaluate_sample_level(best_net, test_loader,  device=device)\n",
    "\n",
    "# 打印\n",
    "print(\"=\"*55)\n",
    "pretty_print(\"VAL\",  val_metrics)\n",
    "pretty_print(\"TEST\", test_metrics)\n",
    "print(\"=\"*55)\n",
    "# =======================================================\n",
    "# VAL   | loss   0.0195 | acc 0.6546 | P 0.6041 | R 0.6025 | F1 0.6033| AUC 0.7135\n",
    "# TEST  | loss   0.0195 | acc 0.6321 | P 0.5901 | R 0.6526 | F1 0.6198| AUC 0.6973\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0-512]    样本 1860 | ACC  67.53% | P  64.95% | R  60.29% | F1  62.53% | AUC 0.7462\n",
      "(512-1k]   样本  501 | ACC  53.69% | P  53.96% | R  56.52% | F1  55.21% | AUC 0.5855\n",
      "(1k-2k]    样本  256 | ACC  55.86% | P  52.00% | R  65.55% | F1  57.99% | AUC 0.5739\n",
      "(2k-8k]    样本  110 | ACC  49.09% | P  42.47% | R  68.89% | F1  52.54% | AUC 0.5716\n",
      "(8k-inf]   样本    5 | ACC  20.00% | P   0.00% | R   0.00% | F1   0.00% | AUC 0.0000\n"
     ]
    }
   ],
   "source": [
    "# # === 重新实例化网络，与训练时配置保持一致 ===\n",
    "best_net = Net(config, num_classes).to(device)\n",
    "\n",
    "# # === 加载参数 ===\n",
    "best_net.load_state_dict(torch.load(model_path, map_location=device,weights_only=False))\n",
    "\n",
    "# best_net=copy.deepcopy(best_model)\n",
    "best_net.eval()      # 切到推理模式\n",
    "\n",
    "\n",
    "length_bins = {\n",
    "    \"(0-512]\"     : (1,   512),\n",
    "    \"(512-1k]\"    : (513, 1023),\n",
    "    \"(1k-2k]\"   : (1024,2048),\n",
    "    \"(2k-8k]\"     : (2049,8191),\n",
    "    \"(8k-inf]\"    : (8192,99999999),\n",
    "}\n",
    "def get_sample_lengths(dataset):\n",
    "    lengths = []\n",
    "    for feat in dataset.features:\n",
    "        real_len = sum(feat.attention_mask)\n",
    "        lengths.append(real_len)\n",
    "    return lengths\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "def evaluate_by_length_bins(model, dataset, dataloader_fn, length_bins,):\n",
    "    lengths = get_sample_lengths(dataset)\n",
    "    results = {}\n",
    "    for name, (lo, hi) in length_bins.items():\n",
    "        idxs = [i for i, L in enumerate(lengths) if lo <= L <= hi]\n",
    "        if not idxs:\n",
    "            continue\n",
    "        subset = Subset(dataset, idxs)\n",
    "        loader = DataLoader(\n",
    "            subset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            collate_fn=lambda batch: collate_graph_split_chunks(\n",
    "                batch, window_size=3, chunk_size=2048, weighted_graph=True, TF_IDF=True\n",
    "            ),\n",
    "            num_workers=8,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        metrics = evaluate_sample_level(model, loader, device=device)\n",
    "        results[name] = (len(idxs), metrics)\n",
    "    return results\n",
    "\n",
    "results = evaluate_by_length_bins(best_net, test_ds, collate_graph_split_chunks, length_bins)\n",
    "\n",
    "for name, (n, (acc, prec, rec, f1, auc)) in results.items():\n",
    "    print(f\"{name:10} 样本 {n:4d} | \"\n",
    "          f\"ACC {acc*100:6.2f}% | P {prec*100:6.2f}% | R {rec*100:6.2f}% | \"\n",
    "          f\"F1 {f1*100:6.2f}% | AUC {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0-512]    样本 1860 | TP  504 TN  752 FP  272 FN  332 | ACC  67.53% | P  64.95% | R  60.29% | F1  62.53% | AUC 0.7462\n",
      "(512-1k]   样本  501 | TP  178 TN  106 FP  142 FN   75 | ACC  56.69% | P  55.62% | R  70.36% | F1  62.13% | AUC 0.5948\n",
      "(1k-2k]    样本  256 | TP   98 TN   41 FP   96 FN   21 | ACC  54.30% | P  50.52% | R  82.35% | F1  62.62% | AUC 0.5784\n",
      "(2k-4k]    样本   86 | TP   30 TN    6 FP   43 FN    7 | ACC  41.86% | P  41.10% | R  81.08% | F1  54.55% | AUC 0.5141\n",
      "(4k-8k]    样本   24 | TP    7 TN    3 FP   13 FN    1 | ACC  41.67% | P  35.00% | R  87.50% | F1  50.00% | AUC 0.6250\n",
      "(8k-inf]   样本    5 | TP    2 TN    0 FP    3 FN    0 | ACC  40.00% | P  40.00% | R 100.00% | F1  57.14% | AUC 0.5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "def evaluate_sample_level_with_confmat(model, dataloader, device=\"cpu\"):\n",
    "    preds, probs, labels = collect_logits_per_sample(model, dataloader, device=device)\n",
    "    acc  = accuracy_score(labels, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    # 混淆矩阵\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds, labels=[0,1]).ravel()\n",
    "    return acc, prec, rec, f1, auc, tp, tn, fp, fn\n",
    "def evaluate_by_length_bins(model, dataset, length_bins):\n",
    "    lengths = get_sample_lengths(dataset)\n",
    "    results = {}\n",
    "    for name, (lo, hi) in length_bins.items():\n",
    "        idxs = [i for i, L in enumerate(lengths) if lo <= L <= hi]\n",
    "        if not idxs:\n",
    "            continue\n",
    "        subset = Subset(dataset, idxs)\n",
    "        loader = DataLoader(\n",
    "            subset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            collate_fn=lambda batch: collate_graph_split_chunks(\n",
    "                batch, window_size=3, chunk_size=2048, weighted_graph=True, TF_IDF=True\n",
    "            ),\n",
    "            num_workers=8,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        metrics = evaluate_sample_level_with_confmat(model, loader, device=device)\n",
    "        results[name] = (len(idxs), metrics)\n",
    "    return results\n",
    "results = evaluate_by_length_bins(best_net, test_ds, length_bins)\n",
    "\n",
    "for name, (n, (acc, prec, rec, f1, auc, tp, tn, fp, fn)) in results.items():\n",
    "    print(f\"{name:10} 样本 {n:4d} | \"\n",
    "          f\"TP {tp:4d} TN {tn:4d} FP {fp:4d} FN {fn:4d} | \"\n",
    "          f\"ACC {acc*100:6.2f}% | P {prec*100:6.2f}% | \"\n",
    "          f\"R {rec*100:6.2f}% | F1 {f1*100:6.2f}% | AUC {auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
